{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8ee4b2-3c7b-437f-94f0-8a7c18ff443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cfba5d4-4514-4c76-b55b-fcd728d7ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biaffine import BiaffineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f747a8ef-de89-4ce9-8bff-951967b93f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self, *initial_data, **kwargs):\n",
    "        for dictionary in initial_data:\n",
    "            for key in dictionary:\n",
    "                setattr(self, key, dictionary[key])\n",
    "        for key in kwargs:\n",
    "            setattr(self, key, kwargs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3fa8c8-36be-4ad5-8a0b-8a52ad9ac6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(bert_model_path='/root/autodl-nas/pretrain-models/roberta-base',bert_feature_dim=768,biaffine_size=300,class_num=8,max_sequence_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cac71e7-3fa7-4b6d-8252-da59f4e34f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /root/autodl-nas/pretrain-models/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BiaffineModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0606f84-b03f-4d88-89fb-54db33ab54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc4cdb37-f3c7-45f6-a594-53230af8c3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('savemodel/triplet_v19.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91620652-a66a-49c7-bfd2-d66b4b4ed6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4055ea30-88a6-48d4-ab0d-92a26f03675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3818e0c4-0d05-4499-a8fe-67225edb8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c73b4f0c-1aac-43fd-b5f8-88aa9305bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.bert_model_path,add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc72027-cd48-4ad2-a669-0149eaffbf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(text):\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = ['##'] + tokens\n",
    "    sen_length = len(tokens)\n",
    "    token_range = []\n",
    "    bert_tokens = tokenizer.encode(tokens,is_split_into_words=True)\n",
    "    length = len(bert_tokens)\n",
    "    bert_tokens_padding = torch.zeros(args.max_sequence_len).long()\n",
    "    mask = torch.zeros(args.max_sequence_len).long()\n",
    "\n",
    "    for i in range(length):\n",
    "        bert_tokens_padding[i] = bert_tokens[i]\n",
    "    mask[:length] = 1\n",
    "\n",
    "    token_start = 1\n",
    "    for i, w, in enumerate(tokens):\n",
    "        token_end = token_start + len(tokenizer.encode(w, add_special_tokens=False))\n",
    "        token_range.append([token_start, token_end-1])\n",
    "        token_start = token_end\n",
    "    assert length == token_range[-1][-1]+2\n",
    "    return bert_tokens_padding,mask,token_range,sen_length,tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc263045-f02e-49af-8048-836c1f873900",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokens_padding,mask,token_range,sen_length,tokens = convert('it would not charge the battery at all, ever. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13c673c0-1db7-4087-8267-67777a1cd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokens_padding,mask,token_range,sen_length,tokens = convert('Good. Shangjin is cool! Shangjin is awsome!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7a56afe-2ae1-4809-8477-184c59192031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens_padding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b98806c1-fb32-4b59-a413-e4d2bc463685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87f0050c-a40e-4b10-90e1-59d8144c459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(bert_tokens_padding.unsqueeze(0), mask.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f889be2f-379b-4f06-aba3-30292db7fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(preds, dim=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90ef208e-1117-49c8-a676-424cc884f5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 3,  ..., 0, 0, 0],\n",
       "        [0, 0, 7,  ..., 0, 0, 0],\n",
       "        [0, 0, 3,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2637db66-75ae-4d56-a0cf-d5ac596abb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASPECT_BEGIN=1\n",
    "ASPECT_IN=2\n",
    "OPINION_BEGIN=3\n",
    "OPINION_IN=4\n",
    "PAIR=5\n",
    "sentiment2id = {'观点-负面': 5, '观点-中性':6, '观点-正面': 7}\n",
    "\n",
    "ASPECT=[ASPECT_BEGIN,ASPECT_IN]\n",
    "OPINION=[OPINION_BEGIN,OPINION_IN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "983e74dc-46a7-4afd-b55d-e3aac5e1642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2sentiment = {v:k for k,v in sentiment2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "907c593d-e4f0-4313-8de1-c267591bd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(tags, length, token_range, type):\n",
    "    spans = []\n",
    "    start = -1\n",
    "    begin,mid = type\n",
    "    for i in range(length):\n",
    "        l, r = token_range[i]\n",
    "        if tags[l][l] == -1:\n",
    "            continue\n",
    "        elif tags[l][l] == begin:\n",
    "            if start != -1:\n",
    "                spans.append([start, i - 1])\n",
    "            start = i\n",
    "        elif tags[l][l] not in type:\n",
    "            if start != -1:\n",
    "                spans.append([start, i - 1])\n",
    "                start = -1\n",
    "    if start != -1:\n",
    "        spans.append([start, length - 1])\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab51c110-6bf1-4bb6-84b0-2f476d18ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_triplet(tags, aspect_spans, opinion_spans, token_ranges):\n",
    "    triplets = []\n",
    "    for al, ar in aspect_spans:\n",
    "        for pl, pr in opinion_spans:\n",
    "            tag_num = [0] * 8\n",
    "            for i in range(al, ar + 1):\n",
    "                for j in range(pl, pr + 1):\n",
    "                    a_start = token_ranges[i][0]\n",
    "                    o_start = token_ranges[j][0]\n",
    "                    if al < pl:\n",
    "                        tag_num[int(tags[a_start][o_start])] += 1\n",
    "                    else:\n",
    "                        tag_num[int(tags[o_start][a_start])] += 1\n",
    "\n",
    "            if sum(tag_num[5:]) == 0: continue\n",
    "            sentiment = -1\n",
    "            if tag_num[5] >= tag_num[6] and tag_num[5] >= tag_num[7]:\n",
    "                sentiment = 5\n",
    "            elif tag_num[6] >= tag_num[5] and tag_num[6] >= tag_num[7]:\n",
    "                sentiment = 6\n",
    "            elif tag_num[7] >= tag_num[5] and tag_num[7] >= tag_num[6]:\n",
    "                sentiment = 7\n",
    "            if sentiment == -1:\n",
    "                continue\n",
    "            triplets.append([al, ar, pl, pr, sentiment])\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "205f6da1-d878-4798-a16a-e5eb2b27f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_aspect_spans = get_spans(preds, sen_length, token_range, ASPECT)\n",
    "predicted_opinion_spans = get_spans(preds, sen_length, token_range, OPINION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69073862-bbb3-421c-875e-af17b343d973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[3, 3], [7, 7]], [[1, 1], [5, 5], [9, 9]], 11)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_aspect_spans,predicted_opinion_spans, sen_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3201bc4-f4b4-4fe6-8173-a16f4d9a13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = find_triplet(preds, predicted_aspect_spans,predicted_opinion_spans,token_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d53514f3-e3e7-44a6-84d5-7d9925ad27e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 3, 5, 5, 7], [7, 7, 9, 9, 7]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7923cb9-b28f-45b9-91b5-7aff5095472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('shangjin', 'cool', '观点-正面')\n",
      "('shangjin', 'awsome', '观点-正面')\n"
     ]
    }
   ],
   "source": [
    "for al,ar,pl,pr,sentiment in triplets:\n",
    "    aspect = ' '.join(tokens[al:ar+1])\n",
    "    opinion = ' '.join(tokens[pl:pr+1])\n",
    "    sentiment = id2sentiment[sentiment]\n",
    "    print((aspect,opinion,sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add64bf7-d70f-439c-82ce-a4b2c8b37aa2",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc7c9e10-c818-49da-91e6-c79bb5b8d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"gts-absa-v19\"\n",
    "save_path=\"/root/autodl-nas/export_models/absa/\"\n",
    "max_length=128\n",
    "opset_version=14\n",
    "export_model_path=f\"{save_path}/{model_id}.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49cea113-a244-4912-95de-939d04961eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from psutil import cpu_count\n",
    "\n",
    "# Constants from the performance optimization available in onnxruntime\n",
    "# It needs to be done before importing onnxruntime\n",
    "environ[\"OMP_NUM_THREADS\"] = str(cpu_count(logical=True))\n",
    "environ[\"OMP_WAIT_POLICY\"] = 'ACTIVE'\n",
    "\n",
    "from onnxruntime import GraphOptimizationLevel, InferenceSession, SessionOptions, get_all_providers\n",
    "\n",
    "class OnnxModel:\n",
    "    def __init__(self, model_path: str, provider: str):\n",
    "        assert provider in get_all_providers(), f\"provider {provider} not found, {get_all_providers()}\"\n",
    "        self.options = self._set_options()\n",
    "        self.model=InferenceSession(model_path, self.options, providers=[provider])\n",
    "        # Load the model as a graph and prepare the CPU backend \n",
    "        self.model.disable_fallback()\n",
    "\n",
    "    def __call__(self, input):\n",
    "        return self.model.run(None, input)[0]\n",
    "  \n",
    "    def _set_options(self):\n",
    "        # Few properties that might have an impact on performances (provided by MS)\n",
    "        options = SessionOptions()\n",
    "        options.intra_op_num_threads = 1\n",
    "        options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "        return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "502c65b7-3b71-440d-995a-7bc646ec1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLC(torch.nn.Module):\n",
    "    def __init__(self, basemodel):\n",
    "        super().__init__()\n",
    "        self.basemodel = basemodel\n",
    "\n",
    "    def forward(self, input_ids,attention_mask):\n",
    "        outputs = self.basemodel(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        logits = outputs\n",
    "        return torch.reshape(torch.argmax(logits,dim=3),(-1,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5cad4f1-4dce-4083-9aa5-e0568896241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc = MLC(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e9f531e-92ac-425d-84e0-a350036eea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase={'input_ids':bert_tokens_padding.unsqueeze(0), \"attention_mask\":mask.unsqueeze(0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "184f3214-efc7-4d08-b388-8755758bf9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mlc(**paraphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e224cd4e-18f9-4671-9e24-ece31c389ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created input_names:\n",
      "['input_ids', 'attention_mask']\n",
      "created output_names:\n",
      "['output_0']\n",
      "created dynamic_axes:\n",
      "{'input_ids': {0: 'batch_size'}, 'attention_mask': {0: 'batch_size'}, 'output_0': {0: 'batch_size'}}\n"
     ]
    }
   ],
   "source": [
    "# generate input and output names/keys\n",
    "input_names = list(paraphrase.keys())\n",
    "output_names = [\"output_0\"]\n",
    "\n",
    "# Generate dynamic axes, with batching -> inputs/outputs with potential dynamic shape\n",
    "symbolic_names = {0: 'batch_size'} #TODO: Exaplain\n",
    "\n",
    "input_dynamic_axes = {input_key: symbolic_names for input_key in input_names}\n",
    "output_dynamic_axes = {output_key: {0: 'batch_size'} for output_key in output_names}\n",
    "dynamic_axes = dict(input_dynamic_axes, **output_dynamic_axes)\n",
    "\n",
    "print(f\"created input_names:\")\n",
    "print(input_names)\n",
    "print(f\"created output_names:\")\n",
    "print(output_names)\n",
    "print(f\"created dynamic_axes:\")\n",
    "print(dynamic_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b63583e-8d31-453d-bad5-4300f2e4b258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': {0: 'batch_size'},\n",
       " 'attention_mask': {0: 'batch_size'},\n",
       " 'output_0': {0: 'batch_size'}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0201b1d0-c940-4597-85d1-44de453fce65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py:716: UserWarning: allowzero=0 by default. In order to honor zero value in shape use allowzero=1\n",
      "  warnings.warn(\"allowzero=0 by default. In order to honor zero value in shape use allowzero=1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported at  /root/autodl-nas/export_models/absa//gts-absa-v19.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "mlc.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(mlc,                               # model being run\n",
    "                      args=tuple(paraphrase.values()),     # model input (or a tuple for multiple inputs)\n",
    "                      f=export_model_path,                 # where to save the model (can be a file or file-like object)\n",
    "                      opset_version=14,         # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,            # whether to execute constant folding for optimization\n",
    "                      enable_onnx_checker=True, \n",
    "                      use_external_data_format=False,\n",
    "                      input_names=input_names,             # the model's input names  'input_ids', 'token_type_ids', 'attention_mask'\n",
    "                      output_names=output_names,           # the model's output names 'output_0'\n",
    "                      dynamic_axes=dynamic_axes)           # inputs/outputs with potential dynamic shape -> mostly all\n",
    "\n",
    "print(\"Model exported at \", export_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a28a383b-dd0e-4962-af0e-112ff8c826b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = \"CPUExecutionProvider\"\n",
    "onnx_model = OnnxModel(\"/root/autodl-nas/export_models/absa/gts-absa-v19.onnx\", provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90279a4c-7824-450a-a005-705242c5de9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 3, ..., 0, 0, 0],\n",
       "        [0, 0, 7, ..., 0, 0, 0],\n",
       "        [0, 0, 3, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_onnx = {k: v.cpu().detach().numpy() for k, v in paraphrase.items()}\n",
    "onnx_model(inputs_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d6e4f1-15ae-4015-be98-60f1d68a998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %input_ids[INT64, batch_sizexsequence]\n",
      "  %attention_mask[INT64, batch_sizexsequence]\n",
      ") initializers (\n",
      "  %basemodel.roberta.embeddings.word_embeddings.weight[FLOAT, 50265x768]\n",
      "  %basemodel.roberta.embeddings.position_embeddings.weight[FLOAT, 514x768]\n",
      "  %basemodel.roberta.embeddings.token_type_embeddings.weight[FLOAT, 1x768]\n",
      "  %basemodel.roberta.embeddings.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.embeddings.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.0.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.0.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.0.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.0.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.0.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.0.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.0.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.0.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.0.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.0.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.1.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.1.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.1.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.1.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.1.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.1.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.1.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.1.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.1.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.1.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.2.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.2.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.2.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.2.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.2.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.2.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.2.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.2.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.2.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.2.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.3.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.3.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.3.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.3.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.3.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.3.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.3.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.3.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.3.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.3.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.4.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.4.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.4.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.4.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.4.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.4.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.4.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.4.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.4.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.4.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.5.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.5.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.5.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.5.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.5.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.5.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.5.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.5.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.5.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.5.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.6.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.6.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.6.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.6.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.6.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.6.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.6.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.6.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.6.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.6.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.7.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.7.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.7.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.7.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.7.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.7.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.7.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.7.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.7.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.7.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.8.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.8.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.8.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.8.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.8.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.8.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.8.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.8.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.8.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.8.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.9.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.9.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.9.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.9.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.9.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.9.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.9.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.9.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.9.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.9.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.10.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.10.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.10.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.10.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.10.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.10.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.10.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.10.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.10.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.10.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.11.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.11.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.11.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.11.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.11.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.11.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.11.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.roberta.encoder.layer.11.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.11.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.roberta.encoder.layer.11.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.classifier.dense.weight[FLOAT, 768x768]\n",
      "  %basemodel.classifier.dense.bias[FLOAT, 768]\n",
      "  %basemodel.classifier.out_proj.weight[FLOAT, 73x768]\n",
      "  %basemodel.classifier.out_proj.bias[FLOAT, 73]\n",
      "  %1639[INT64, 1]\n",
      "  %1640[INT64, 1]\n",
      "  %1641[FLOAT, 768x768]\n",
      "  %1642[FLOAT, 768x768]\n",
      "  %1643[INT64, 1]\n",
      "  %1644[INT64, 1]\n",
      "  %1645[FLOAT, 768x768]\n",
      "  %1646[INT64, 1]\n",
      "  %1647[INT64, 1]\n",
      "  %1648[INT64, 1]\n",
      "  %1649[INT64, 1]\n",
      "  %1650[INT64, 1]\n",
      "  %1651[FLOAT, 768x768]\n",
      "  %1652[FLOAT, 768x3072]\n",
      "  %1653[FLOAT, 3072x768]\n",
      "  %1654[FLOAT, 768x768]\n",
      "  %1655[FLOAT, 768x768]\n",
      "  %1656[INT64, 1]\n",
      "  %1657[INT64, 1]\n",
      "  %1658[FLOAT, 768x768]\n",
      "  %1659[INT64, 1]\n",
      "  %1660[INT64, 1]\n",
      "  %1661[INT64, 1]\n",
      "  %1662[INT64, 1]\n",
      "  %1663[INT64, 1]\n",
      "  %1664[FLOAT, 768x768]\n",
      "  %1665[FLOAT, 768x3072]\n",
      "  %1666[FLOAT, 3072x768]\n",
      "  %1667[FLOAT, 768x768]\n",
      "  %1668[FLOAT, 768x768]\n",
      "  %1669[INT64, 1]\n",
      "  %1670[INT64, 1]\n",
      "  %1671[FLOAT, 768x768]\n",
      "  %1672[INT64, 1]\n",
      "  %1673[INT64, 1]\n",
      "  %1674[INT64, 1]\n",
      "  %1675[INT64, 1]\n",
      "  %1676[INT64, 1]\n",
      "  %1677[FLOAT, 768x768]\n",
      "  %1678[FLOAT, 768x3072]\n",
      "  %1679[FLOAT, 3072x768]\n",
      "  %1680[FLOAT, 768x768]\n",
      "  %1681[FLOAT, 768x768]\n",
      "  %1682[INT64, 1]\n",
      "  %1683[INT64, 1]\n",
      "  %1684[FLOAT, 768x768]\n",
      "  %1685[INT64, 1]\n",
      "  %1686[INT64, 1]\n",
      "  %1687[INT64, 1]\n",
      "  %1688[INT64, 1]\n",
      "  %1689[INT64, 1]\n",
      "  %1690[FLOAT, 768x768]\n",
      "  %1691[FLOAT, 768x3072]\n",
      "  %1692[FLOAT, 3072x768]\n",
      "  %1693[FLOAT, 768x768]\n",
      "  %1694[FLOAT, 768x768]\n",
      "  %1695[INT64, 1]\n",
      "  %1696[INT64, 1]\n",
      "  %1697[FLOAT, 768x768]\n",
      "  %1698[INT64, 1]\n",
      "  %1699[INT64, 1]\n",
      "  %1700[INT64, 1]\n",
      "  %1701[INT64, 1]\n",
      "  %1702[INT64, 1]\n",
      "  %1703[FLOAT, 768x768]\n",
      "  %1704[FLOAT, 768x3072]\n",
      "  %1705[FLOAT, 3072x768]\n",
      "  %1706[FLOAT, 768x768]\n",
      "  %1707[FLOAT, 768x768]\n",
      "  %1708[INT64, 1]\n",
      "  %1709[INT64, 1]\n",
      "  %1710[FLOAT, 768x768]\n",
      "  %1711[INT64, 1]\n",
      "  %1712[INT64, 1]\n",
      "  %1713[INT64, 1]\n",
      "  %1714[INT64, 1]\n",
      "  %1715[INT64, 1]\n",
      "  %1716[FLOAT, 768x768]\n",
      "  %1717[FLOAT, 768x3072]\n",
      "  %1718[FLOAT, 3072x768]\n",
      "  %1719[FLOAT, 768x768]\n",
      "  %1720[FLOAT, 768x768]\n",
      "  %1721[INT64, 1]\n",
      "  %1722[INT64, 1]\n",
      "  %1723[FLOAT, 768x768]\n",
      "  %1724[INT64, 1]\n",
      "  %1725[INT64, 1]\n",
      "  %1726[INT64, 1]\n",
      "  %1727[INT64, 1]\n",
      "  %1728[INT64, 1]\n",
      "  %1729[FLOAT, 768x768]\n",
      "  %1730[FLOAT, 768x3072]\n",
      "  %1731[FLOAT, 3072x768]\n",
      "  %1732[FLOAT, 768x768]\n",
      "  %1733[FLOAT, 768x768]\n",
      "  %1734[INT64, 1]\n",
      "  %1735[INT64, 1]\n",
      "  %1736[FLOAT, 768x768]\n",
      "  %1737[INT64, 1]\n",
      "  %1738[INT64, 1]\n",
      "  %1739[INT64, 1]\n",
      "  %1740[INT64, 1]\n",
      "  %1741[INT64, 1]\n",
      "  %1742[FLOAT, 768x768]\n",
      "  %1743[FLOAT, 768x3072]\n",
      "  %1744[FLOAT, 3072x768]\n",
      "  %1745[FLOAT, 768x768]\n",
      "  %1746[FLOAT, 768x768]\n",
      "  %1747[INT64, 1]\n",
      "  %1748[INT64, 1]\n",
      "  %1749[FLOAT, 768x768]\n",
      "  %1750[INT64, 1]\n",
      "  %1751[INT64, 1]\n",
      "  %1752[INT64, 1]\n",
      "  %1753[INT64, 1]\n",
      "  %1754[INT64, 1]\n",
      "  %1755[FLOAT, 768x768]\n",
      "  %1756[FLOAT, 768x3072]\n",
      "  %1757[FLOAT, 3072x768]\n",
      "  %1758[FLOAT, 768x768]\n",
      "  %1759[FLOAT, 768x768]\n",
      "  %1760[INT64, 1]\n",
      "  %1761[INT64, 1]\n",
      "  %1762[FLOAT, 768x768]\n",
      "  %1763[INT64, 1]\n",
      "  %1764[INT64, 1]\n",
      "  %1765[INT64, 1]\n",
      "  %1766[INT64, 1]\n",
      "  %1767[INT64, 1]\n",
      "  %1768[FLOAT, 768x768]\n",
      "  %1769[FLOAT, 768x3072]\n",
      "  %1770[FLOAT, 3072x768]\n",
      "  %1771[FLOAT, 768x768]\n",
      "  %1772[FLOAT, 768x768]\n",
      "  %1773[INT64, 1]\n",
      "  %1774[INT64, 1]\n",
      "  %1775[FLOAT, 768x768]\n",
      "  %1776[INT64, 1]\n",
      "  %1777[INT64, 1]\n",
      "  %1778[INT64, 1]\n",
      "  %1779[INT64, 1]\n",
      "  %1780[INT64, 1]\n",
      "  %1781[FLOAT, 768x768]\n",
      "  %1782[FLOAT, 768x3072]\n",
      "  %1783[FLOAT, 3072x768]\n",
      "  %1784[FLOAT, 768x768]\n",
      "  %1785[FLOAT, 768x768]\n",
      "  %1786[INT64, 1]\n",
      "  %1787[INT64, 1]\n",
      "  %1788[FLOAT, 768x768]\n",
      "  %1789[INT64, 1]\n",
      "  %1790[INT64, 1]\n",
      "  %1791[INT64, 1]\n",
      "  %1792[INT64, 1]\n",
      "  %1793[INT64, 1]\n",
      "  %1794[FLOAT, 768x768]\n",
      "  %1795[FLOAT, 768x3072]\n",
      "  %1796[FLOAT, 3072x768]\n",
      ") {\n",
      "  %204 = Shape(%input_ids)\n",
      "  %205 = Constant[value = <Scalar Tensor []>]()\n",
      "  %206 = Gather[axis = 0](%204, %205)\n",
      "  %207 = Shape(%input_ids)\n",
      "  %208 = Constant[value = <Scalar Tensor []>]()\n",
      "  %209 = Gather[axis = 0](%207, %208)\n",
      "  %210 = Constant[value = <Tensor>]()\n",
      "  %214 = Unsqueeze[axes = [0]](%209)\n",
      "  %216 = Constant[value = <Tensor>]()\n",
      "  %217 = Slice(%210, %1639, %214, %1640, %216)\n",
      "  %218 = Unsqueeze[axes = [0]](%206)\n",
      "  %219 = Unsqueeze[axes = [0]](%209)\n",
      "  %220 = Concat[axis = 0](%218, %219)\n",
      "  %221 = Constant[value = <Tensor>]()\n",
      "  %222 = Reshape(%220, %221)\n",
      "  %223 = Shape(%222)\n",
      "  %224 = ConstantOfShape[value = <Tensor>](%223)\n",
      "  %225 = Constant[value = <Scalar Tensor []>]()\n",
      "  %226 = Mul(%224, %225)\n",
      "  %227 = Equal(%222, %226)\n",
      "  %228 = Where(%227, %224, %222)\n",
      "  %229 = Expand(%217, %228)\n",
      "  %230 = Unsqueeze[axes = [1]](%attention_mask)\n",
      "  %231 = Unsqueeze[axes = [2]](%230)\n",
      "  %232 = Cast[to = 1](%231)\n",
      "  %233 = Constant[value = <Scalar Tensor []>]()\n",
      "  %234 = Sub(%233, %232)\n",
      "  %235 = Constant[value = <Scalar Tensor []>]()\n",
      "  %236 = Mul(%234, %235)\n",
      "  %237 = Constant[value = <Scalar Tensor []>]()\n",
      "  %238 = Equal(%input_ids, %237)\n",
      "  %239 = Not(%238)\n",
      "  %240 = Cast[to = 6](%239)\n",
      "  %241 = Constant[value = <Scalar Tensor []>]()\n",
      "  %242 = CumSum(%240, %241)\n",
      "  %243 = Constant[value = <Scalar Tensor []>]()\n",
      "  %244 = Add(%242, %243)\n",
      "  %245 = Mul(%244, %240)\n",
      "  %246 = Cast[to = 7](%245)\n",
      "  %247 = Constant[value = <Scalar Tensor []>]()\n",
      "  %248 = Add(%246, %247)\n",
      "  %249 = Gather(%basemodel.roberta.embeddings.word_embeddings.weight, %input_ids)\n",
      "  %250 = Gather(%basemodel.roberta.embeddings.token_type_embeddings.weight, %229)\n",
      "  %251 = Add(%249, %250)\n",
      "  %252 = Gather(%basemodel.roberta.embeddings.position_embeddings.weight, %248)\n",
      "  %253 = Add(%251, %252)\n",
      "  %254 = ReduceMean[axes = [-1]](%253)\n",
      "  %255 = Sub(%253, %254)\n",
      "  %256 = Constant[value = <Scalar Tensor []>]()\n",
      "  %257 = Pow(%255, %256)\n",
      "  %258 = ReduceMean[axes = [-1]](%257)\n",
      "  %259 = Constant[value = <Scalar Tensor []>]()\n",
      "  %260 = Add(%258, %259)\n",
      "  %261 = Sqrt(%260)\n",
      "  %262 = Div(%255, %261)\n",
      "  %263 = Mul(%262, %basemodel.roberta.embeddings.LayerNorm.weight)\n",
      "  %264 = Add(%263, %basemodel.roberta.embeddings.LayerNorm.bias)\n",
      "  %266 = MatMul(%264, %1641)\n",
      "  %267 = Add(%basemodel.roberta.encoder.layer.0.attention.self.query.bias, %266)\n",
      "  %269 = MatMul(%264, %1642)\n",
      "  %270 = Add(%basemodel.roberta.encoder.layer.0.attention.self.key.bias, %269)\n",
      "  %271 = Shape(%270)\n",
      "  %272 = Constant[value = <Scalar Tensor []>]()\n",
      "  %273 = Gather[axis = 0](%271, %272)\n",
      "  %274 = Shape(%270)\n",
      "  %275 = Constant[value = <Scalar Tensor []>]()\n",
      "  %276 = Gather[axis = 0](%274, %275)\n",
      "  %279 = Unsqueeze[axes = [0]](%273)\n",
      "  %280 = Unsqueeze[axes = [0]](%276)\n",
      "  %283 = Concat[axis = 0](%279, %280, %1643, %1644)\n",
      "  %284 = Reshape(%270, %283)\n",
      "  %286 = MatMul(%264, %1645)\n",
      "  %287 = Add(%basemodel.roberta.encoder.layer.0.attention.self.value.bias, %286)\n",
      "  %288 = Shape(%287)\n",
      "  %289 = Constant[value = <Scalar Tensor []>]()\n",
      "  %290 = Gather[axis = 0](%288, %289)\n",
      "  %291 = Shape(%287)\n",
      "  %292 = Constant[value = <Scalar Tensor []>]()\n",
      "  %293 = Gather[axis = 0](%291, %292)\n",
      "  %296 = Unsqueeze[axes = [0]](%290)\n",
      "  %297 = Unsqueeze[axes = [0]](%293)\n",
      "  %300 = Concat[axis = 0](%296, %297, %1646, %1647)\n",
      "  %301 = Reshape(%287, %300)\n",
      "  %302 = Transpose[perm = [0, 2, 1, 3]](%301)\n",
      "  %303 = Shape(%267)\n",
      "  %304 = Constant[value = <Scalar Tensor []>]()\n",
      "  %305 = Gather[axis = 0](%303, %304)\n",
      "  %306 = Shape(%267)\n",
      "  %307 = Constant[value = <Scalar Tensor []>]()\n",
      "  %308 = Gather[axis = 0](%306, %307)\n",
      "  %311 = Unsqueeze[axes = [0]](%305)\n",
      "  %312 = Unsqueeze[axes = [0]](%308)\n",
      "  %315 = Concat[axis = 0](%311, %312, %1648, %1649)\n",
      "  %316 = Reshape(%267, %315)\n",
      "  %317 = Transpose[perm = [0, 2, 1, 3]](%316)\n",
      "  %318 = Transpose[perm = [0, 2, 3, 1]](%284)\n",
      "  %319 = MatMul(%317, %318)\n",
      "  %320 = Constant[value = <Scalar Tensor []>]()\n",
      "  %321 = Div(%319, %320)\n",
      "  %322 = Add(%321, %236)\n",
      "  %323 = Softmax[axis = 3](%322)\n",
      "  %324 = MatMul(%323, %302)\n",
      "  %325 = Transpose[perm = [0, 2, 1, 3]](%324)\n",
      "  %326 = Shape(%325)\n",
      "  %327 = Constant[value = <Scalar Tensor []>]()\n",
      "  %328 = Gather[axis = 0](%326, %327)\n",
      "  %329 = Shape(%325)\n",
      "  %330 = Constant[value = <Scalar Tensor []>]()\n",
      "  %331 = Gather[axis = 0](%329, %330)\n",
      "  %333 = Unsqueeze[axes = [0]](%328)\n",
      "  %334 = Unsqueeze[axes = [0]](%331)\n",
      "  %336 = Concat[axis = 0](%333, %334, %1650)\n",
      "  %337 = Reshape(%325, %336)\n",
      "  %339 = MatMul(%337, %1651)\n",
      "  %340 = Add(%basemodel.roberta.encoder.layer.0.attention.output.dense.bias, %339)\n",
      "  %341 = Add(%340, %264)\n",
      "  %342 = ReduceMean[axes = [-1]](%341)\n",
      "  %343 = Sub(%341, %342)\n",
      "  %344 = Constant[value = <Scalar Tensor []>]()\n",
      "  %345 = Pow(%343, %344)\n",
      "  %346 = ReduceMean[axes = [-1]](%345)\n",
      "  %347 = Constant[value = <Scalar Tensor []>]()\n",
      "  %348 = Add(%346, %347)\n",
      "  %349 = Sqrt(%348)\n",
      "  %350 = Div(%343, %349)\n",
      "  %351 = Mul(%350, %basemodel.roberta.encoder.layer.0.attention.output.LayerNorm.weight)\n",
      "  %352 = Add(%351, %basemodel.roberta.encoder.layer.0.attention.output.LayerNorm.bias)\n",
      "  %354 = MatMul(%352, %1652)\n",
      "  %355 = Add(%basemodel.roberta.encoder.layer.0.intermediate.dense.bias, %354)\n",
      "  %356 = Constant[value = <Scalar Tensor []>]()\n",
      "  %357 = Div(%355, %356)\n",
      "  %358 = Erf(%357)\n",
      "  %359 = Constant[value = <Scalar Tensor []>]()\n",
      "  %360 = Add(%358, %359)\n",
      "  %361 = Mul(%355, %360)\n",
      "  %362 = Constant[value = <Scalar Tensor []>]()\n",
      "  %363 = Mul(%361, %362)\n",
      "  %365 = MatMul(%363, %1653)\n",
      "  %366 = Add(%basemodel.roberta.encoder.layer.0.output.dense.bias, %365)\n",
      "  %367 = Add(%366, %352)\n",
      "  %368 = ReduceMean[axes = [-1]](%367)\n",
      "  %369 = Sub(%367, %368)\n",
      "  %370 = Constant[value = <Scalar Tensor []>]()\n",
      "  %371 = Pow(%369, %370)\n",
      "  %372 = ReduceMean[axes = [-1]](%371)\n",
      "  %373 = Constant[value = <Scalar Tensor []>]()\n",
      "  %374 = Add(%372, %373)\n",
      "  %375 = Sqrt(%374)\n",
      "  %376 = Div(%369, %375)\n",
      "  %377 = Mul(%376, %basemodel.roberta.encoder.layer.0.output.LayerNorm.weight)\n",
      "  %378 = Add(%377, %basemodel.roberta.encoder.layer.0.output.LayerNorm.bias)\n",
      "  %380 = MatMul(%378, %1654)\n",
      "  %381 = Add(%basemodel.roberta.encoder.layer.1.attention.self.query.bias, %380)\n",
      "  %383 = MatMul(%378, %1655)\n",
      "  %384 = Add(%basemodel.roberta.encoder.layer.1.attention.self.key.bias, %383)\n",
      "  %385 = Shape(%384)\n",
      "  %386 = Constant[value = <Scalar Tensor []>]()\n",
      "  %387 = Gather[axis = 0](%385, %386)\n",
      "  %388 = Shape(%384)\n",
      "  %389 = Constant[value = <Scalar Tensor []>]()\n",
      "  %390 = Gather[axis = 0](%388, %389)\n",
      "  %393 = Unsqueeze[axes = [0]](%387)\n",
      "  %394 = Unsqueeze[axes = [0]](%390)\n",
      "  %397 = Concat[axis = 0](%393, %394, %1656, %1657)\n",
      "  %398 = Reshape(%384, %397)\n",
      "  %400 = MatMul(%378, %1658)\n",
      "  %401 = Add(%basemodel.roberta.encoder.layer.1.attention.self.value.bias, %400)\n",
      "  %402 = Shape(%401)\n",
      "  %403 = Constant[value = <Scalar Tensor []>]()\n",
      "  %404 = Gather[axis = 0](%402, %403)\n",
      "  %405 = Shape(%401)\n",
      "  %406 = Constant[value = <Scalar Tensor []>]()\n",
      "  %407 = Gather[axis = 0](%405, %406)\n",
      "  %410 = Unsqueeze[axes = [0]](%404)\n",
      "  %411 = Unsqueeze[axes = [0]](%407)\n",
      "  %414 = Concat[axis = 0](%410, %411, %1659, %1660)\n",
      "  %415 = Reshape(%401, %414)\n",
      "  %416 = Transpose[perm = [0, 2, 1, 3]](%415)\n",
      "  %417 = Shape(%381)\n",
      "  %418 = Constant[value = <Scalar Tensor []>]()\n",
      "  %419 = Gather[axis = 0](%417, %418)\n",
      "  %420 = Shape(%381)\n",
      "  %421 = Constant[value = <Scalar Tensor []>]()\n",
      "  %422 = Gather[axis = 0](%420, %421)\n",
      "  %425 = Unsqueeze[axes = [0]](%419)\n",
      "  %426 = Unsqueeze[axes = [0]](%422)\n",
      "  %429 = Concat[axis = 0](%425, %426, %1661, %1662)\n",
      "  %430 = Reshape(%381, %429)\n",
      "  %431 = Transpose[perm = [0, 2, 1, 3]](%430)\n",
      "  %432 = Transpose[perm = [0, 2, 3, 1]](%398)\n",
      "  %433 = MatMul(%431, %432)\n",
      "  %434 = Constant[value = <Scalar Tensor []>]()\n",
      "  %435 = Div(%433, %434)\n",
      "  %436 = Add(%435, %236)\n",
      "  %437 = Softmax[axis = 3](%436)\n",
      "  %438 = MatMul(%437, %416)\n",
      "  %439 = Transpose[perm = [0, 2, 1, 3]](%438)\n",
      "  %440 = Shape(%439)\n",
      "  %441 = Constant[value = <Scalar Tensor []>]()\n",
      "  %442 = Gather[axis = 0](%440, %441)\n",
      "  %443 = Shape(%439)\n",
      "  %444 = Constant[value = <Scalar Tensor []>]()\n",
      "  %445 = Gather[axis = 0](%443, %444)\n",
      "  %447 = Unsqueeze[axes = [0]](%442)\n",
      "  %448 = Unsqueeze[axes = [0]](%445)\n",
      "  %450 = Concat[axis = 0](%447, %448, %1663)\n",
      "  %451 = Reshape(%439, %450)\n",
      "  %453 = MatMul(%451, %1664)\n",
      "  %454 = Add(%basemodel.roberta.encoder.layer.1.attention.output.dense.bias, %453)\n",
      "  %455 = Add(%454, %378)\n",
      "  %456 = ReduceMean[axes = [-1]](%455)\n",
      "  %457 = Sub(%455, %456)\n",
      "  %458 = Constant[value = <Scalar Tensor []>]()\n",
      "  %459 = Pow(%457, %458)\n",
      "  %460 = ReduceMean[axes = [-1]](%459)\n",
      "  %461 = Constant[value = <Scalar Tensor []>]()\n",
      "  %462 = Add(%460, %461)\n",
      "  %463 = Sqrt(%462)\n",
      "  %464 = Div(%457, %463)\n",
      "  %465 = Mul(%464, %basemodel.roberta.encoder.layer.1.attention.output.LayerNorm.weight)\n",
      "  %466 = Add(%465, %basemodel.roberta.encoder.layer.1.attention.output.LayerNorm.bias)\n",
      "  %468 = MatMul(%466, %1665)\n",
      "  %469 = Add(%basemodel.roberta.encoder.layer.1.intermediate.dense.bias, %468)\n",
      "  %470 = Constant[value = <Scalar Tensor []>]()\n",
      "  %471 = Div(%469, %470)\n",
      "  %472 = Erf(%471)\n",
      "  %473 = Constant[value = <Scalar Tensor []>]()\n",
      "  %474 = Add(%472, %473)\n",
      "  %475 = Mul(%469, %474)\n",
      "  %476 = Constant[value = <Scalar Tensor []>]()\n",
      "  %477 = Mul(%475, %476)\n",
      "  %479 = MatMul(%477, %1666)\n",
      "  %480 = Add(%basemodel.roberta.encoder.layer.1.output.dense.bias, %479)\n",
      "  %481 = Add(%480, %466)\n",
      "  %482 = ReduceMean[axes = [-1]](%481)\n",
      "  %483 = Sub(%481, %482)\n",
      "  %484 = Constant[value = <Scalar Tensor []>]()\n",
      "  %485 = Pow(%483, %484)\n",
      "  %486 = ReduceMean[axes = [-1]](%485)\n",
      "  %487 = Constant[value = <Scalar Tensor []>]()\n",
      "  %488 = Add(%486, %487)\n",
      "  %489 = Sqrt(%488)\n",
      "  %490 = Div(%483, %489)\n",
      "  %491 = Mul(%490, %basemodel.roberta.encoder.layer.1.output.LayerNorm.weight)\n",
      "  %492 = Add(%491, %basemodel.roberta.encoder.layer.1.output.LayerNorm.bias)\n",
      "  %494 = MatMul(%492, %1667)\n",
      "  %495 = Add(%basemodel.roberta.encoder.layer.2.attention.self.query.bias, %494)\n",
      "  %497 = MatMul(%492, %1668)\n",
      "  %498 = Add(%basemodel.roberta.encoder.layer.2.attention.self.key.bias, %497)\n",
      "  %499 = Shape(%498)\n",
      "  %500 = Constant[value = <Scalar Tensor []>]()\n",
      "  %501 = Gather[axis = 0](%499, %500)\n",
      "  %502 = Shape(%498)\n",
      "  %503 = Constant[value = <Scalar Tensor []>]()\n",
      "  %504 = Gather[axis = 0](%502, %503)\n",
      "  %507 = Unsqueeze[axes = [0]](%501)\n",
      "  %508 = Unsqueeze[axes = [0]](%504)\n",
      "  %511 = Concat[axis = 0](%507, %508, %1669, %1670)\n",
      "  %512 = Reshape(%498, %511)\n",
      "  %514 = MatMul(%492, %1671)\n",
      "  %515 = Add(%basemodel.roberta.encoder.layer.2.attention.self.value.bias, %514)\n",
      "  %516 = Shape(%515)\n",
      "  %517 = Constant[value = <Scalar Tensor []>]()\n",
      "  %518 = Gather[axis = 0](%516, %517)\n",
      "  %519 = Shape(%515)\n",
      "  %520 = Constant[value = <Scalar Tensor []>]()\n",
      "  %521 = Gather[axis = 0](%519, %520)\n",
      "  %524 = Unsqueeze[axes = [0]](%518)\n",
      "  %525 = Unsqueeze[axes = [0]](%521)\n",
      "  %528 = Concat[axis = 0](%524, %525, %1672, %1673)\n",
      "  %529 = Reshape(%515, %528)\n",
      "  %530 = Transpose[perm = [0, 2, 1, 3]](%529)\n",
      "  %531 = Shape(%495)\n",
      "  %532 = Constant[value = <Scalar Tensor []>]()\n",
      "  %533 = Gather[axis = 0](%531, %532)\n",
      "  %534 = Shape(%495)\n",
      "  %535 = Constant[value = <Scalar Tensor []>]()\n",
      "  %536 = Gather[axis = 0](%534, %535)\n",
      "  %539 = Unsqueeze[axes = [0]](%533)\n",
      "  %540 = Unsqueeze[axes = [0]](%536)\n",
      "  %543 = Concat[axis = 0](%539, %540, %1674, %1675)\n",
      "  %544 = Reshape(%495, %543)\n",
      "  %545 = Transpose[perm = [0, 2, 1, 3]](%544)\n",
      "  %546 = Transpose[perm = [0, 2, 3, 1]](%512)\n",
      "  %547 = MatMul(%545, %546)\n",
      "  %548 = Constant[value = <Scalar Tensor []>]()\n",
      "  %549 = Div(%547, %548)\n",
      "  %550 = Add(%549, %236)\n",
      "  %551 = Softmax[axis = 3](%550)\n",
      "  %552 = MatMul(%551, %530)\n",
      "  %553 = Transpose[perm = [0, 2, 1, 3]](%552)\n",
      "  %554 = Shape(%553)\n",
      "  %555 = Constant[value = <Scalar Tensor []>]()\n",
      "  %556 = Gather[axis = 0](%554, %555)\n",
      "  %557 = Shape(%553)\n",
      "  %558 = Constant[value = <Scalar Tensor []>]()\n",
      "  %559 = Gather[axis = 0](%557, %558)\n",
      "  %561 = Unsqueeze[axes = [0]](%556)\n",
      "  %562 = Unsqueeze[axes = [0]](%559)\n",
      "  %564 = Concat[axis = 0](%561, %562, %1676)\n",
      "  %565 = Reshape(%553, %564)\n",
      "  %567 = MatMul(%565, %1677)\n",
      "  %568 = Add(%basemodel.roberta.encoder.layer.2.attention.output.dense.bias, %567)\n",
      "  %569 = Add(%568, %492)\n",
      "  %570 = ReduceMean[axes = [-1]](%569)\n",
      "  %571 = Sub(%569, %570)\n",
      "  %572 = Constant[value = <Scalar Tensor []>]()\n",
      "  %573 = Pow(%571, %572)\n",
      "  %574 = ReduceMean[axes = [-1]](%573)\n",
      "  %575 = Constant[value = <Scalar Tensor []>]()\n",
      "  %576 = Add(%574, %575)\n",
      "  %577 = Sqrt(%576)\n",
      "  %578 = Div(%571, %577)\n",
      "  %579 = Mul(%578, %basemodel.roberta.encoder.layer.2.attention.output.LayerNorm.weight)\n",
      "  %580 = Add(%579, %basemodel.roberta.encoder.layer.2.attention.output.LayerNorm.bias)\n",
      "  %582 = MatMul(%580, %1678)\n",
      "  %583 = Add(%basemodel.roberta.encoder.layer.2.intermediate.dense.bias, %582)\n",
      "  %584 = Constant[value = <Scalar Tensor []>]()\n",
      "  %585 = Div(%583, %584)\n",
      "  %586 = Erf(%585)\n",
      "  %587 = Constant[value = <Scalar Tensor []>]()\n",
      "  %588 = Add(%586, %587)\n",
      "  %589 = Mul(%583, %588)\n",
      "  %590 = Constant[value = <Scalar Tensor []>]()\n",
      "  %591 = Mul(%589, %590)\n",
      "  %593 = MatMul(%591, %1679)\n",
      "  %594 = Add(%basemodel.roberta.encoder.layer.2.output.dense.bias, %593)\n",
      "  %595 = Add(%594, %580)\n",
      "  %596 = ReduceMean[axes = [-1]](%595)\n",
      "  %597 = Sub(%595, %596)\n",
      "  %598 = Constant[value = <Scalar Tensor []>]()\n",
      "  %599 = Pow(%597, %598)\n",
      "  %600 = ReduceMean[axes = [-1]](%599)\n",
      "  %601 = Constant[value = <Scalar Tensor []>]()\n",
      "  %602 = Add(%600, %601)\n",
      "  %603 = Sqrt(%602)\n",
      "  %604 = Div(%597, %603)\n",
      "  %605 = Mul(%604, %basemodel.roberta.encoder.layer.2.output.LayerNorm.weight)\n",
      "  %606 = Add(%605, %basemodel.roberta.encoder.layer.2.output.LayerNorm.bias)\n",
      "  %608 = MatMul(%606, %1680)\n",
      "  %609 = Add(%basemodel.roberta.encoder.layer.3.attention.self.query.bias, %608)\n",
      "  %611 = MatMul(%606, %1681)\n",
      "  %612 = Add(%basemodel.roberta.encoder.layer.3.attention.self.key.bias, %611)\n",
      "  %613 = Shape(%612)\n",
      "  %614 = Constant[value = <Scalar Tensor []>]()\n",
      "  %615 = Gather[axis = 0](%613, %614)\n",
      "  %616 = Shape(%612)\n",
      "  %617 = Constant[value = <Scalar Tensor []>]()\n",
      "  %618 = Gather[axis = 0](%616, %617)\n",
      "  %621 = Unsqueeze[axes = [0]](%615)\n",
      "  %622 = Unsqueeze[axes = [0]](%618)\n",
      "  %625 = Concat[axis = 0](%621, %622, %1682, %1683)\n",
      "  %626 = Reshape(%612, %625)\n",
      "  %628 = MatMul(%606, %1684)\n",
      "  %629 = Add(%basemodel.roberta.encoder.layer.3.attention.self.value.bias, %628)\n",
      "  %630 = Shape(%629)\n",
      "  %631 = Constant[value = <Scalar Tensor []>]()\n",
      "  %632 = Gather[axis = 0](%630, %631)\n",
      "  %633 = Shape(%629)\n",
      "  %634 = Constant[value = <Scalar Tensor []>]()\n",
      "  %635 = Gather[axis = 0](%633, %634)\n",
      "  %638 = Unsqueeze[axes = [0]](%632)\n",
      "  %639 = Unsqueeze[axes = [0]](%635)\n",
      "  %642 = Concat[axis = 0](%638, %639, %1685, %1686)\n",
      "  %643 = Reshape(%629, %642)\n",
      "  %644 = Transpose[perm = [0, 2, 1, 3]](%643)\n",
      "  %645 = Shape(%609)\n",
      "  %646 = Constant[value = <Scalar Tensor []>]()\n",
      "  %647 = Gather[axis = 0](%645, %646)\n",
      "  %648 = Shape(%609)\n",
      "  %649 = Constant[value = <Scalar Tensor []>]()\n",
      "  %650 = Gather[axis = 0](%648, %649)\n",
      "  %653 = Unsqueeze[axes = [0]](%647)\n",
      "  %654 = Unsqueeze[axes = [0]](%650)\n",
      "  %657 = Concat[axis = 0](%653, %654, %1687, %1688)\n",
      "  %658 = Reshape(%609, %657)\n",
      "  %659 = Transpose[perm = [0, 2, 1, 3]](%658)\n",
      "  %660 = Transpose[perm = [0, 2, 3, 1]](%626)\n",
      "  %661 = MatMul(%659, %660)\n",
      "  %662 = Constant[value = <Scalar Tensor []>]()\n",
      "  %663 = Div(%661, %662)\n",
      "  %664 = Add(%663, %236)\n",
      "  %665 = Softmax[axis = 3](%664)\n",
      "  %666 = MatMul(%665, %644)\n",
      "  %667 = Transpose[perm = [0, 2, 1, 3]](%666)\n",
      "  %668 = Shape(%667)\n",
      "  %669 = Constant[value = <Scalar Tensor []>]()\n",
      "  %670 = Gather[axis = 0](%668, %669)\n",
      "  %671 = Shape(%667)\n",
      "  %672 = Constant[value = <Scalar Tensor []>]()\n",
      "  %673 = Gather[axis = 0](%671, %672)\n",
      "  %675 = Unsqueeze[axes = [0]](%670)\n",
      "  %676 = Unsqueeze[axes = [0]](%673)\n",
      "  %678 = Concat[axis = 0](%675, %676, %1689)\n",
      "  %679 = Reshape(%667, %678)\n",
      "  %681 = MatMul(%679, %1690)\n",
      "  %682 = Add(%basemodel.roberta.encoder.layer.3.attention.output.dense.bias, %681)\n",
      "  %683 = Add(%682, %606)\n",
      "  %684 = ReduceMean[axes = [-1]](%683)\n",
      "  %685 = Sub(%683, %684)\n",
      "  %686 = Constant[value = <Scalar Tensor []>]()\n",
      "  %687 = Pow(%685, %686)\n",
      "  %688 = ReduceMean[axes = [-1]](%687)\n",
      "  %689 = Constant[value = <Scalar Tensor []>]()\n",
      "  %690 = Add(%688, %689)\n",
      "  %691 = Sqrt(%690)\n",
      "  %692 = Div(%685, %691)\n",
      "  %693 = Mul(%692, %basemodel.roberta.encoder.layer.3.attention.output.LayerNorm.weight)\n",
      "  %694 = Add(%693, %basemodel.roberta.encoder.layer.3.attention.output.LayerNorm.bias)\n",
      "  %696 = MatMul(%694, %1691)\n",
      "  %697 = Add(%basemodel.roberta.encoder.layer.3.intermediate.dense.bias, %696)\n",
      "  %698 = Constant[value = <Scalar Tensor []>]()\n",
      "  %699 = Div(%697, %698)\n",
      "  %700 = Erf(%699)\n",
      "  %701 = Constant[value = <Scalar Tensor []>]()\n",
      "  %702 = Add(%700, %701)\n",
      "  %703 = Mul(%697, %702)\n",
      "  %704 = Constant[value = <Scalar Tensor []>]()\n",
      "  %705 = Mul(%703, %704)\n",
      "  %707 = MatMul(%705, %1692)\n",
      "  %708 = Add(%basemodel.roberta.encoder.layer.3.output.dense.bias, %707)\n",
      "  %709 = Add(%708, %694)\n",
      "  %710 = ReduceMean[axes = [-1]](%709)\n",
      "  %711 = Sub(%709, %710)\n",
      "  %712 = Constant[value = <Scalar Tensor []>]()\n",
      "  %713 = Pow(%711, %712)\n",
      "  %714 = ReduceMean[axes = [-1]](%713)\n",
      "  %715 = Constant[value = <Scalar Tensor []>]()\n",
      "  %716 = Add(%714, %715)\n",
      "  %717 = Sqrt(%716)\n",
      "  %718 = Div(%711, %717)\n",
      "  %719 = Mul(%718, %basemodel.roberta.encoder.layer.3.output.LayerNorm.weight)\n",
      "  %720 = Add(%719, %basemodel.roberta.encoder.layer.3.output.LayerNorm.bias)\n",
      "  %722 = MatMul(%720, %1693)\n",
      "  %723 = Add(%basemodel.roberta.encoder.layer.4.attention.self.query.bias, %722)\n",
      "  %725 = MatMul(%720, %1694)\n",
      "  %726 = Add(%basemodel.roberta.encoder.layer.4.attention.self.key.bias, %725)\n",
      "  %727 = Shape(%726)\n",
      "  %728 = Constant[value = <Scalar Tensor []>]()\n",
      "  %729 = Gather[axis = 0](%727, %728)\n",
      "  %730 = Shape(%726)\n",
      "  %731 = Constant[value = <Scalar Tensor []>]()\n",
      "  %732 = Gather[axis = 0](%730, %731)\n",
      "  %735 = Unsqueeze[axes = [0]](%729)\n",
      "  %736 = Unsqueeze[axes = [0]](%732)\n",
      "  %739 = Concat[axis = 0](%735, %736, %1695, %1696)\n",
      "  %740 = Reshape(%726, %739)\n",
      "  %742 = MatMul(%720, %1697)\n",
      "  %743 = Add(%basemodel.roberta.encoder.layer.4.attention.self.value.bias, %742)\n",
      "  %744 = Shape(%743)\n",
      "  %745 = Constant[value = <Scalar Tensor []>]()\n",
      "  %746 = Gather[axis = 0](%744, %745)\n",
      "  %747 = Shape(%743)\n",
      "  %748 = Constant[value = <Scalar Tensor []>]()\n",
      "  %749 = Gather[axis = 0](%747, %748)\n",
      "  %752 = Unsqueeze[axes = [0]](%746)\n",
      "  %753 = Unsqueeze[axes = [0]](%749)\n",
      "  %756 = Concat[axis = 0](%752, %753, %1698, %1699)\n",
      "  %757 = Reshape(%743, %756)\n",
      "  %758 = Transpose[perm = [0, 2, 1, 3]](%757)\n",
      "  %759 = Shape(%723)\n",
      "  %760 = Constant[value = <Scalar Tensor []>]()\n",
      "  %761 = Gather[axis = 0](%759, %760)\n",
      "  %762 = Shape(%723)\n",
      "  %763 = Constant[value = <Scalar Tensor []>]()\n",
      "  %764 = Gather[axis = 0](%762, %763)\n",
      "  %767 = Unsqueeze[axes = [0]](%761)\n",
      "  %768 = Unsqueeze[axes = [0]](%764)\n",
      "  %771 = Concat[axis = 0](%767, %768, %1700, %1701)\n",
      "  %772 = Reshape(%723, %771)\n",
      "  %773 = Transpose[perm = [0, 2, 1, 3]](%772)\n",
      "  %774 = Transpose[perm = [0, 2, 3, 1]](%740)\n",
      "  %775 = MatMul(%773, %774)\n",
      "  %776 = Constant[value = <Scalar Tensor []>]()\n",
      "  %777 = Div(%775, %776)\n",
      "  %778 = Add(%777, %236)\n",
      "  %779 = Softmax[axis = 3](%778)\n",
      "  %780 = MatMul(%779, %758)\n",
      "  %781 = Transpose[perm = [0, 2, 1, 3]](%780)\n",
      "  %782 = Shape(%781)\n",
      "  %783 = Constant[value = <Scalar Tensor []>]()\n",
      "  %784 = Gather[axis = 0](%782, %783)\n",
      "  %785 = Shape(%781)\n",
      "  %786 = Constant[value = <Scalar Tensor []>]()\n",
      "  %787 = Gather[axis = 0](%785, %786)\n",
      "  %789 = Unsqueeze[axes = [0]](%784)\n",
      "  %790 = Unsqueeze[axes = [0]](%787)\n",
      "  %792 = Concat[axis = 0](%789, %790, %1702)\n",
      "  %793 = Reshape(%781, %792)\n",
      "  %795 = MatMul(%793, %1703)\n",
      "  %796 = Add(%basemodel.roberta.encoder.layer.4.attention.output.dense.bias, %795)\n",
      "  %797 = Add(%796, %720)\n",
      "  %798 = ReduceMean[axes = [-1]](%797)\n",
      "  %799 = Sub(%797, %798)\n",
      "  %800 = Constant[value = <Scalar Tensor []>]()\n",
      "  %801 = Pow(%799, %800)\n",
      "  %802 = ReduceMean[axes = [-1]](%801)\n",
      "  %803 = Constant[value = <Scalar Tensor []>]()\n",
      "  %804 = Add(%802, %803)\n",
      "  %805 = Sqrt(%804)\n",
      "  %806 = Div(%799, %805)\n",
      "  %807 = Mul(%806, %basemodel.roberta.encoder.layer.4.attention.output.LayerNorm.weight)\n",
      "  %808 = Add(%807, %basemodel.roberta.encoder.layer.4.attention.output.LayerNorm.bias)\n",
      "  %810 = MatMul(%808, %1704)\n",
      "  %811 = Add(%basemodel.roberta.encoder.layer.4.intermediate.dense.bias, %810)\n",
      "  %812 = Constant[value = <Scalar Tensor []>]()\n",
      "  %813 = Div(%811, %812)\n",
      "  %814 = Erf(%813)\n",
      "  %815 = Constant[value = <Scalar Tensor []>]()\n",
      "  %816 = Add(%814, %815)\n",
      "  %817 = Mul(%811, %816)\n",
      "  %818 = Constant[value = <Scalar Tensor []>]()\n",
      "  %819 = Mul(%817, %818)\n",
      "  %821 = MatMul(%819, %1705)\n",
      "  %822 = Add(%basemodel.roberta.encoder.layer.4.output.dense.bias, %821)\n",
      "  %823 = Add(%822, %808)\n",
      "  %824 = ReduceMean[axes = [-1]](%823)\n",
      "  %825 = Sub(%823, %824)\n",
      "  %826 = Constant[value = <Scalar Tensor []>]()\n",
      "  %827 = Pow(%825, %826)\n",
      "  %828 = ReduceMean[axes = [-1]](%827)\n",
      "  %829 = Constant[value = <Scalar Tensor []>]()\n",
      "  %830 = Add(%828, %829)\n",
      "  %831 = Sqrt(%830)\n",
      "  %832 = Div(%825, %831)\n",
      "  %833 = Mul(%832, %basemodel.roberta.encoder.layer.4.output.LayerNorm.weight)\n",
      "  %834 = Add(%833, %basemodel.roberta.encoder.layer.4.output.LayerNorm.bias)\n",
      "  %836 = MatMul(%834, %1706)\n",
      "  %837 = Add(%basemodel.roberta.encoder.layer.5.attention.self.query.bias, %836)\n",
      "  %839 = MatMul(%834, %1707)\n",
      "  %840 = Add(%basemodel.roberta.encoder.layer.5.attention.self.key.bias, %839)\n",
      "  %841 = Shape(%840)\n",
      "  %842 = Constant[value = <Scalar Tensor []>]()\n",
      "  %843 = Gather[axis = 0](%841, %842)\n",
      "  %844 = Shape(%840)\n",
      "  %845 = Constant[value = <Scalar Tensor []>]()\n",
      "  %846 = Gather[axis = 0](%844, %845)\n",
      "  %849 = Unsqueeze[axes = [0]](%843)\n",
      "  %850 = Unsqueeze[axes = [0]](%846)\n",
      "  %853 = Concat[axis = 0](%849, %850, %1708, %1709)\n",
      "  %854 = Reshape(%840, %853)\n",
      "  %856 = MatMul(%834, %1710)\n",
      "  %857 = Add(%basemodel.roberta.encoder.layer.5.attention.self.value.bias, %856)\n",
      "  %858 = Shape(%857)\n",
      "  %859 = Constant[value = <Scalar Tensor []>]()\n",
      "  %860 = Gather[axis = 0](%858, %859)\n",
      "  %861 = Shape(%857)\n",
      "  %862 = Constant[value = <Scalar Tensor []>]()\n",
      "  %863 = Gather[axis = 0](%861, %862)\n",
      "  %866 = Unsqueeze[axes = [0]](%860)\n",
      "  %867 = Unsqueeze[axes = [0]](%863)\n",
      "  %870 = Concat[axis = 0](%866, %867, %1711, %1712)\n",
      "  %871 = Reshape(%857, %870)\n",
      "  %872 = Transpose[perm = [0, 2, 1, 3]](%871)\n",
      "  %873 = Shape(%837)\n",
      "  %874 = Constant[value = <Scalar Tensor []>]()\n",
      "  %875 = Gather[axis = 0](%873, %874)\n",
      "  %876 = Shape(%837)\n",
      "  %877 = Constant[value = <Scalar Tensor []>]()\n",
      "  %878 = Gather[axis = 0](%876, %877)\n",
      "  %881 = Unsqueeze[axes = [0]](%875)\n",
      "  %882 = Unsqueeze[axes = [0]](%878)\n",
      "  %885 = Concat[axis = 0](%881, %882, %1713, %1714)\n",
      "  %886 = Reshape(%837, %885)\n",
      "  %887 = Transpose[perm = [0, 2, 1, 3]](%886)\n",
      "  %888 = Transpose[perm = [0, 2, 3, 1]](%854)\n",
      "  %889 = MatMul(%887, %888)\n",
      "  %890 = Constant[value = <Scalar Tensor []>]()\n",
      "  %891 = Div(%889, %890)\n",
      "  %892 = Add(%891, %236)\n",
      "  %893 = Softmax[axis = 3](%892)\n",
      "  %894 = MatMul(%893, %872)\n",
      "  %895 = Transpose[perm = [0, 2, 1, 3]](%894)\n",
      "  %896 = Shape(%895)\n",
      "  %897 = Constant[value = <Scalar Tensor []>]()\n",
      "  %898 = Gather[axis = 0](%896, %897)\n",
      "  %899 = Shape(%895)\n",
      "  %900 = Constant[value = <Scalar Tensor []>]()\n",
      "  %901 = Gather[axis = 0](%899, %900)\n",
      "  %903 = Unsqueeze[axes = [0]](%898)\n",
      "  %904 = Unsqueeze[axes = [0]](%901)\n",
      "  %906 = Concat[axis = 0](%903, %904, %1715)\n",
      "  %907 = Reshape(%895, %906)\n",
      "  %909 = MatMul(%907, %1716)\n",
      "  %910 = Add(%basemodel.roberta.encoder.layer.5.attention.output.dense.bias, %909)\n",
      "  %911 = Add(%910, %834)\n",
      "  %912 = ReduceMean[axes = [-1]](%911)\n",
      "  %913 = Sub(%911, %912)\n",
      "  %914 = Constant[value = <Scalar Tensor []>]()\n",
      "  %915 = Pow(%913, %914)\n",
      "  %916 = ReduceMean[axes = [-1]](%915)\n",
      "  %917 = Constant[value = <Scalar Tensor []>]()\n",
      "  %918 = Add(%916, %917)\n",
      "  %919 = Sqrt(%918)\n",
      "  %920 = Div(%913, %919)\n",
      "  %921 = Mul(%920, %basemodel.roberta.encoder.layer.5.attention.output.LayerNorm.weight)\n",
      "  %922 = Add(%921, %basemodel.roberta.encoder.layer.5.attention.output.LayerNorm.bias)\n",
      "  %924 = MatMul(%922, %1717)\n",
      "  %925 = Add(%basemodel.roberta.encoder.layer.5.intermediate.dense.bias, %924)\n",
      "  %926 = Constant[value = <Scalar Tensor []>]()\n",
      "  %927 = Div(%925, %926)\n",
      "  %928 = Erf(%927)\n",
      "  %929 = Constant[value = <Scalar Tensor []>]()\n",
      "  %930 = Add(%928, %929)\n",
      "  %931 = Mul(%925, %930)\n",
      "  %932 = Constant[value = <Scalar Tensor []>]()\n",
      "  %933 = Mul(%931, %932)\n",
      "  %935 = MatMul(%933, %1718)\n",
      "  %936 = Add(%basemodel.roberta.encoder.layer.5.output.dense.bias, %935)\n",
      "  %937 = Add(%936, %922)\n",
      "  %938 = ReduceMean[axes = [-1]](%937)\n",
      "  %939 = Sub(%937, %938)\n",
      "  %940 = Constant[value = <Scalar Tensor []>]()\n",
      "  %941 = Pow(%939, %940)\n",
      "  %942 = ReduceMean[axes = [-1]](%941)\n",
      "  %943 = Constant[value = <Scalar Tensor []>]()\n",
      "  %944 = Add(%942, %943)\n",
      "  %945 = Sqrt(%944)\n",
      "  %946 = Div(%939, %945)\n",
      "  %947 = Mul(%946, %basemodel.roberta.encoder.layer.5.output.LayerNorm.weight)\n",
      "  %948 = Add(%947, %basemodel.roberta.encoder.layer.5.output.LayerNorm.bias)\n",
      "  %950 = MatMul(%948, %1719)\n",
      "  %951 = Add(%basemodel.roberta.encoder.layer.6.attention.self.query.bias, %950)\n",
      "  %953 = MatMul(%948, %1720)\n",
      "  %954 = Add(%basemodel.roberta.encoder.layer.6.attention.self.key.bias, %953)\n",
      "  %955 = Shape(%954)\n",
      "  %956 = Constant[value = <Scalar Tensor []>]()\n",
      "  %957 = Gather[axis = 0](%955, %956)\n",
      "  %958 = Shape(%954)\n",
      "  %959 = Constant[value = <Scalar Tensor []>]()\n",
      "  %960 = Gather[axis = 0](%958, %959)\n",
      "  %963 = Unsqueeze[axes = [0]](%957)\n",
      "  %964 = Unsqueeze[axes = [0]](%960)\n",
      "  %967 = Concat[axis = 0](%963, %964, %1721, %1722)\n",
      "  %968 = Reshape(%954, %967)\n",
      "  %970 = MatMul(%948, %1723)\n",
      "  %971 = Add(%basemodel.roberta.encoder.layer.6.attention.self.value.bias, %970)\n",
      "  %972 = Shape(%971)\n",
      "  %973 = Constant[value = <Scalar Tensor []>]()\n",
      "  %974 = Gather[axis = 0](%972, %973)\n",
      "  %975 = Shape(%971)\n",
      "  %976 = Constant[value = <Scalar Tensor []>]()\n",
      "  %977 = Gather[axis = 0](%975, %976)\n",
      "  %980 = Unsqueeze[axes = [0]](%974)\n",
      "  %981 = Unsqueeze[axes = [0]](%977)\n",
      "  %984 = Concat[axis = 0](%980, %981, %1724, %1725)\n",
      "  %985 = Reshape(%971, %984)\n",
      "  %986 = Transpose[perm = [0, 2, 1, 3]](%985)\n",
      "  %987 = Shape(%951)\n",
      "  %988 = Constant[value = <Scalar Tensor []>]()\n",
      "  %989 = Gather[axis = 0](%987, %988)\n",
      "  %990 = Shape(%951)\n",
      "  %991 = Constant[value = <Scalar Tensor []>]()\n",
      "  %992 = Gather[axis = 0](%990, %991)\n",
      "  %995 = Unsqueeze[axes = [0]](%989)\n",
      "  %996 = Unsqueeze[axes = [0]](%992)\n",
      "  %999 = Concat[axis = 0](%995, %996, %1726, %1727)\n",
      "  %1000 = Reshape(%951, %999)\n",
      "  %1001 = Transpose[perm = [0, 2, 1, 3]](%1000)\n",
      "  %1002 = Transpose[perm = [0, 2, 3, 1]](%968)\n",
      "  %1003 = MatMul(%1001, %1002)\n",
      "  %1004 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1005 = Div(%1003, %1004)\n",
      "  %1006 = Add(%1005, %236)\n",
      "  %1007 = Softmax[axis = 3](%1006)\n",
      "  %1008 = MatMul(%1007, %986)\n",
      "  %1009 = Transpose[perm = [0, 2, 1, 3]](%1008)\n",
      "  %1010 = Shape(%1009)\n",
      "  %1011 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1012 = Gather[axis = 0](%1010, %1011)\n",
      "  %1013 = Shape(%1009)\n",
      "  %1014 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1015 = Gather[axis = 0](%1013, %1014)\n",
      "  %1017 = Unsqueeze[axes = [0]](%1012)\n",
      "  %1018 = Unsqueeze[axes = [0]](%1015)\n",
      "  %1020 = Concat[axis = 0](%1017, %1018, %1728)\n",
      "  %1021 = Reshape(%1009, %1020)\n",
      "  %1023 = MatMul(%1021, %1729)\n",
      "  %1024 = Add(%basemodel.roberta.encoder.layer.6.attention.output.dense.bias, %1023)\n",
      "  %1025 = Add(%1024, %948)\n",
      "  %1026 = ReduceMean[axes = [-1]](%1025)\n",
      "  %1027 = Sub(%1025, %1026)\n",
      "  %1028 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1029 = Pow(%1027, %1028)\n",
      "  %1030 = ReduceMean[axes = [-1]](%1029)\n",
      "  %1031 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1032 = Add(%1030, %1031)\n",
      "  %1033 = Sqrt(%1032)\n",
      "  %1034 = Div(%1027, %1033)\n",
      "  %1035 = Mul(%1034, %basemodel.roberta.encoder.layer.6.attention.output.LayerNorm.weight)\n",
      "  %1036 = Add(%1035, %basemodel.roberta.encoder.layer.6.attention.output.LayerNorm.bias)\n",
      "  %1038 = MatMul(%1036, %1730)\n",
      "  %1039 = Add(%basemodel.roberta.encoder.layer.6.intermediate.dense.bias, %1038)\n",
      "  %1040 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1041 = Div(%1039, %1040)\n",
      "  %1042 = Erf(%1041)\n",
      "  %1043 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1044 = Add(%1042, %1043)\n",
      "  %1045 = Mul(%1039, %1044)\n",
      "  %1046 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1047 = Mul(%1045, %1046)\n",
      "  %1049 = MatMul(%1047, %1731)\n",
      "  %1050 = Add(%basemodel.roberta.encoder.layer.6.output.dense.bias, %1049)\n",
      "  %1051 = Add(%1050, %1036)\n",
      "  %1052 = ReduceMean[axes = [-1]](%1051)\n",
      "  %1053 = Sub(%1051, %1052)\n",
      "  %1054 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1055 = Pow(%1053, %1054)\n",
      "  %1056 = ReduceMean[axes = [-1]](%1055)\n",
      "  %1057 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1058 = Add(%1056, %1057)\n",
      "  %1059 = Sqrt(%1058)\n",
      "  %1060 = Div(%1053, %1059)\n",
      "  %1061 = Mul(%1060, %basemodel.roberta.encoder.layer.6.output.LayerNorm.weight)\n",
      "  %1062 = Add(%1061, %basemodel.roberta.encoder.layer.6.output.LayerNorm.bias)\n",
      "  %1064 = MatMul(%1062, %1732)\n",
      "  %1065 = Add(%basemodel.roberta.encoder.layer.7.attention.self.query.bias, %1064)\n",
      "  %1067 = MatMul(%1062, %1733)\n",
      "  %1068 = Add(%basemodel.roberta.encoder.layer.7.attention.self.key.bias, %1067)\n",
      "  %1069 = Shape(%1068)\n",
      "  %1070 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1071 = Gather[axis = 0](%1069, %1070)\n",
      "  %1072 = Shape(%1068)\n",
      "  %1073 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1074 = Gather[axis = 0](%1072, %1073)\n",
      "  %1077 = Unsqueeze[axes = [0]](%1071)\n",
      "  %1078 = Unsqueeze[axes = [0]](%1074)\n",
      "  %1081 = Concat[axis = 0](%1077, %1078, %1734, %1735)\n",
      "  %1082 = Reshape(%1068, %1081)\n",
      "  %1084 = MatMul(%1062, %1736)\n",
      "  %1085 = Add(%basemodel.roberta.encoder.layer.7.attention.self.value.bias, %1084)\n",
      "  %1086 = Shape(%1085)\n",
      "  %1087 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1088 = Gather[axis = 0](%1086, %1087)\n",
      "  %1089 = Shape(%1085)\n",
      "  %1090 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1091 = Gather[axis = 0](%1089, %1090)\n",
      "  %1094 = Unsqueeze[axes = [0]](%1088)\n",
      "  %1095 = Unsqueeze[axes = [0]](%1091)\n",
      "  %1098 = Concat[axis = 0](%1094, %1095, %1737, %1738)\n",
      "  %1099 = Reshape(%1085, %1098)\n",
      "  %1100 = Transpose[perm = [0, 2, 1, 3]](%1099)\n",
      "  %1101 = Shape(%1065)\n",
      "  %1102 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1103 = Gather[axis = 0](%1101, %1102)\n",
      "  %1104 = Shape(%1065)\n",
      "  %1105 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1106 = Gather[axis = 0](%1104, %1105)\n",
      "  %1109 = Unsqueeze[axes = [0]](%1103)\n",
      "  %1110 = Unsqueeze[axes = [0]](%1106)\n",
      "  %1113 = Concat[axis = 0](%1109, %1110, %1739, %1740)\n",
      "  %1114 = Reshape(%1065, %1113)\n",
      "  %1115 = Transpose[perm = [0, 2, 1, 3]](%1114)\n",
      "  %1116 = Transpose[perm = [0, 2, 3, 1]](%1082)\n",
      "  %1117 = MatMul(%1115, %1116)\n",
      "  %1118 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1119 = Div(%1117, %1118)\n",
      "  %1120 = Add(%1119, %236)\n",
      "  %1121 = Softmax[axis = 3](%1120)\n",
      "  %1122 = MatMul(%1121, %1100)\n",
      "  %1123 = Transpose[perm = [0, 2, 1, 3]](%1122)\n",
      "  %1124 = Shape(%1123)\n",
      "  %1125 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1126 = Gather[axis = 0](%1124, %1125)\n",
      "  %1127 = Shape(%1123)\n",
      "  %1128 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1129 = Gather[axis = 0](%1127, %1128)\n",
      "  %1131 = Unsqueeze[axes = [0]](%1126)\n",
      "  %1132 = Unsqueeze[axes = [0]](%1129)\n",
      "  %1134 = Concat[axis = 0](%1131, %1132, %1741)\n",
      "  %1135 = Reshape(%1123, %1134)\n",
      "  %1137 = MatMul(%1135, %1742)\n",
      "  %1138 = Add(%basemodel.roberta.encoder.layer.7.attention.output.dense.bias, %1137)\n",
      "  %1139 = Add(%1138, %1062)\n",
      "  %1140 = ReduceMean[axes = [-1]](%1139)\n",
      "  %1141 = Sub(%1139, %1140)\n",
      "  %1142 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1143 = Pow(%1141, %1142)\n",
      "  %1144 = ReduceMean[axes = [-1]](%1143)\n",
      "  %1145 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1146 = Add(%1144, %1145)\n",
      "  %1147 = Sqrt(%1146)\n",
      "  %1148 = Div(%1141, %1147)\n",
      "  %1149 = Mul(%1148, %basemodel.roberta.encoder.layer.7.attention.output.LayerNorm.weight)\n",
      "  %1150 = Add(%1149, %basemodel.roberta.encoder.layer.7.attention.output.LayerNorm.bias)\n",
      "  %1152 = MatMul(%1150, %1743)\n",
      "  %1153 = Add(%basemodel.roberta.encoder.layer.7.intermediate.dense.bias, %1152)\n",
      "  %1154 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1155 = Div(%1153, %1154)\n",
      "  %1156 = Erf(%1155)\n",
      "  %1157 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1158 = Add(%1156, %1157)\n",
      "  %1159 = Mul(%1153, %1158)\n",
      "  %1160 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1161 = Mul(%1159, %1160)\n",
      "  %1163 = MatMul(%1161, %1744)\n",
      "  %1164 = Add(%basemodel.roberta.encoder.layer.7.output.dense.bias, %1163)\n",
      "  %1165 = Add(%1164, %1150)\n",
      "  %1166 = ReduceMean[axes = [-1]](%1165)\n",
      "  %1167 = Sub(%1165, %1166)\n",
      "  %1168 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1169 = Pow(%1167, %1168)\n",
      "  %1170 = ReduceMean[axes = [-1]](%1169)\n",
      "  %1171 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1172 = Add(%1170, %1171)\n",
      "  %1173 = Sqrt(%1172)\n",
      "  %1174 = Div(%1167, %1173)\n",
      "  %1175 = Mul(%1174, %basemodel.roberta.encoder.layer.7.output.LayerNorm.weight)\n",
      "  %1176 = Add(%1175, %basemodel.roberta.encoder.layer.7.output.LayerNorm.bias)\n",
      "  %1178 = MatMul(%1176, %1745)\n",
      "  %1179 = Add(%basemodel.roberta.encoder.layer.8.attention.self.query.bias, %1178)\n",
      "  %1181 = MatMul(%1176, %1746)\n",
      "  %1182 = Add(%basemodel.roberta.encoder.layer.8.attention.self.key.bias, %1181)\n",
      "  %1183 = Shape(%1182)\n",
      "  %1184 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1185 = Gather[axis = 0](%1183, %1184)\n",
      "  %1186 = Shape(%1182)\n",
      "  %1187 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1188 = Gather[axis = 0](%1186, %1187)\n",
      "  %1191 = Unsqueeze[axes = [0]](%1185)\n",
      "  %1192 = Unsqueeze[axes = [0]](%1188)\n",
      "  %1195 = Concat[axis = 0](%1191, %1192, %1747, %1748)\n",
      "  %1196 = Reshape(%1182, %1195)\n",
      "  %1198 = MatMul(%1176, %1749)\n",
      "  %1199 = Add(%basemodel.roberta.encoder.layer.8.attention.self.value.bias, %1198)\n",
      "  %1200 = Shape(%1199)\n",
      "  %1201 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1202 = Gather[axis = 0](%1200, %1201)\n",
      "  %1203 = Shape(%1199)\n",
      "  %1204 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1205 = Gather[axis = 0](%1203, %1204)\n",
      "  %1208 = Unsqueeze[axes = [0]](%1202)\n",
      "  %1209 = Unsqueeze[axes = [0]](%1205)\n",
      "  %1212 = Concat[axis = 0](%1208, %1209, %1750, %1751)\n",
      "  %1213 = Reshape(%1199, %1212)\n",
      "  %1214 = Transpose[perm = [0, 2, 1, 3]](%1213)\n",
      "  %1215 = Shape(%1179)\n",
      "  %1216 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1217 = Gather[axis = 0](%1215, %1216)\n",
      "  %1218 = Shape(%1179)\n",
      "  %1219 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1220 = Gather[axis = 0](%1218, %1219)\n",
      "  %1223 = Unsqueeze[axes = [0]](%1217)\n",
      "  %1224 = Unsqueeze[axes = [0]](%1220)\n",
      "  %1227 = Concat[axis = 0](%1223, %1224, %1752, %1753)\n",
      "  %1228 = Reshape(%1179, %1227)\n",
      "  %1229 = Transpose[perm = [0, 2, 1, 3]](%1228)\n",
      "  %1230 = Transpose[perm = [0, 2, 3, 1]](%1196)\n",
      "  %1231 = MatMul(%1229, %1230)\n",
      "  %1232 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1233 = Div(%1231, %1232)\n",
      "  %1234 = Add(%1233, %236)\n",
      "  %1235 = Softmax[axis = 3](%1234)\n",
      "  %1236 = MatMul(%1235, %1214)\n",
      "  %1237 = Transpose[perm = [0, 2, 1, 3]](%1236)\n",
      "  %1238 = Shape(%1237)\n",
      "  %1239 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1240 = Gather[axis = 0](%1238, %1239)\n",
      "  %1241 = Shape(%1237)\n",
      "  %1242 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1243 = Gather[axis = 0](%1241, %1242)\n",
      "  %1245 = Unsqueeze[axes = [0]](%1240)\n",
      "  %1246 = Unsqueeze[axes = [0]](%1243)\n",
      "  %1248 = Concat[axis = 0](%1245, %1246, %1754)\n",
      "  %1249 = Reshape(%1237, %1248)\n",
      "  %1251 = MatMul(%1249, %1755)\n",
      "  %1252 = Add(%basemodel.roberta.encoder.layer.8.attention.output.dense.bias, %1251)\n",
      "  %1253 = Add(%1252, %1176)\n",
      "  %1254 = ReduceMean[axes = [-1]](%1253)\n",
      "  %1255 = Sub(%1253, %1254)\n",
      "  %1256 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1257 = Pow(%1255, %1256)\n",
      "  %1258 = ReduceMean[axes = [-1]](%1257)\n",
      "  %1259 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1260 = Add(%1258, %1259)\n",
      "  %1261 = Sqrt(%1260)\n",
      "  %1262 = Div(%1255, %1261)\n",
      "  %1263 = Mul(%1262, %basemodel.roberta.encoder.layer.8.attention.output.LayerNorm.weight)\n",
      "  %1264 = Add(%1263, %basemodel.roberta.encoder.layer.8.attention.output.LayerNorm.bias)\n",
      "  %1266 = MatMul(%1264, %1756)\n",
      "  %1267 = Add(%basemodel.roberta.encoder.layer.8.intermediate.dense.bias, %1266)\n",
      "  %1268 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1269 = Div(%1267, %1268)\n",
      "  %1270 = Erf(%1269)\n",
      "  %1271 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1272 = Add(%1270, %1271)\n",
      "  %1273 = Mul(%1267, %1272)\n",
      "  %1274 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1275 = Mul(%1273, %1274)\n",
      "  %1277 = MatMul(%1275, %1757)\n",
      "  %1278 = Add(%basemodel.roberta.encoder.layer.8.output.dense.bias, %1277)\n",
      "  %1279 = Add(%1278, %1264)\n",
      "  %1280 = ReduceMean[axes = [-1]](%1279)\n",
      "  %1281 = Sub(%1279, %1280)\n",
      "  %1282 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1283 = Pow(%1281, %1282)\n",
      "  %1284 = ReduceMean[axes = [-1]](%1283)\n",
      "  %1285 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1286 = Add(%1284, %1285)\n",
      "  %1287 = Sqrt(%1286)\n",
      "  %1288 = Div(%1281, %1287)\n",
      "  %1289 = Mul(%1288, %basemodel.roberta.encoder.layer.8.output.LayerNorm.weight)\n",
      "  %1290 = Add(%1289, %basemodel.roberta.encoder.layer.8.output.LayerNorm.bias)\n",
      "  %1292 = MatMul(%1290, %1758)\n",
      "  %1293 = Add(%basemodel.roberta.encoder.layer.9.attention.self.query.bias, %1292)\n",
      "  %1295 = MatMul(%1290, %1759)\n",
      "  %1296 = Add(%basemodel.roberta.encoder.layer.9.attention.self.key.bias, %1295)\n",
      "  %1297 = Shape(%1296)\n",
      "  %1298 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1299 = Gather[axis = 0](%1297, %1298)\n",
      "  %1300 = Shape(%1296)\n",
      "  %1301 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1302 = Gather[axis = 0](%1300, %1301)\n",
      "  %1305 = Unsqueeze[axes = [0]](%1299)\n",
      "  %1306 = Unsqueeze[axes = [0]](%1302)\n",
      "  %1309 = Concat[axis = 0](%1305, %1306, %1760, %1761)\n",
      "  %1310 = Reshape(%1296, %1309)\n",
      "  %1312 = MatMul(%1290, %1762)\n",
      "  %1313 = Add(%basemodel.roberta.encoder.layer.9.attention.self.value.bias, %1312)\n",
      "  %1314 = Shape(%1313)\n",
      "  %1315 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1316 = Gather[axis = 0](%1314, %1315)\n",
      "  %1317 = Shape(%1313)\n",
      "  %1318 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1319 = Gather[axis = 0](%1317, %1318)\n",
      "  %1322 = Unsqueeze[axes = [0]](%1316)\n",
      "  %1323 = Unsqueeze[axes = [0]](%1319)\n",
      "  %1326 = Concat[axis = 0](%1322, %1323, %1763, %1764)\n",
      "  %1327 = Reshape(%1313, %1326)\n",
      "  %1328 = Transpose[perm = [0, 2, 1, 3]](%1327)\n",
      "  %1329 = Shape(%1293)\n",
      "  %1330 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1331 = Gather[axis = 0](%1329, %1330)\n",
      "  %1332 = Shape(%1293)\n",
      "  %1333 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1334 = Gather[axis = 0](%1332, %1333)\n",
      "  %1337 = Unsqueeze[axes = [0]](%1331)\n",
      "  %1338 = Unsqueeze[axes = [0]](%1334)\n",
      "  %1341 = Concat[axis = 0](%1337, %1338, %1765, %1766)\n",
      "  %1342 = Reshape(%1293, %1341)\n",
      "  %1343 = Transpose[perm = [0, 2, 1, 3]](%1342)\n",
      "  %1344 = Transpose[perm = [0, 2, 3, 1]](%1310)\n",
      "  %1345 = MatMul(%1343, %1344)\n",
      "  %1346 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1347 = Div(%1345, %1346)\n",
      "  %1348 = Add(%1347, %236)\n",
      "  %1349 = Softmax[axis = 3](%1348)\n",
      "  %1350 = MatMul(%1349, %1328)\n",
      "  %1351 = Transpose[perm = [0, 2, 1, 3]](%1350)\n",
      "  %1352 = Shape(%1351)\n",
      "  %1353 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1354 = Gather[axis = 0](%1352, %1353)\n",
      "  %1355 = Shape(%1351)\n",
      "  %1356 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1357 = Gather[axis = 0](%1355, %1356)\n",
      "  %1359 = Unsqueeze[axes = [0]](%1354)\n",
      "  %1360 = Unsqueeze[axes = [0]](%1357)\n",
      "  %1362 = Concat[axis = 0](%1359, %1360, %1767)\n",
      "  %1363 = Reshape(%1351, %1362)\n",
      "  %1365 = MatMul(%1363, %1768)\n",
      "  %1366 = Add(%basemodel.roberta.encoder.layer.9.attention.output.dense.bias, %1365)\n",
      "  %1367 = Add(%1366, %1290)\n",
      "  %1368 = ReduceMean[axes = [-1]](%1367)\n",
      "  %1369 = Sub(%1367, %1368)\n",
      "  %1370 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1371 = Pow(%1369, %1370)\n",
      "  %1372 = ReduceMean[axes = [-1]](%1371)\n",
      "  %1373 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1374 = Add(%1372, %1373)\n",
      "  %1375 = Sqrt(%1374)\n",
      "  %1376 = Div(%1369, %1375)\n",
      "  %1377 = Mul(%1376, %basemodel.roberta.encoder.layer.9.attention.output.LayerNorm.weight)\n",
      "  %1378 = Add(%1377, %basemodel.roberta.encoder.layer.9.attention.output.LayerNorm.bias)\n",
      "  %1380 = MatMul(%1378, %1769)\n",
      "  %1381 = Add(%basemodel.roberta.encoder.layer.9.intermediate.dense.bias, %1380)\n",
      "  %1382 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1383 = Div(%1381, %1382)\n",
      "  %1384 = Erf(%1383)\n",
      "  %1385 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1386 = Add(%1384, %1385)\n",
      "  %1387 = Mul(%1381, %1386)\n",
      "  %1388 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1389 = Mul(%1387, %1388)\n",
      "  %1391 = MatMul(%1389, %1770)\n",
      "  %1392 = Add(%basemodel.roberta.encoder.layer.9.output.dense.bias, %1391)\n",
      "  %1393 = Add(%1392, %1378)\n",
      "  %1394 = ReduceMean[axes = [-1]](%1393)\n",
      "  %1395 = Sub(%1393, %1394)\n",
      "  %1396 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1397 = Pow(%1395, %1396)\n",
      "  %1398 = ReduceMean[axes = [-1]](%1397)\n",
      "  %1399 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1400 = Add(%1398, %1399)\n",
      "  %1401 = Sqrt(%1400)\n",
      "  %1402 = Div(%1395, %1401)\n",
      "  %1403 = Mul(%1402, %basemodel.roberta.encoder.layer.9.output.LayerNorm.weight)\n",
      "  %1404 = Add(%1403, %basemodel.roberta.encoder.layer.9.output.LayerNorm.bias)\n",
      "  %1406 = MatMul(%1404, %1771)\n",
      "  %1407 = Add(%basemodel.roberta.encoder.layer.10.attention.self.query.bias, %1406)\n",
      "  %1409 = MatMul(%1404, %1772)\n",
      "  %1410 = Add(%basemodel.roberta.encoder.layer.10.attention.self.key.bias, %1409)\n",
      "  %1411 = Shape(%1410)\n",
      "  %1412 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1413 = Gather[axis = 0](%1411, %1412)\n",
      "  %1414 = Shape(%1410)\n",
      "  %1415 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1416 = Gather[axis = 0](%1414, %1415)\n",
      "  %1419 = Unsqueeze[axes = [0]](%1413)\n",
      "  %1420 = Unsqueeze[axes = [0]](%1416)\n",
      "  %1423 = Concat[axis = 0](%1419, %1420, %1773, %1774)\n",
      "  %1424 = Reshape(%1410, %1423)\n",
      "  %1426 = MatMul(%1404, %1775)\n",
      "  %1427 = Add(%basemodel.roberta.encoder.layer.10.attention.self.value.bias, %1426)\n",
      "  %1428 = Shape(%1427)\n",
      "  %1429 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1430 = Gather[axis = 0](%1428, %1429)\n",
      "  %1431 = Shape(%1427)\n",
      "  %1432 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1433 = Gather[axis = 0](%1431, %1432)\n",
      "  %1436 = Unsqueeze[axes = [0]](%1430)\n",
      "  %1437 = Unsqueeze[axes = [0]](%1433)\n",
      "  %1440 = Concat[axis = 0](%1436, %1437, %1776, %1777)\n",
      "  %1441 = Reshape(%1427, %1440)\n",
      "  %1442 = Transpose[perm = [0, 2, 1, 3]](%1441)\n",
      "  %1443 = Shape(%1407)\n",
      "  %1444 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1445 = Gather[axis = 0](%1443, %1444)\n",
      "  %1446 = Shape(%1407)\n",
      "  %1447 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1448 = Gather[axis = 0](%1446, %1447)\n",
      "  %1451 = Unsqueeze[axes = [0]](%1445)\n",
      "  %1452 = Unsqueeze[axes = [0]](%1448)\n",
      "  %1455 = Concat[axis = 0](%1451, %1452, %1778, %1779)\n",
      "  %1456 = Reshape(%1407, %1455)\n",
      "  %1457 = Transpose[perm = [0, 2, 1, 3]](%1456)\n",
      "  %1458 = Transpose[perm = [0, 2, 3, 1]](%1424)\n",
      "  %1459 = MatMul(%1457, %1458)\n",
      "  %1460 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1461 = Div(%1459, %1460)\n",
      "  %1462 = Add(%1461, %236)\n",
      "  %1463 = Softmax[axis = 3](%1462)\n",
      "  %1464 = MatMul(%1463, %1442)\n",
      "  %1465 = Transpose[perm = [0, 2, 1, 3]](%1464)\n",
      "  %1466 = Shape(%1465)\n",
      "  %1467 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1468 = Gather[axis = 0](%1466, %1467)\n",
      "  %1469 = Shape(%1465)\n",
      "  %1470 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1471 = Gather[axis = 0](%1469, %1470)\n",
      "  %1473 = Unsqueeze[axes = [0]](%1468)\n",
      "  %1474 = Unsqueeze[axes = [0]](%1471)\n",
      "  %1476 = Concat[axis = 0](%1473, %1474, %1780)\n",
      "  %1477 = Reshape(%1465, %1476)\n",
      "  %1479 = MatMul(%1477, %1781)\n",
      "  %1480 = Add(%basemodel.roberta.encoder.layer.10.attention.output.dense.bias, %1479)\n",
      "  %1481 = Add(%1480, %1404)\n",
      "  %1482 = ReduceMean[axes = [-1]](%1481)\n",
      "  %1483 = Sub(%1481, %1482)\n",
      "  %1484 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1485 = Pow(%1483, %1484)\n",
      "  %1486 = ReduceMean[axes = [-1]](%1485)\n",
      "  %1487 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1488 = Add(%1486, %1487)\n",
      "  %1489 = Sqrt(%1488)\n",
      "  %1490 = Div(%1483, %1489)\n",
      "  %1491 = Mul(%1490, %basemodel.roberta.encoder.layer.10.attention.output.LayerNorm.weight)\n",
      "  %1492 = Add(%1491, %basemodel.roberta.encoder.layer.10.attention.output.LayerNorm.bias)\n",
      "  %1494 = MatMul(%1492, %1782)\n",
      "  %1495 = Add(%basemodel.roberta.encoder.layer.10.intermediate.dense.bias, %1494)\n",
      "  %1496 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1497 = Div(%1495, %1496)\n",
      "  %1498 = Erf(%1497)\n",
      "  %1499 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1500 = Add(%1498, %1499)\n",
      "  %1501 = Mul(%1495, %1500)\n",
      "  %1502 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1503 = Mul(%1501, %1502)\n",
      "  %1505 = MatMul(%1503, %1783)\n",
      "  %1506 = Add(%basemodel.roberta.encoder.layer.10.output.dense.bias, %1505)\n",
      "  %1507 = Add(%1506, %1492)\n",
      "  %1508 = ReduceMean[axes = [-1]](%1507)\n",
      "  %1509 = Sub(%1507, %1508)\n",
      "  %1510 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1511 = Pow(%1509, %1510)\n",
      "  %1512 = ReduceMean[axes = [-1]](%1511)\n",
      "  %1513 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1514 = Add(%1512, %1513)\n",
      "  %1515 = Sqrt(%1514)\n",
      "  %1516 = Div(%1509, %1515)\n",
      "  %1517 = Mul(%1516, %basemodel.roberta.encoder.layer.10.output.LayerNorm.weight)\n",
      "  %1518 = Add(%1517, %basemodel.roberta.encoder.layer.10.output.LayerNorm.bias)\n",
      "  %1520 = MatMul(%1518, %1784)\n",
      "  %1521 = Add(%basemodel.roberta.encoder.layer.11.attention.self.query.bias, %1520)\n",
      "  %1523 = MatMul(%1518, %1785)\n",
      "  %1524 = Add(%basemodel.roberta.encoder.layer.11.attention.self.key.bias, %1523)\n",
      "  %1525 = Shape(%1524)\n",
      "  %1526 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1527 = Gather[axis = 0](%1525, %1526)\n",
      "  %1528 = Shape(%1524)\n",
      "  %1529 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1530 = Gather[axis = 0](%1528, %1529)\n",
      "  %1533 = Unsqueeze[axes = [0]](%1527)\n",
      "  %1534 = Unsqueeze[axes = [0]](%1530)\n",
      "  %1537 = Concat[axis = 0](%1533, %1534, %1786, %1787)\n",
      "  %1538 = Reshape(%1524, %1537)\n",
      "  %1540 = MatMul(%1518, %1788)\n",
      "  %1541 = Add(%basemodel.roberta.encoder.layer.11.attention.self.value.bias, %1540)\n",
      "  %1542 = Shape(%1541)\n",
      "  %1543 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1544 = Gather[axis = 0](%1542, %1543)\n",
      "  %1545 = Shape(%1541)\n",
      "  %1546 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1547 = Gather[axis = 0](%1545, %1546)\n",
      "  %1550 = Unsqueeze[axes = [0]](%1544)\n",
      "  %1551 = Unsqueeze[axes = [0]](%1547)\n",
      "  %1554 = Concat[axis = 0](%1550, %1551, %1789, %1790)\n",
      "  %1555 = Reshape(%1541, %1554)\n",
      "  %1556 = Transpose[perm = [0, 2, 1, 3]](%1555)\n",
      "  %1557 = Shape(%1521)\n",
      "  %1558 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1559 = Gather[axis = 0](%1557, %1558)\n",
      "  %1560 = Shape(%1521)\n",
      "  %1561 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1562 = Gather[axis = 0](%1560, %1561)\n",
      "  %1565 = Unsqueeze[axes = [0]](%1559)\n",
      "  %1566 = Unsqueeze[axes = [0]](%1562)\n",
      "  %1569 = Concat[axis = 0](%1565, %1566, %1791, %1792)\n",
      "  %1570 = Reshape(%1521, %1569)\n",
      "  %1571 = Transpose[perm = [0, 2, 1, 3]](%1570)\n",
      "  %1572 = Transpose[perm = [0, 2, 3, 1]](%1538)\n",
      "  %1573 = MatMul(%1571, %1572)\n",
      "  %1574 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1575 = Div(%1573, %1574)\n",
      "  %1576 = Add(%1575, %236)\n",
      "  %1577 = Softmax[axis = 3](%1576)\n",
      "  %1578 = MatMul(%1577, %1556)\n",
      "  %1579 = Transpose[perm = [0, 2, 1, 3]](%1578)\n",
      "  %1580 = Shape(%1579)\n",
      "  %1581 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1582 = Gather[axis = 0](%1580, %1581)\n",
      "  %1583 = Shape(%1579)\n",
      "  %1584 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1585 = Gather[axis = 0](%1583, %1584)\n",
      "  %1587 = Unsqueeze[axes = [0]](%1582)\n",
      "  %1588 = Unsqueeze[axes = [0]](%1585)\n",
      "  %1590 = Concat[axis = 0](%1587, %1588, %1793)\n",
      "  %1591 = Reshape(%1579, %1590)\n",
      "  %1593 = MatMul(%1591, %1794)\n",
      "  %1594 = Add(%basemodel.roberta.encoder.layer.11.attention.output.dense.bias, %1593)\n",
      "  %1595 = Add(%1594, %1518)\n",
      "  %1596 = ReduceMean[axes = [-1]](%1595)\n",
      "  %1597 = Sub(%1595, %1596)\n",
      "  %1598 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1599 = Pow(%1597, %1598)\n",
      "  %1600 = ReduceMean[axes = [-1]](%1599)\n",
      "  %1601 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1602 = Add(%1600, %1601)\n",
      "  %1603 = Sqrt(%1602)\n",
      "  %1604 = Div(%1597, %1603)\n",
      "  %1605 = Mul(%1604, %basemodel.roberta.encoder.layer.11.attention.output.LayerNorm.weight)\n",
      "  %1606 = Add(%1605, %basemodel.roberta.encoder.layer.11.attention.output.LayerNorm.bias)\n",
      "  %1608 = MatMul(%1606, %1795)\n",
      "  %1609 = Add(%basemodel.roberta.encoder.layer.11.intermediate.dense.bias, %1608)\n",
      "  %1610 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1611 = Div(%1609, %1610)\n",
      "  %1612 = Erf(%1611)\n",
      "  %1613 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1614 = Add(%1612, %1613)\n",
      "  %1615 = Mul(%1609, %1614)\n",
      "  %1616 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1617 = Mul(%1615, %1616)\n",
      "  %1619 = MatMul(%1617, %1796)\n",
      "  %1620 = Add(%basemodel.roberta.encoder.layer.11.output.dense.bias, %1619)\n",
      "  %1621 = Add(%1620, %1606)\n",
      "  %1622 = ReduceMean[axes = [-1]](%1621)\n",
      "  %1623 = Sub(%1621, %1622)\n",
      "  %1624 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1625 = Pow(%1623, %1624)\n",
      "  %1626 = ReduceMean[axes = [-1]](%1625)\n",
      "  %1627 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1628 = Add(%1626, %1627)\n",
      "  %1629 = Sqrt(%1628)\n",
      "  %1630 = Div(%1623, %1629)\n",
      "  %1631 = Mul(%1630, %basemodel.roberta.encoder.layer.11.output.LayerNorm.weight)\n",
      "  %1632 = Add(%1631, %basemodel.roberta.encoder.layer.11.output.LayerNorm.bias)\n",
      "  %1633 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1634 = Gather[axis = 1](%1632, %1633)\n",
      "  %1635 = Gemm[alpha = 1, beta = 1, transB = 1](%1634, %basemodel.classifier.dense.weight, %basemodel.classifier.dense.bias)\n",
      "  %1636 = Tanh(%1635)\n",
      "  %1637 = Gemm[alpha = 1, beta = 1, transB = 1](%1636, %basemodel.classifier.out_proj.weight, %basemodel.classifier.out_proj.bias)\n",
      "  %output_0 = Softmax[axis = 1](%1637)\n",
      "  return %output_0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model2 = onnx.load(\"/root/autodl-nas/export_models/absa/charger-category-lb73-f61-0713.onnx\")\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(model2)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model2.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb6cb0-7287-4f70-ad1f-e83633add418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
