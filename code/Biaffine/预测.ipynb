{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8ee4b2-3c7b-437f-94f0-8a7c18ff443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cfba5d4-4514-4c76-b55b-fcd728d7ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biaffine import BiaffineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f747a8ef-de89-4ce9-8bff-951967b93f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self, *initial_data, **kwargs):\n",
    "        for dictionary in initial_data:\n",
    "            for key in dictionary:\n",
    "                setattr(self, key, dictionary[key])\n",
    "        for key in kwargs:\n",
    "            setattr(self, key, kwargs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3fa8c8-36be-4ad5-8a0b-8a52ad9ac6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(bert_model_path='/root/autodl-nas/pretrain-models/roberta-base',bert_feature_dim=768,biaffine_size=300,class_num=8,max_sequence_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cac71e7-3fa7-4b6d-8252-da59f4e34f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /root/autodl-nas/pretrain-models/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BiaffineModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0606f84-b03f-4d88-89fb-54db33ab54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc4cdb37-f3c7-45f6-a594-53230af8c3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('savemodel/triplet_v11.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91620652-a66a-49c7-bfd2-d66b4b4ed6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4055ea30-88a6-48d4-ab0d-92a26f03675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3818e0c4-0d05-4499-a8fe-67225edb8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c73b4f0c-1aac-43fd-b5f8-88aa9305bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.bert_model_path,add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc72027-cd48-4ad2-a669-0149eaffbf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(text):\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = ['##'] + tokens\n",
    "    sen_length = len(tokens)\n",
    "    token_range = []\n",
    "    bert_tokens = tokenizer.encode(tokens,is_split_into_words=True)\n",
    "    length = len(bert_tokens)\n",
    "    bert_tokens_padding = torch.zeros(args.max_sequence_len).long()\n",
    "    mask = torch.zeros(args.max_sequence_len).long()\n",
    "\n",
    "    for i in range(length):\n",
    "        bert_tokens_padding[i] = bert_tokens[i]\n",
    "    mask[:length] = 1\n",
    "\n",
    "    token_start = 1\n",
    "    for i, w, in enumerate(tokens):\n",
    "        token_end = token_start + len(tokenizer.encode(w, add_special_tokens=False))\n",
    "        token_range.append([token_start, token_end-1])\n",
    "        token_start = token_end\n",
    "    assert length == token_range[-1][-1]+2\n",
    "    return bert_tokens_padding,mask,token_range,sen_length,tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc263045-f02e-49af-8048-836c1f873900",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokens_padding,mask,token_range,sen_length,tokens = convert('But when I plugged in my MacBook Pro 13\" M1 (A2338), my Mac saw power, but it would not charge the battery at all, ever. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "13c673c0-1db7-4087-8267-67777a1cd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_tokens_padding,mask,token_range,sen_length,tokens = convert('Good. Shangjin is cool! Shangjin is awsome!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7a56afe-2ae1-4809-8477-184c59192031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens_padding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b98806c1-fb32-4b59-a413-e4d2bc463685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eff04e1-f59d-4620-ae64-72b946e0c7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 47385,    53,    77,   939, 30251,    11,   127, 13418,  6298,\n",
       "         1759,   508, 12801,   475,   134,    36,    10,  1922,  3170,  4839,\n",
       "         2156,   127, 13418,   794,   476,  2156,    53,    24,    74,    45,\n",
       "         1427,     5,  3822,    23,    70,  2156,   655,   479,     2,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens_padding\n",
    "# tokens\n",
    "# mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87f0050c-a40e-4b10-90e1-59d8144c459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(bert_tokens_padding.unsqueeze(0), mask.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f889be2f-379b-4f06-aba3-30292db7fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(preds, dim=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90ef208e-1117-49c8-a676-424cc884f5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0,  ..., 0, 0, 0],\n",
       "        [0, 1, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2637db66-75ae-4d56-a0cf-d5ac596abb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASPECT_BEGIN=1\n",
    "ASPECT_IN=2\n",
    "OPINION_BEGIN=3\n",
    "OPINION_IN=4\n",
    "PAIR=5\n",
    "sentiment2id = {'观点-负面': 5, '观点-中性':6, '观点-正面': 7}\n",
    "\n",
    "ASPECT=[ASPECT_BEGIN,ASPECT_IN]\n",
    "OPINION=[OPINION_BEGIN,OPINION_IN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "983e74dc-46a7-4afd-b55d-e3aac5e1642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2sentiment = {v:k for k,v in sentiment2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "907c593d-e4f0-4313-8de1-c267591bd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(tags, length, token_range, type):\n",
    "    spans = []\n",
    "    start = -1\n",
    "    begin,mid = type\n",
    "    for i in range(length):\n",
    "        l, r = token_range[i]\n",
    "        if tags[l][l] == -1:\n",
    "            continue\n",
    "        elif tags[l][l] == begin:\n",
    "            if start != -1:\n",
    "                spans.append([start, i - 1])\n",
    "            start = i\n",
    "        elif tags[l][l] not in type:\n",
    "            if start != -1:\n",
    "                spans.append([start, i - 1])\n",
    "                start = -1\n",
    "    if start != -1:\n",
    "        spans.append([start, length - 1])\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab51c110-6bf1-4bb6-84b0-2f476d18ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_triplet(tags, aspect_spans, opinion_spans, token_ranges):\n",
    "    triplets = []\n",
    "    for al, ar in aspect_spans:\n",
    "        for pl, pr in opinion_spans:\n",
    "            tag_num = [0] * 8\n",
    "            for i in range(al, ar + 1):\n",
    "                for j in range(pl, pr + 1):\n",
    "                    a_start = token_ranges[i][0]\n",
    "                    o_start = token_ranges[j][0]\n",
    "                    if al < pl:\n",
    "                        tag_num[int(tags[a_start][o_start])] += 1\n",
    "                    else:\n",
    "                        tag_num[int(tags[o_start][a_start])] += 1\n",
    "\n",
    "            if sum(tag_num[5:]) == 0: continue\n",
    "            sentiment = -1\n",
    "            if tag_num[5] >= tag_num[6] and tag_num[5] >= tag_num[7]:\n",
    "                sentiment = 5\n",
    "            elif tag_num[6] >= tag_num[5] and tag_num[6] >= tag_num[7]:\n",
    "                sentiment = 6\n",
    "            elif tag_num[7] >= tag_num[5] and tag_num[7] >= tag_num[6]:\n",
    "                sentiment = 7\n",
    "            if sentiment == -1:\n",
    "                continue\n",
    "            triplets.append([al, ar, pl, pr, sentiment])\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "205f6da1-d878-4798-a16a-e5eb2b27f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_aspect_spans = get_spans(preds, sen_length, token_range, ASPECT)\n",
    "predicted_opinion_spans = get_spans(preds, sen_length, token_range, OPINION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69073862-bbb3-421c-875e-af17b343d973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 0]], [[23, 27]], 33)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_aspect_spans,predicted_opinion_spans, sen_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3201bc4-f4b4-4fe6-8173-a16f4d9a13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = find_triplet(preds, predicted_aspect_spans,predicted_opinion_spans,token_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d53514f3-e3e7-44a6-84d5-7d9925ad27e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 23, 27, 5]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7923cb9-b28f-45b9-91b5-7aff5095472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('##', 'would not charge the battery', '观点-负面')\n"
     ]
    }
   ],
   "source": [
    "for al,ar,pl,pr,sentiment in triplets:\n",
    "    aspect = ' '.join(tokens[al:ar+1])\n",
    "    opinion = ' '.join(tokens[pl:pr+1])\n",
    "    sentiment = id2sentiment[sentiment]\n",
    "    print((aspect,opinion,sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add64bf7-d70f-439c-82ce-a4b2c8b37aa2",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc7c9e10-c818-49da-91e6-c79bb5b8d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"gts-absa-v11\"\n",
    "save_path=\"/root/autodl-nas/export_models/absa/\"\n",
    "max_length=128\n",
    "opset_version=14\n",
    "export_model_path=f\"{save_path}/{model_id}.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49cea113-a244-4912-95de-939d04961eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from psutil import cpu_count\n",
    "\n",
    "# Constants from the performance optimization available in onnxruntime\n",
    "# It needs to be done before importing onnxruntime\n",
    "environ[\"OMP_NUM_THREADS\"] = str(cpu_count(logical=True))\n",
    "environ[\"OMP_WAIT_POLICY\"] = 'ACTIVE'\n",
    "\n",
    "from onnxruntime import GraphOptimizationLevel, InferenceSession, SessionOptions, get_all_providers\n",
    "\n",
    "class OnnxModel:\n",
    "    def __init__(self, model_path: str, provider: str):\n",
    "        assert provider in get_all_providers(), f\"provider {provider} not found, {get_all_providers()}\"\n",
    "        self.options = self._set_options()\n",
    "        self.model=InferenceSession(model_path, self.options, providers=[provider])\n",
    "        # Load the model as a graph and prepare the CPU backend \n",
    "        self.model.disable_fallback()\n",
    "\n",
    "    def __call__(self, input):\n",
    "        return self.model.run(None, input)[0]\n",
    "  \n",
    "    def _set_options(self):\n",
    "        # Few properties that might have an impact on performances (provided by MS)\n",
    "        options = SessionOptions()\n",
    "        options.intra_op_num_threads = 1\n",
    "        options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "        return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "502c65b7-3b71-440d-995a-7bc646ec1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLC(torch.nn.Module):\n",
    "    def __init__(self, basemodel):\n",
    "        super().__init__()\n",
    "        self.basemodel = basemodel\n",
    "\n",
    "    def forward(self, input_ids,attention_mask):\n",
    "        outputs = self.basemodel(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        logits = outputs\n",
    "        return torch.reshape(torch.argmax(logits,dim=3),(-1,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5cad4f1-4dce-4083-9aa5-e0568896241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc = MLC(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e9f531e-92ac-425d-84e0-a350036eea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase={'input_ids':bert_tokens_padding.unsqueeze(0), \"attention_mask\":mask.unsqueeze(0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "184f3214-efc7-4d08-b388-8755758bf9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mlc(**paraphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e224cd4e-18f9-4671-9e24-ece31c389ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created input_names:\n",
      "['input_ids', 'attention_mask']\n",
      "created output_names:\n",
      "['output_0']\n",
      "created dynamic_axes:\n",
      "{'input_ids': {0: 'batch_size'}, 'attention_mask': {0: 'batch_size'}, 'output_0': {0: 'batch_size'}}\n"
     ]
    }
   ],
   "source": [
    "# generate input and output names/keys\n",
    "input_names = list(paraphrase.keys())\n",
    "output_names = [\"output_0\"]\n",
    "\n",
    "# Generate dynamic axes, with batching -> inputs/outputs with potential dynamic shape\n",
    "symbolic_names = {0: 'batch_size'} #TODO: Exaplain\n",
    "\n",
    "input_dynamic_axes = {input_key: symbolic_names for input_key in input_names}\n",
    "output_dynamic_axes = {output_key: {0: 'batch_size'} for output_key in output_names}\n",
    "dynamic_axes = dict(input_dynamic_axes, **output_dynamic_axes)\n",
    "\n",
    "print(f\"created input_names:\")\n",
    "print(input_names)\n",
    "print(f\"created output_names:\")\n",
    "print(output_names)\n",
    "print(f\"created dynamic_axes:\")\n",
    "print(dynamic_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b63583e-8d31-453d-bad5-4300f2e4b258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': {0: 'batch_size'},\n",
       " 'attention_mask': {0: 'batch_size'},\n",
       " 'output_0': {0: 'batch_size'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0201b1d0-c940-4597-85d1-44de453fce65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py:716: UserWarning: allowzero=0 by default. In order to honor zero value in shape use allowzero=1\n",
      "  warnings.warn(\"allowzero=0 by default. In order to honor zero value in shape use allowzero=1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported at  /root/autodl-nas/export_models/absa//gts-absa-v11.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "mlc.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(mlc,                               # model being run\n",
    "                      args=tuple(paraphrase.values()),     # model input (or a tuple for multiple inputs)\n",
    "                      f=export_model_path,                 # where to save the model (can be a file or file-like object)\n",
    "                      opset_version=14,         # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,            # whether to execute constant folding for optimization\n",
    "                      enable_onnx_checker=True, \n",
    "                      use_external_data_format=False,\n",
    "                      input_names=input_names,             # the model's input names  'input_ids', 'token_type_ids', 'attention_mask'\n",
    "                      output_names=output_names,           # the model's output names 'output_0'\n",
    "                      dynamic_axes=dynamic_axes)           # inputs/outputs with potential dynamic shape -> mostly all\n",
    "\n",
    "print(\"Model exported at \", export_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a28a383b-dd0e-4962-af0e-112ff8c826b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = \"CPUExecutionProvider\"\n",
    "onnx_model = OnnxModel(\"/root/autodl-nas/export_models/absa/gts-absa-v11.onnx\", provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90279a4c-7824-450a-a005-705242c5de9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_onnx = {k: v.cpu().detach().numpy() for k, v in paraphrase.items()}\n",
    "onnx_model(inputs_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02d6e4f1-15ae-4015-be98-60f1d68a998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %input_ids[INT64, batch_sizex128]\n",
      "  %attention_mask[INT64, batch_sizex128]\n",
      ") initializers (\n",
      "  %basemodel.bert.embeddings.word_embeddings.weight[FLOAT, 50265x768]\n",
      "  %basemodel.bert.embeddings.position_embeddings.weight[FLOAT, 514x768]\n",
      "  %basemodel.bert.embeddings.token_type_embeddings.weight[FLOAT, 1x768]\n",
      "  %basemodel.bert.embeddings.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.embeddings.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.0.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.0.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.0.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.0.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.0.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.0.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.0.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.0.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.0.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.0.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.1.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.1.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.1.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.1.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.1.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.1.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.1.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.1.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.1.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.1.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.2.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.2.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.2.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.2.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.2.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.2.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.2.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.2.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.2.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.2.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.3.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.3.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.3.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.3.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.3.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.3.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.3.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.3.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.3.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.3.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.4.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.4.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.4.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.4.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.4.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.4.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.4.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.4.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.4.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.4.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.5.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.5.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.5.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.5.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.5.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.5.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.5.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.5.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.5.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.5.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.6.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.6.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.6.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.6.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.6.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.6.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.6.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.6.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.6.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.6.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.7.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.7.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.7.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.7.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.7.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.7.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.7.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.7.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.7.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.7.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.8.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.8.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.8.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.8.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.8.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.8.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.8.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.8.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.8.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.8.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.9.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.9.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.9.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.9.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.9.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.9.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.9.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.9.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.9.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.9.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.10.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.10.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.10.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.10.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.10.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.10.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.10.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.10.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.10.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.10.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.11.attention.self.query.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.11.attention.self.key.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.11.attention.self.value.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.11.attention.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.11.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.11.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.11.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %basemodel.bert.encoder.layer.11.output.dense.bias[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.11.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %basemodel.bert.encoder.layer.11.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %basemodel.start.bias[FLOAT, 300]\n",
      "  %basemodel.end.bias[FLOAT, 300]\n",
      "  %1962[INT64, 1]\n",
      "  %1963[INT64, 1]\n",
      "  %1964[FLOAT, 768x768]\n",
      "  %1965[FLOAT, 768x768]\n",
      "  %1966[INT64, 1]\n",
      "  %1967[INT64, 1]\n",
      "  %1968[FLOAT, 768x768]\n",
      "  %1969[INT64, 1]\n",
      "  %1970[INT64, 1]\n",
      "  %1971[INT64, 1]\n",
      "  %1972[INT64, 1]\n",
      "  %1973[INT64, 1]\n",
      "  %1974[FLOAT, 768x768]\n",
      "  %1975[FLOAT, 768x3072]\n",
      "  %1976[FLOAT, 3072x768]\n",
      "  %1977[FLOAT, 768x768]\n",
      "  %1978[FLOAT, 768x768]\n",
      "  %1979[INT64, 1]\n",
      "  %1980[INT64, 1]\n",
      "  %1981[FLOAT, 768x768]\n",
      "  %1982[INT64, 1]\n",
      "  %1983[INT64, 1]\n",
      "  %1984[INT64, 1]\n",
      "  %1985[INT64, 1]\n",
      "  %1986[INT64, 1]\n",
      "  %1987[FLOAT, 768x768]\n",
      "  %1988[FLOAT, 768x3072]\n",
      "  %1989[FLOAT, 3072x768]\n",
      "  %1990[FLOAT, 768x768]\n",
      "  %1991[FLOAT, 768x768]\n",
      "  %1992[INT64, 1]\n",
      "  %1993[INT64, 1]\n",
      "  %1994[FLOAT, 768x768]\n",
      "  %1995[INT64, 1]\n",
      "  %1996[INT64, 1]\n",
      "  %1997[INT64, 1]\n",
      "  %1998[INT64, 1]\n",
      "  %1999[INT64, 1]\n",
      "  %2000[FLOAT, 768x768]\n",
      "  %2001[FLOAT, 768x3072]\n",
      "  %2002[FLOAT, 3072x768]\n",
      "  %2003[FLOAT, 768x768]\n",
      "  %2004[FLOAT, 768x768]\n",
      "  %2005[INT64, 1]\n",
      "  %2006[INT64, 1]\n",
      "  %2007[FLOAT, 768x768]\n",
      "  %2008[INT64, 1]\n",
      "  %2009[INT64, 1]\n",
      "  %2010[INT64, 1]\n",
      "  %2011[INT64, 1]\n",
      "  %2012[INT64, 1]\n",
      "  %2013[FLOAT, 768x768]\n",
      "  %2014[FLOAT, 768x3072]\n",
      "  %2015[FLOAT, 3072x768]\n",
      "  %2016[FLOAT, 768x768]\n",
      "  %2017[FLOAT, 768x768]\n",
      "  %2018[INT64, 1]\n",
      "  %2019[INT64, 1]\n",
      "  %2020[FLOAT, 768x768]\n",
      "  %2021[INT64, 1]\n",
      "  %2022[INT64, 1]\n",
      "  %2023[INT64, 1]\n",
      "  %2024[INT64, 1]\n",
      "  %2025[INT64, 1]\n",
      "  %2026[FLOAT, 768x768]\n",
      "  %2027[FLOAT, 768x3072]\n",
      "  %2028[FLOAT, 3072x768]\n",
      "  %2029[FLOAT, 768x768]\n",
      "  %2030[FLOAT, 768x768]\n",
      "  %2031[INT64, 1]\n",
      "  %2032[INT64, 1]\n",
      "  %2033[FLOAT, 768x768]\n",
      "  %2034[INT64, 1]\n",
      "  %2035[INT64, 1]\n",
      "  %2036[INT64, 1]\n",
      "  %2037[INT64, 1]\n",
      "  %2038[INT64, 1]\n",
      "  %2039[FLOAT, 768x768]\n",
      "  %2040[FLOAT, 768x3072]\n",
      "  %2041[FLOAT, 3072x768]\n",
      "  %2042[FLOAT, 768x768]\n",
      "  %2043[FLOAT, 768x768]\n",
      "  %2044[INT64, 1]\n",
      "  %2045[INT64, 1]\n",
      "  %2046[FLOAT, 768x768]\n",
      "  %2047[INT64, 1]\n",
      "  %2048[INT64, 1]\n",
      "  %2049[INT64, 1]\n",
      "  %2050[INT64, 1]\n",
      "  %2051[INT64, 1]\n",
      "  %2052[FLOAT, 768x768]\n",
      "  %2053[FLOAT, 768x3072]\n",
      "  %2054[FLOAT, 3072x768]\n",
      "  %2055[FLOAT, 768x768]\n",
      "  %2056[FLOAT, 768x768]\n",
      "  %2057[INT64, 1]\n",
      "  %2058[INT64, 1]\n",
      "  %2059[FLOAT, 768x768]\n",
      "  %2060[INT64, 1]\n",
      "  %2061[INT64, 1]\n",
      "  %2062[INT64, 1]\n",
      "  %2063[INT64, 1]\n",
      "  %2064[INT64, 1]\n",
      "  %2065[FLOAT, 768x768]\n",
      "  %2066[FLOAT, 768x3072]\n",
      "  %2067[FLOAT, 3072x768]\n",
      "  %2068[FLOAT, 768x768]\n",
      "  %2069[FLOAT, 768x768]\n",
      "  %2070[INT64, 1]\n",
      "  %2071[INT64, 1]\n",
      "  %2072[FLOAT, 768x768]\n",
      "  %2073[INT64, 1]\n",
      "  %2074[INT64, 1]\n",
      "  %2075[INT64, 1]\n",
      "  %2076[INT64, 1]\n",
      "  %2077[INT64, 1]\n",
      "  %2078[FLOAT, 768x768]\n",
      "  %2079[FLOAT, 768x3072]\n",
      "  %2080[FLOAT, 3072x768]\n",
      "  %2081[FLOAT, 768x768]\n",
      "  %2082[FLOAT, 768x768]\n",
      "  %2083[INT64, 1]\n",
      "  %2084[INT64, 1]\n",
      "  %2085[FLOAT, 768x768]\n",
      "  %2086[INT64, 1]\n",
      "  %2087[INT64, 1]\n",
      "  %2088[INT64, 1]\n",
      "  %2089[INT64, 1]\n",
      "  %2090[INT64, 1]\n",
      "  %2091[FLOAT, 768x768]\n",
      "  %2092[FLOAT, 768x3072]\n",
      "  %2093[FLOAT, 3072x768]\n",
      "  %2094[FLOAT, 768x768]\n",
      "  %2095[FLOAT, 768x768]\n",
      "  %2096[INT64, 1]\n",
      "  %2097[INT64, 1]\n",
      "  %2098[FLOAT, 768x768]\n",
      "  %2099[INT64, 1]\n",
      "  %2100[INT64, 1]\n",
      "  %2101[INT64, 1]\n",
      "  %2102[INT64, 1]\n",
      "  %2103[INT64, 1]\n",
      "  %2104[FLOAT, 768x768]\n",
      "  %2105[FLOAT, 768x3072]\n",
      "  %2106[FLOAT, 3072x768]\n",
      "  %2107[FLOAT, 768x768]\n",
      "  %2108[FLOAT, 768x768]\n",
      "  %2109[INT64, 1]\n",
      "  %2110[INT64, 1]\n",
      "  %2111[FLOAT, 768x768]\n",
      "  %2112[INT64, 1]\n",
      "  %2113[INT64, 1]\n",
      "  %2114[INT64, 1]\n",
      "  %2115[INT64, 1]\n",
      "  %2116[INT64, 1]\n",
      "  %2117[FLOAT, 768x768]\n",
      "  %2118[FLOAT, 768x3072]\n",
      "  %2119[FLOAT, 3072x768]\n",
      "  %2120[FLOAT, 768x300]\n",
      "  %2121[FLOAT, 768x300]\n",
      "  %2122[INT64, 1]\n",
      "  %2123[INT64, 1]\n",
      "  %2124[INT64, 1]\n",
      "  %2125[INT64, 1]\n",
      "  %2126[INT64, 1]\n",
      "  %2127[INT64, 1]\n",
      "  %2128[INT64, 1]\n",
      "  %2129[INT64, 1]\n",
      "  %2130[INT64, 1]\n",
      "  %2131[FLOAT, 301x2408]\n",
      "  %2132[INT64, 1]\n",
      ") {\n",
      "  %207 = Shape(%input_ids)\n",
      "  %208 = Constant[value = <Scalar Tensor []>]()\n",
      "  %209 = Gather[axis = 0](%207, %208)\n",
      "  %210 = Shape(%input_ids)\n",
      "  %211 = Constant[value = <Scalar Tensor []>]()\n",
      "  %212 = Gather[axis = 0](%210, %211)\n",
      "  %213 = Constant[value = <Tensor>]()\n",
      "  %218 = Constant[value = <Tensor>]()\n",
      "  %219 = Unsqueeze(%212, %218)\n",
      "  %222 = Constant[value = <Tensor>]()\n",
      "  %223 = Slice(%213, %1962, %219, %1963, %222)\n",
      "  %224 = Constant[value = <Tensor>]()\n",
      "  %225 = Unsqueeze(%209, %224)\n",
      "  %226 = Constant[value = <Tensor>]()\n",
      "  %227 = Unsqueeze(%212, %226)\n",
      "  %228 = Concat[axis = 0](%225, %227)\n",
      "  %229 = Constant[value = <Tensor>]()\n",
      "  %230 = Reshape[allowzero = 0](%228, %229)\n",
      "  %231 = Shape(%230)\n",
      "  %232 = ConstantOfShape[value = <Tensor>](%231)\n",
      "  %233 = Constant[value = <Scalar Tensor []>]()\n",
      "  %234 = Mul(%232, %233)\n",
      "  %235 = Equal(%230, %234)\n",
      "  %236 = Where(%235, %232, %230)\n",
      "  %237 = Expand(%223, %236)\n",
      "  %238 = Constant[value = <Tensor>]()\n",
      "  %239 = Unsqueeze(%attention_mask, %238)\n",
      "  %240 = Constant[value = <Tensor>]()\n",
      "  %241 = Unsqueeze(%239, %240)\n",
      "  %242 = Cast[to = 1](%241)\n",
      "  %243 = Constant[value = <Scalar Tensor []>]()\n",
      "  %244 = Sub(%243, %242)\n",
      "  %245 = Constant[value = <Scalar Tensor []>]()\n",
      "  %246 = Mul(%244, %245)\n",
      "  %247 = Constant[value = <Scalar Tensor []>]()\n",
      "  %248 = Equal(%input_ids, %247)\n",
      "  %249 = Not(%248)\n",
      "  %250 = Cast[to = 6](%249)\n",
      "  %251 = Constant[value = <Scalar Tensor []>]()\n",
      "  %252 = CumSum(%250, %251)\n",
      "  %253 = Constant[value = <Scalar Tensor []>]()\n",
      "  %254 = Add(%252, %253)\n",
      "  %255 = Mul(%254, %250)\n",
      "  %256 = Cast[to = 7](%255)\n",
      "  %257 = Constant[value = <Scalar Tensor []>]()\n",
      "  %258 = Add(%256, %257)\n",
      "  %259 = Gather(%basemodel.bert.embeddings.word_embeddings.weight, %input_ids)\n",
      "  %260 = Gather(%basemodel.bert.embeddings.token_type_embeddings.weight, %237)\n",
      "  %261 = Add(%259, %260)\n",
      "  %262 = Gather(%basemodel.bert.embeddings.position_embeddings.weight, %258)\n",
      "  %263 = Add(%261, %262)\n",
      "  %264 = ReduceMean[axes = [-1]](%263)\n",
      "  %265 = Sub(%263, %264)\n",
      "  %266 = Constant[value = <Scalar Tensor []>]()\n",
      "  %267 = Pow(%265, %266)\n",
      "  %268 = ReduceMean[axes = [-1]](%267)\n",
      "  %269 = Constant[value = <Scalar Tensor []>]()\n",
      "  %270 = Add(%268, %269)\n",
      "  %271 = Sqrt(%270)\n",
      "  %272 = Div(%265, %271)\n",
      "  %273 = Mul(%272, %basemodel.bert.embeddings.LayerNorm.weight)\n",
      "  %274 = Add(%273, %basemodel.bert.embeddings.LayerNorm.bias)\n",
      "  %276 = MatMul(%274, %1964)\n",
      "  %277 = Add(%basemodel.bert.encoder.layer.0.attention.self.query.bias, %276)\n",
      "  %279 = MatMul(%274, %1965)\n",
      "  %280 = Add(%basemodel.bert.encoder.layer.0.attention.self.key.bias, %279)\n",
      "  %281 = Shape(%280)\n",
      "  %282 = Constant[value = <Scalar Tensor []>]()\n",
      "  %283 = Gather[axis = 0](%281, %282)\n",
      "  %284 = Shape(%280)\n",
      "  %285 = Constant[value = <Scalar Tensor []>]()\n",
      "  %286 = Gather[axis = 0](%284, %285)\n",
      "  %289 = Constant[value = <Tensor>]()\n",
      "  %290 = Unsqueeze(%283, %289)\n",
      "  %291 = Constant[value = <Tensor>]()\n",
      "  %292 = Unsqueeze(%286, %291)\n",
      "  %297 = Concat[axis = 0](%290, %292, %1966, %1967)\n",
      "  %298 = Reshape[allowzero = 0](%280, %297)\n",
      "  %300 = MatMul(%274, %1968)\n",
      "  %301 = Add(%basemodel.bert.encoder.layer.0.attention.self.value.bias, %300)\n",
      "  %302 = Shape(%301)\n",
      "  %303 = Constant[value = <Scalar Tensor []>]()\n",
      "  %304 = Gather[axis = 0](%302, %303)\n",
      "  %305 = Shape(%301)\n",
      "  %306 = Constant[value = <Scalar Tensor []>]()\n",
      "  %307 = Gather[axis = 0](%305, %306)\n",
      "  %310 = Constant[value = <Tensor>]()\n",
      "  %311 = Unsqueeze(%304, %310)\n",
      "  %312 = Constant[value = <Tensor>]()\n",
      "  %313 = Unsqueeze(%307, %312)\n",
      "  %318 = Concat[axis = 0](%311, %313, %1969, %1970)\n",
      "  %319 = Reshape[allowzero = 0](%301, %318)\n",
      "  %320 = Transpose[perm = [0, 2, 1, 3]](%319)\n",
      "  %321 = Shape(%277)\n",
      "  %322 = Constant[value = <Scalar Tensor []>]()\n",
      "  %323 = Gather[axis = 0](%321, %322)\n",
      "  %324 = Shape(%277)\n",
      "  %325 = Constant[value = <Scalar Tensor []>]()\n",
      "  %326 = Gather[axis = 0](%324, %325)\n",
      "  %329 = Constant[value = <Tensor>]()\n",
      "  %330 = Unsqueeze(%323, %329)\n",
      "  %331 = Constant[value = <Tensor>]()\n",
      "  %332 = Unsqueeze(%326, %331)\n",
      "  %337 = Concat[axis = 0](%330, %332, %1971, %1972)\n",
      "  %338 = Reshape[allowzero = 0](%277, %337)\n",
      "  %339 = Transpose[perm = [0, 2, 1, 3]](%338)\n",
      "  %340 = Transpose[perm = [0, 2, 3, 1]](%298)\n",
      "  %341 = MatMul(%339, %340)\n",
      "  %342 = Constant[value = <Scalar Tensor []>]()\n",
      "  %343 = Div(%341, %342)\n",
      "  %344 = Add(%343, %246)\n",
      "  %345 = Softmax[axis = -1](%344)\n",
      "  %346 = MatMul(%345, %320)\n",
      "  %347 = Transpose[perm = [0, 2, 1, 3]](%346)\n",
      "  %348 = Shape(%347)\n",
      "  %349 = Constant[value = <Scalar Tensor []>]()\n",
      "  %350 = Gather[axis = 0](%348, %349)\n",
      "  %351 = Shape(%347)\n",
      "  %352 = Constant[value = <Scalar Tensor []>]()\n",
      "  %353 = Gather[axis = 0](%351, %352)\n",
      "  %355 = Constant[value = <Tensor>]()\n",
      "  %356 = Unsqueeze(%350, %355)\n",
      "  %357 = Constant[value = <Tensor>]()\n",
      "  %358 = Unsqueeze(%353, %357)\n",
      "  %361 = Concat[axis = 0](%356, %358, %1973)\n",
      "  %362 = Reshape[allowzero = 0](%347, %361)\n",
      "  %364 = MatMul(%362, %1974)\n",
      "  %365 = Add(%basemodel.bert.encoder.layer.0.attention.output.dense.bias, %364)\n",
      "  %366 = Add(%365, %274)\n",
      "  %367 = ReduceMean[axes = [-1]](%366)\n",
      "  %368 = Sub(%366, %367)\n",
      "  %369 = Constant[value = <Scalar Tensor []>]()\n",
      "  %370 = Pow(%368, %369)\n",
      "  %371 = ReduceMean[axes = [-1]](%370)\n",
      "  %372 = Constant[value = <Scalar Tensor []>]()\n",
      "  %373 = Add(%371, %372)\n",
      "  %374 = Sqrt(%373)\n",
      "  %375 = Div(%368, %374)\n",
      "  %376 = Mul(%375, %basemodel.bert.encoder.layer.0.attention.output.LayerNorm.weight)\n",
      "  %377 = Add(%376, %basemodel.bert.encoder.layer.0.attention.output.LayerNorm.bias)\n",
      "  %379 = MatMul(%377, %1975)\n",
      "  %380 = Add(%basemodel.bert.encoder.layer.0.intermediate.dense.bias, %379)\n",
      "  %381 = Constant[value = <Scalar Tensor []>]()\n",
      "  %382 = Div(%380, %381)\n",
      "  %383 = Erf(%382)\n",
      "  %384 = Constant[value = <Scalar Tensor []>]()\n",
      "  %385 = Add(%383, %384)\n",
      "  %386 = Mul(%380, %385)\n",
      "  %387 = Constant[value = <Scalar Tensor []>]()\n",
      "  %388 = Mul(%386, %387)\n",
      "  %390 = MatMul(%388, %1976)\n",
      "  %391 = Add(%basemodel.bert.encoder.layer.0.output.dense.bias, %390)\n",
      "  %392 = Add(%391, %377)\n",
      "  %393 = ReduceMean[axes = [-1]](%392)\n",
      "  %394 = Sub(%392, %393)\n",
      "  %395 = Constant[value = <Scalar Tensor []>]()\n",
      "  %396 = Pow(%394, %395)\n",
      "  %397 = ReduceMean[axes = [-1]](%396)\n",
      "  %398 = Constant[value = <Scalar Tensor []>]()\n",
      "  %399 = Add(%397, %398)\n",
      "  %400 = Sqrt(%399)\n",
      "  %401 = Div(%394, %400)\n",
      "  %402 = Mul(%401, %basemodel.bert.encoder.layer.0.output.LayerNorm.weight)\n",
      "  %403 = Add(%402, %basemodel.bert.encoder.layer.0.output.LayerNorm.bias)\n",
      "  %405 = MatMul(%403, %1977)\n",
      "  %406 = Add(%basemodel.bert.encoder.layer.1.attention.self.query.bias, %405)\n",
      "  %408 = MatMul(%403, %1978)\n",
      "  %409 = Add(%basemodel.bert.encoder.layer.1.attention.self.key.bias, %408)\n",
      "  %410 = Shape(%409)\n",
      "  %411 = Constant[value = <Scalar Tensor []>]()\n",
      "  %412 = Gather[axis = 0](%410, %411)\n",
      "  %413 = Shape(%409)\n",
      "  %414 = Constant[value = <Scalar Tensor []>]()\n",
      "  %415 = Gather[axis = 0](%413, %414)\n",
      "  %418 = Constant[value = <Tensor>]()\n",
      "  %419 = Unsqueeze(%412, %418)\n",
      "  %420 = Constant[value = <Tensor>]()\n",
      "  %421 = Unsqueeze(%415, %420)\n",
      "  %426 = Concat[axis = 0](%419, %421, %1979, %1980)\n",
      "  %427 = Reshape[allowzero = 0](%409, %426)\n",
      "  %429 = MatMul(%403, %1981)\n",
      "  %430 = Add(%basemodel.bert.encoder.layer.1.attention.self.value.bias, %429)\n",
      "  %431 = Shape(%430)\n",
      "  %432 = Constant[value = <Scalar Tensor []>]()\n",
      "  %433 = Gather[axis = 0](%431, %432)\n",
      "  %434 = Shape(%430)\n",
      "  %435 = Constant[value = <Scalar Tensor []>]()\n",
      "  %436 = Gather[axis = 0](%434, %435)\n",
      "  %439 = Constant[value = <Tensor>]()\n",
      "  %440 = Unsqueeze(%433, %439)\n",
      "  %441 = Constant[value = <Tensor>]()\n",
      "  %442 = Unsqueeze(%436, %441)\n",
      "  %447 = Concat[axis = 0](%440, %442, %1982, %1983)\n",
      "  %448 = Reshape[allowzero = 0](%430, %447)\n",
      "  %449 = Transpose[perm = [0, 2, 1, 3]](%448)\n",
      "  %450 = Shape(%406)\n",
      "  %451 = Constant[value = <Scalar Tensor []>]()\n",
      "  %452 = Gather[axis = 0](%450, %451)\n",
      "  %453 = Shape(%406)\n",
      "  %454 = Constant[value = <Scalar Tensor []>]()\n",
      "  %455 = Gather[axis = 0](%453, %454)\n",
      "  %458 = Constant[value = <Tensor>]()\n",
      "  %459 = Unsqueeze(%452, %458)\n",
      "  %460 = Constant[value = <Tensor>]()\n",
      "  %461 = Unsqueeze(%455, %460)\n",
      "  %466 = Concat[axis = 0](%459, %461, %1984, %1985)\n",
      "  %467 = Reshape[allowzero = 0](%406, %466)\n",
      "  %468 = Transpose[perm = [0, 2, 1, 3]](%467)\n",
      "  %469 = Transpose[perm = [0, 2, 3, 1]](%427)\n",
      "  %470 = MatMul(%468, %469)\n",
      "  %471 = Constant[value = <Scalar Tensor []>]()\n",
      "  %472 = Div(%470, %471)\n",
      "  %473 = Add(%472, %246)\n",
      "  %474 = Softmax[axis = -1](%473)\n",
      "  %475 = MatMul(%474, %449)\n",
      "  %476 = Transpose[perm = [0, 2, 1, 3]](%475)\n",
      "  %477 = Shape(%476)\n",
      "  %478 = Constant[value = <Scalar Tensor []>]()\n",
      "  %479 = Gather[axis = 0](%477, %478)\n",
      "  %480 = Shape(%476)\n",
      "  %481 = Constant[value = <Scalar Tensor []>]()\n",
      "  %482 = Gather[axis = 0](%480, %481)\n",
      "  %484 = Constant[value = <Tensor>]()\n",
      "  %485 = Unsqueeze(%479, %484)\n",
      "  %486 = Constant[value = <Tensor>]()\n",
      "  %487 = Unsqueeze(%482, %486)\n",
      "  %490 = Concat[axis = 0](%485, %487, %1986)\n",
      "  %491 = Reshape[allowzero = 0](%476, %490)\n",
      "  %493 = MatMul(%491, %1987)\n",
      "  %494 = Add(%basemodel.bert.encoder.layer.1.attention.output.dense.bias, %493)\n",
      "  %495 = Add(%494, %403)\n",
      "  %496 = ReduceMean[axes = [-1]](%495)\n",
      "  %497 = Sub(%495, %496)\n",
      "  %498 = Constant[value = <Scalar Tensor []>]()\n",
      "  %499 = Pow(%497, %498)\n",
      "  %500 = ReduceMean[axes = [-1]](%499)\n",
      "  %501 = Constant[value = <Scalar Tensor []>]()\n",
      "  %502 = Add(%500, %501)\n",
      "  %503 = Sqrt(%502)\n",
      "  %504 = Div(%497, %503)\n",
      "  %505 = Mul(%504, %basemodel.bert.encoder.layer.1.attention.output.LayerNorm.weight)\n",
      "  %506 = Add(%505, %basemodel.bert.encoder.layer.1.attention.output.LayerNorm.bias)\n",
      "  %508 = MatMul(%506, %1988)\n",
      "  %509 = Add(%basemodel.bert.encoder.layer.1.intermediate.dense.bias, %508)\n",
      "  %510 = Constant[value = <Scalar Tensor []>]()\n",
      "  %511 = Div(%509, %510)\n",
      "  %512 = Erf(%511)\n",
      "  %513 = Constant[value = <Scalar Tensor []>]()\n",
      "  %514 = Add(%512, %513)\n",
      "  %515 = Mul(%509, %514)\n",
      "  %516 = Constant[value = <Scalar Tensor []>]()\n",
      "  %517 = Mul(%515, %516)\n",
      "  %519 = MatMul(%517, %1989)\n",
      "  %520 = Add(%basemodel.bert.encoder.layer.1.output.dense.bias, %519)\n",
      "  %521 = Add(%520, %506)\n",
      "  %522 = ReduceMean[axes = [-1]](%521)\n",
      "  %523 = Sub(%521, %522)\n",
      "  %524 = Constant[value = <Scalar Tensor []>]()\n",
      "  %525 = Pow(%523, %524)\n",
      "  %526 = ReduceMean[axes = [-1]](%525)\n",
      "  %527 = Constant[value = <Scalar Tensor []>]()\n",
      "  %528 = Add(%526, %527)\n",
      "  %529 = Sqrt(%528)\n",
      "  %530 = Div(%523, %529)\n",
      "  %531 = Mul(%530, %basemodel.bert.encoder.layer.1.output.LayerNorm.weight)\n",
      "  %532 = Add(%531, %basemodel.bert.encoder.layer.1.output.LayerNorm.bias)\n",
      "  %534 = MatMul(%532, %1990)\n",
      "  %535 = Add(%basemodel.bert.encoder.layer.2.attention.self.query.bias, %534)\n",
      "  %537 = MatMul(%532, %1991)\n",
      "  %538 = Add(%basemodel.bert.encoder.layer.2.attention.self.key.bias, %537)\n",
      "  %539 = Shape(%538)\n",
      "  %540 = Constant[value = <Scalar Tensor []>]()\n",
      "  %541 = Gather[axis = 0](%539, %540)\n",
      "  %542 = Shape(%538)\n",
      "  %543 = Constant[value = <Scalar Tensor []>]()\n",
      "  %544 = Gather[axis = 0](%542, %543)\n",
      "  %547 = Constant[value = <Tensor>]()\n",
      "  %548 = Unsqueeze(%541, %547)\n",
      "  %549 = Constant[value = <Tensor>]()\n",
      "  %550 = Unsqueeze(%544, %549)\n",
      "  %555 = Concat[axis = 0](%548, %550, %1992, %1993)\n",
      "  %556 = Reshape[allowzero = 0](%538, %555)\n",
      "  %558 = MatMul(%532, %1994)\n",
      "  %559 = Add(%basemodel.bert.encoder.layer.2.attention.self.value.bias, %558)\n",
      "  %560 = Shape(%559)\n",
      "  %561 = Constant[value = <Scalar Tensor []>]()\n",
      "  %562 = Gather[axis = 0](%560, %561)\n",
      "  %563 = Shape(%559)\n",
      "  %564 = Constant[value = <Scalar Tensor []>]()\n",
      "  %565 = Gather[axis = 0](%563, %564)\n",
      "  %568 = Constant[value = <Tensor>]()\n",
      "  %569 = Unsqueeze(%562, %568)\n",
      "  %570 = Constant[value = <Tensor>]()\n",
      "  %571 = Unsqueeze(%565, %570)\n",
      "  %576 = Concat[axis = 0](%569, %571, %1995, %1996)\n",
      "  %577 = Reshape[allowzero = 0](%559, %576)\n",
      "  %578 = Transpose[perm = [0, 2, 1, 3]](%577)\n",
      "  %579 = Shape(%535)\n",
      "  %580 = Constant[value = <Scalar Tensor []>]()\n",
      "  %581 = Gather[axis = 0](%579, %580)\n",
      "  %582 = Shape(%535)\n",
      "  %583 = Constant[value = <Scalar Tensor []>]()\n",
      "  %584 = Gather[axis = 0](%582, %583)\n",
      "  %587 = Constant[value = <Tensor>]()\n",
      "  %588 = Unsqueeze(%581, %587)\n",
      "  %589 = Constant[value = <Tensor>]()\n",
      "  %590 = Unsqueeze(%584, %589)\n",
      "  %595 = Concat[axis = 0](%588, %590, %1997, %1998)\n",
      "  %596 = Reshape[allowzero = 0](%535, %595)\n",
      "  %597 = Transpose[perm = [0, 2, 1, 3]](%596)\n",
      "  %598 = Transpose[perm = [0, 2, 3, 1]](%556)\n",
      "  %599 = MatMul(%597, %598)\n",
      "  %600 = Constant[value = <Scalar Tensor []>]()\n",
      "  %601 = Div(%599, %600)\n",
      "  %602 = Add(%601, %246)\n",
      "  %603 = Softmax[axis = -1](%602)\n",
      "  %604 = MatMul(%603, %578)\n",
      "  %605 = Transpose[perm = [0, 2, 1, 3]](%604)\n",
      "  %606 = Shape(%605)\n",
      "  %607 = Constant[value = <Scalar Tensor []>]()\n",
      "  %608 = Gather[axis = 0](%606, %607)\n",
      "  %609 = Shape(%605)\n",
      "  %610 = Constant[value = <Scalar Tensor []>]()\n",
      "  %611 = Gather[axis = 0](%609, %610)\n",
      "  %613 = Constant[value = <Tensor>]()\n",
      "  %614 = Unsqueeze(%608, %613)\n",
      "  %615 = Constant[value = <Tensor>]()\n",
      "  %616 = Unsqueeze(%611, %615)\n",
      "  %619 = Concat[axis = 0](%614, %616, %1999)\n",
      "  %620 = Reshape[allowzero = 0](%605, %619)\n",
      "  %622 = MatMul(%620, %2000)\n",
      "  %623 = Add(%basemodel.bert.encoder.layer.2.attention.output.dense.bias, %622)\n",
      "  %624 = Add(%623, %532)\n",
      "  %625 = ReduceMean[axes = [-1]](%624)\n",
      "  %626 = Sub(%624, %625)\n",
      "  %627 = Constant[value = <Scalar Tensor []>]()\n",
      "  %628 = Pow(%626, %627)\n",
      "  %629 = ReduceMean[axes = [-1]](%628)\n",
      "  %630 = Constant[value = <Scalar Tensor []>]()\n",
      "  %631 = Add(%629, %630)\n",
      "  %632 = Sqrt(%631)\n",
      "  %633 = Div(%626, %632)\n",
      "  %634 = Mul(%633, %basemodel.bert.encoder.layer.2.attention.output.LayerNorm.weight)\n",
      "  %635 = Add(%634, %basemodel.bert.encoder.layer.2.attention.output.LayerNorm.bias)\n",
      "  %637 = MatMul(%635, %2001)\n",
      "  %638 = Add(%basemodel.bert.encoder.layer.2.intermediate.dense.bias, %637)\n",
      "  %639 = Constant[value = <Scalar Tensor []>]()\n",
      "  %640 = Div(%638, %639)\n",
      "  %641 = Erf(%640)\n",
      "  %642 = Constant[value = <Scalar Tensor []>]()\n",
      "  %643 = Add(%641, %642)\n",
      "  %644 = Mul(%638, %643)\n",
      "  %645 = Constant[value = <Scalar Tensor []>]()\n",
      "  %646 = Mul(%644, %645)\n",
      "  %648 = MatMul(%646, %2002)\n",
      "  %649 = Add(%basemodel.bert.encoder.layer.2.output.dense.bias, %648)\n",
      "  %650 = Add(%649, %635)\n",
      "  %651 = ReduceMean[axes = [-1]](%650)\n",
      "  %652 = Sub(%650, %651)\n",
      "  %653 = Constant[value = <Scalar Tensor []>]()\n",
      "  %654 = Pow(%652, %653)\n",
      "  %655 = ReduceMean[axes = [-1]](%654)\n",
      "  %656 = Constant[value = <Scalar Tensor []>]()\n",
      "  %657 = Add(%655, %656)\n",
      "  %658 = Sqrt(%657)\n",
      "  %659 = Div(%652, %658)\n",
      "  %660 = Mul(%659, %basemodel.bert.encoder.layer.2.output.LayerNorm.weight)\n",
      "  %661 = Add(%660, %basemodel.bert.encoder.layer.2.output.LayerNorm.bias)\n",
      "  %663 = MatMul(%661, %2003)\n",
      "  %664 = Add(%basemodel.bert.encoder.layer.3.attention.self.query.bias, %663)\n",
      "  %666 = MatMul(%661, %2004)\n",
      "  %667 = Add(%basemodel.bert.encoder.layer.3.attention.self.key.bias, %666)\n",
      "  %668 = Shape(%667)\n",
      "  %669 = Constant[value = <Scalar Tensor []>]()\n",
      "  %670 = Gather[axis = 0](%668, %669)\n",
      "  %671 = Shape(%667)\n",
      "  %672 = Constant[value = <Scalar Tensor []>]()\n",
      "  %673 = Gather[axis = 0](%671, %672)\n",
      "  %676 = Constant[value = <Tensor>]()\n",
      "  %677 = Unsqueeze(%670, %676)\n",
      "  %678 = Constant[value = <Tensor>]()\n",
      "  %679 = Unsqueeze(%673, %678)\n",
      "  %684 = Concat[axis = 0](%677, %679, %2005, %2006)\n",
      "  %685 = Reshape[allowzero = 0](%667, %684)\n",
      "  %687 = MatMul(%661, %2007)\n",
      "  %688 = Add(%basemodel.bert.encoder.layer.3.attention.self.value.bias, %687)\n",
      "  %689 = Shape(%688)\n",
      "  %690 = Constant[value = <Scalar Tensor []>]()\n",
      "  %691 = Gather[axis = 0](%689, %690)\n",
      "  %692 = Shape(%688)\n",
      "  %693 = Constant[value = <Scalar Tensor []>]()\n",
      "  %694 = Gather[axis = 0](%692, %693)\n",
      "  %697 = Constant[value = <Tensor>]()\n",
      "  %698 = Unsqueeze(%691, %697)\n",
      "  %699 = Constant[value = <Tensor>]()\n",
      "  %700 = Unsqueeze(%694, %699)\n",
      "  %705 = Concat[axis = 0](%698, %700, %2008, %2009)\n",
      "  %706 = Reshape[allowzero = 0](%688, %705)\n",
      "  %707 = Transpose[perm = [0, 2, 1, 3]](%706)\n",
      "  %708 = Shape(%664)\n",
      "  %709 = Constant[value = <Scalar Tensor []>]()\n",
      "  %710 = Gather[axis = 0](%708, %709)\n",
      "  %711 = Shape(%664)\n",
      "  %712 = Constant[value = <Scalar Tensor []>]()\n",
      "  %713 = Gather[axis = 0](%711, %712)\n",
      "  %716 = Constant[value = <Tensor>]()\n",
      "  %717 = Unsqueeze(%710, %716)\n",
      "  %718 = Constant[value = <Tensor>]()\n",
      "  %719 = Unsqueeze(%713, %718)\n",
      "  %724 = Concat[axis = 0](%717, %719, %2010, %2011)\n",
      "  %725 = Reshape[allowzero = 0](%664, %724)\n",
      "  %726 = Transpose[perm = [0, 2, 1, 3]](%725)\n",
      "  %727 = Transpose[perm = [0, 2, 3, 1]](%685)\n",
      "  %728 = MatMul(%726, %727)\n",
      "  %729 = Constant[value = <Scalar Tensor []>]()\n",
      "  %730 = Div(%728, %729)\n",
      "  %731 = Add(%730, %246)\n",
      "  %732 = Softmax[axis = -1](%731)\n",
      "  %733 = MatMul(%732, %707)\n",
      "  %734 = Transpose[perm = [0, 2, 1, 3]](%733)\n",
      "  %735 = Shape(%734)\n",
      "  %736 = Constant[value = <Scalar Tensor []>]()\n",
      "  %737 = Gather[axis = 0](%735, %736)\n",
      "  %738 = Shape(%734)\n",
      "  %739 = Constant[value = <Scalar Tensor []>]()\n",
      "  %740 = Gather[axis = 0](%738, %739)\n",
      "  %742 = Constant[value = <Tensor>]()\n",
      "  %743 = Unsqueeze(%737, %742)\n",
      "  %744 = Constant[value = <Tensor>]()\n",
      "  %745 = Unsqueeze(%740, %744)\n",
      "  %748 = Concat[axis = 0](%743, %745, %2012)\n",
      "  %749 = Reshape[allowzero = 0](%734, %748)\n",
      "  %751 = MatMul(%749, %2013)\n",
      "  %752 = Add(%basemodel.bert.encoder.layer.3.attention.output.dense.bias, %751)\n",
      "  %753 = Add(%752, %661)\n",
      "  %754 = ReduceMean[axes = [-1]](%753)\n",
      "  %755 = Sub(%753, %754)\n",
      "  %756 = Constant[value = <Scalar Tensor []>]()\n",
      "  %757 = Pow(%755, %756)\n",
      "  %758 = ReduceMean[axes = [-1]](%757)\n",
      "  %759 = Constant[value = <Scalar Tensor []>]()\n",
      "  %760 = Add(%758, %759)\n",
      "  %761 = Sqrt(%760)\n",
      "  %762 = Div(%755, %761)\n",
      "  %763 = Mul(%762, %basemodel.bert.encoder.layer.3.attention.output.LayerNorm.weight)\n",
      "  %764 = Add(%763, %basemodel.bert.encoder.layer.3.attention.output.LayerNorm.bias)\n",
      "  %766 = MatMul(%764, %2014)\n",
      "  %767 = Add(%basemodel.bert.encoder.layer.3.intermediate.dense.bias, %766)\n",
      "  %768 = Constant[value = <Scalar Tensor []>]()\n",
      "  %769 = Div(%767, %768)\n",
      "  %770 = Erf(%769)\n",
      "  %771 = Constant[value = <Scalar Tensor []>]()\n",
      "  %772 = Add(%770, %771)\n",
      "  %773 = Mul(%767, %772)\n",
      "  %774 = Constant[value = <Scalar Tensor []>]()\n",
      "  %775 = Mul(%773, %774)\n",
      "  %777 = MatMul(%775, %2015)\n",
      "  %778 = Add(%basemodel.bert.encoder.layer.3.output.dense.bias, %777)\n",
      "  %779 = Add(%778, %764)\n",
      "  %780 = ReduceMean[axes = [-1]](%779)\n",
      "  %781 = Sub(%779, %780)\n",
      "  %782 = Constant[value = <Scalar Tensor []>]()\n",
      "  %783 = Pow(%781, %782)\n",
      "  %784 = ReduceMean[axes = [-1]](%783)\n",
      "  %785 = Constant[value = <Scalar Tensor []>]()\n",
      "  %786 = Add(%784, %785)\n",
      "  %787 = Sqrt(%786)\n",
      "  %788 = Div(%781, %787)\n",
      "  %789 = Mul(%788, %basemodel.bert.encoder.layer.3.output.LayerNorm.weight)\n",
      "  %790 = Add(%789, %basemodel.bert.encoder.layer.3.output.LayerNorm.bias)\n",
      "  %792 = MatMul(%790, %2016)\n",
      "  %793 = Add(%basemodel.bert.encoder.layer.4.attention.self.query.bias, %792)\n",
      "  %795 = MatMul(%790, %2017)\n",
      "  %796 = Add(%basemodel.bert.encoder.layer.4.attention.self.key.bias, %795)\n",
      "  %797 = Shape(%796)\n",
      "  %798 = Constant[value = <Scalar Tensor []>]()\n",
      "  %799 = Gather[axis = 0](%797, %798)\n",
      "  %800 = Shape(%796)\n",
      "  %801 = Constant[value = <Scalar Tensor []>]()\n",
      "  %802 = Gather[axis = 0](%800, %801)\n",
      "  %805 = Constant[value = <Tensor>]()\n",
      "  %806 = Unsqueeze(%799, %805)\n",
      "  %807 = Constant[value = <Tensor>]()\n",
      "  %808 = Unsqueeze(%802, %807)\n",
      "  %813 = Concat[axis = 0](%806, %808, %2018, %2019)\n",
      "  %814 = Reshape[allowzero = 0](%796, %813)\n",
      "  %816 = MatMul(%790, %2020)\n",
      "  %817 = Add(%basemodel.bert.encoder.layer.4.attention.self.value.bias, %816)\n",
      "  %818 = Shape(%817)\n",
      "  %819 = Constant[value = <Scalar Tensor []>]()\n",
      "  %820 = Gather[axis = 0](%818, %819)\n",
      "  %821 = Shape(%817)\n",
      "  %822 = Constant[value = <Scalar Tensor []>]()\n",
      "  %823 = Gather[axis = 0](%821, %822)\n",
      "  %826 = Constant[value = <Tensor>]()\n",
      "  %827 = Unsqueeze(%820, %826)\n",
      "  %828 = Constant[value = <Tensor>]()\n",
      "  %829 = Unsqueeze(%823, %828)\n",
      "  %834 = Concat[axis = 0](%827, %829, %2021, %2022)\n",
      "  %835 = Reshape[allowzero = 0](%817, %834)\n",
      "  %836 = Transpose[perm = [0, 2, 1, 3]](%835)\n",
      "  %837 = Shape(%793)\n",
      "  %838 = Constant[value = <Scalar Tensor []>]()\n",
      "  %839 = Gather[axis = 0](%837, %838)\n",
      "  %840 = Shape(%793)\n",
      "  %841 = Constant[value = <Scalar Tensor []>]()\n",
      "  %842 = Gather[axis = 0](%840, %841)\n",
      "  %845 = Constant[value = <Tensor>]()\n",
      "  %846 = Unsqueeze(%839, %845)\n",
      "  %847 = Constant[value = <Tensor>]()\n",
      "  %848 = Unsqueeze(%842, %847)\n",
      "  %853 = Concat[axis = 0](%846, %848, %2023, %2024)\n",
      "  %854 = Reshape[allowzero = 0](%793, %853)\n",
      "  %855 = Transpose[perm = [0, 2, 1, 3]](%854)\n",
      "  %856 = Transpose[perm = [0, 2, 3, 1]](%814)\n",
      "  %857 = MatMul(%855, %856)\n",
      "  %858 = Constant[value = <Scalar Tensor []>]()\n",
      "  %859 = Div(%857, %858)\n",
      "  %860 = Add(%859, %246)\n",
      "  %861 = Softmax[axis = -1](%860)\n",
      "  %862 = MatMul(%861, %836)\n",
      "  %863 = Transpose[perm = [0, 2, 1, 3]](%862)\n",
      "  %864 = Shape(%863)\n",
      "  %865 = Constant[value = <Scalar Tensor []>]()\n",
      "  %866 = Gather[axis = 0](%864, %865)\n",
      "  %867 = Shape(%863)\n",
      "  %868 = Constant[value = <Scalar Tensor []>]()\n",
      "  %869 = Gather[axis = 0](%867, %868)\n",
      "  %871 = Constant[value = <Tensor>]()\n",
      "  %872 = Unsqueeze(%866, %871)\n",
      "  %873 = Constant[value = <Tensor>]()\n",
      "  %874 = Unsqueeze(%869, %873)\n",
      "  %877 = Concat[axis = 0](%872, %874, %2025)\n",
      "  %878 = Reshape[allowzero = 0](%863, %877)\n",
      "  %880 = MatMul(%878, %2026)\n",
      "  %881 = Add(%basemodel.bert.encoder.layer.4.attention.output.dense.bias, %880)\n",
      "  %882 = Add(%881, %790)\n",
      "  %883 = ReduceMean[axes = [-1]](%882)\n",
      "  %884 = Sub(%882, %883)\n",
      "  %885 = Constant[value = <Scalar Tensor []>]()\n",
      "  %886 = Pow(%884, %885)\n",
      "  %887 = ReduceMean[axes = [-1]](%886)\n",
      "  %888 = Constant[value = <Scalar Tensor []>]()\n",
      "  %889 = Add(%887, %888)\n",
      "  %890 = Sqrt(%889)\n",
      "  %891 = Div(%884, %890)\n",
      "  %892 = Mul(%891, %basemodel.bert.encoder.layer.4.attention.output.LayerNorm.weight)\n",
      "  %893 = Add(%892, %basemodel.bert.encoder.layer.4.attention.output.LayerNorm.bias)\n",
      "  %895 = MatMul(%893, %2027)\n",
      "  %896 = Add(%basemodel.bert.encoder.layer.4.intermediate.dense.bias, %895)\n",
      "  %897 = Constant[value = <Scalar Tensor []>]()\n",
      "  %898 = Div(%896, %897)\n",
      "  %899 = Erf(%898)\n",
      "  %900 = Constant[value = <Scalar Tensor []>]()\n",
      "  %901 = Add(%899, %900)\n",
      "  %902 = Mul(%896, %901)\n",
      "  %903 = Constant[value = <Scalar Tensor []>]()\n",
      "  %904 = Mul(%902, %903)\n",
      "  %906 = MatMul(%904, %2028)\n",
      "  %907 = Add(%basemodel.bert.encoder.layer.4.output.dense.bias, %906)\n",
      "  %908 = Add(%907, %893)\n",
      "  %909 = ReduceMean[axes = [-1]](%908)\n",
      "  %910 = Sub(%908, %909)\n",
      "  %911 = Constant[value = <Scalar Tensor []>]()\n",
      "  %912 = Pow(%910, %911)\n",
      "  %913 = ReduceMean[axes = [-1]](%912)\n",
      "  %914 = Constant[value = <Scalar Tensor []>]()\n",
      "  %915 = Add(%913, %914)\n",
      "  %916 = Sqrt(%915)\n",
      "  %917 = Div(%910, %916)\n",
      "  %918 = Mul(%917, %basemodel.bert.encoder.layer.4.output.LayerNorm.weight)\n",
      "  %919 = Add(%918, %basemodel.bert.encoder.layer.4.output.LayerNorm.bias)\n",
      "  %921 = MatMul(%919, %2029)\n",
      "  %922 = Add(%basemodel.bert.encoder.layer.5.attention.self.query.bias, %921)\n",
      "  %924 = MatMul(%919, %2030)\n",
      "  %925 = Add(%basemodel.bert.encoder.layer.5.attention.self.key.bias, %924)\n",
      "  %926 = Shape(%925)\n",
      "  %927 = Constant[value = <Scalar Tensor []>]()\n",
      "  %928 = Gather[axis = 0](%926, %927)\n",
      "  %929 = Shape(%925)\n",
      "  %930 = Constant[value = <Scalar Tensor []>]()\n",
      "  %931 = Gather[axis = 0](%929, %930)\n",
      "  %934 = Constant[value = <Tensor>]()\n",
      "  %935 = Unsqueeze(%928, %934)\n",
      "  %936 = Constant[value = <Tensor>]()\n",
      "  %937 = Unsqueeze(%931, %936)\n",
      "  %942 = Concat[axis = 0](%935, %937, %2031, %2032)\n",
      "  %943 = Reshape[allowzero = 0](%925, %942)\n",
      "  %945 = MatMul(%919, %2033)\n",
      "  %946 = Add(%basemodel.bert.encoder.layer.5.attention.self.value.bias, %945)\n",
      "  %947 = Shape(%946)\n",
      "  %948 = Constant[value = <Scalar Tensor []>]()\n",
      "  %949 = Gather[axis = 0](%947, %948)\n",
      "  %950 = Shape(%946)\n",
      "  %951 = Constant[value = <Scalar Tensor []>]()\n",
      "  %952 = Gather[axis = 0](%950, %951)\n",
      "  %955 = Constant[value = <Tensor>]()\n",
      "  %956 = Unsqueeze(%949, %955)\n",
      "  %957 = Constant[value = <Tensor>]()\n",
      "  %958 = Unsqueeze(%952, %957)\n",
      "  %963 = Concat[axis = 0](%956, %958, %2034, %2035)\n",
      "  %964 = Reshape[allowzero = 0](%946, %963)\n",
      "  %965 = Transpose[perm = [0, 2, 1, 3]](%964)\n",
      "  %966 = Shape(%922)\n",
      "  %967 = Constant[value = <Scalar Tensor []>]()\n",
      "  %968 = Gather[axis = 0](%966, %967)\n",
      "  %969 = Shape(%922)\n",
      "  %970 = Constant[value = <Scalar Tensor []>]()\n",
      "  %971 = Gather[axis = 0](%969, %970)\n",
      "  %974 = Constant[value = <Tensor>]()\n",
      "  %975 = Unsqueeze(%968, %974)\n",
      "  %976 = Constant[value = <Tensor>]()\n",
      "  %977 = Unsqueeze(%971, %976)\n",
      "  %982 = Concat[axis = 0](%975, %977, %2036, %2037)\n",
      "  %983 = Reshape[allowzero = 0](%922, %982)\n",
      "  %984 = Transpose[perm = [0, 2, 1, 3]](%983)\n",
      "  %985 = Transpose[perm = [0, 2, 3, 1]](%943)\n",
      "  %986 = MatMul(%984, %985)\n",
      "  %987 = Constant[value = <Scalar Tensor []>]()\n",
      "  %988 = Div(%986, %987)\n",
      "  %989 = Add(%988, %246)\n",
      "  %990 = Softmax[axis = -1](%989)\n",
      "  %991 = MatMul(%990, %965)\n",
      "  %992 = Transpose[perm = [0, 2, 1, 3]](%991)\n",
      "  %993 = Shape(%992)\n",
      "  %994 = Constant[value = <Scalar Tensor []>]()\n",
      "  %995 = Gather[axis = 0](%993, %994)\n",
      "  %996 = Shape(%992)\n",
      "  %997 = Constant[value = <Scalar Tensor []>]()\n",
      "  %998 = Gather[axis = 0](%996, %997)\n",
      "  %1000 = Constant[value = <Tensor>]()\n",
      "  %1001 = Unsqueeze(%995, %1000)\n",
      "  %1002 = Constant[value = <Tensor>]()\n",
      "  %1003 = Unsqueeze(%998, %1002)\n",
      "  %1006 = Concat[axis = 0](%1001, %1003, %2038)\n",
      "  %1007 = Reshape[allowzero = 0](%992, %1006)\n",
      "  %1009 = MatMul(%1007, %2039)\n",
      "  %1010 = Add(%basemodel.bert.encoder.layer.5.attention.output.dense.bias, %1009)\n",
      "  %1011 = Add(%1010, %919)\n",
      "  %1012 = ReduceMean[axes = [-1]](%1011)\n",
      "  %1013 = Sub(%1011, %1012)\n",
      "  %1014 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1015 = Pow(%1013, %1014)\n",
      "  %1016 = ReduceMean[axes = [-1]](%1015)\n",
      "  %1017 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1018 = Add(%1016, %1017)\n",
      "  %1019 = Sqrt(%1018)\n",
      "  %1020 = Div(%1013, %1019)\n",
      "  %1021 = Mul(%1020, %basemodel.bert.encoder.layer.5.attention.output.LayerNorm.weight)\n",
      "  %1022 = Add(%1021, %basemodel.bert.encoder.layer.5.attention.output.LayerNorm.bias)\n",
      "  %1024 = MatMul(%1022, %2040)\n",
      "  %1025 = Add(%basemodel.bert.encoder.layer.5.intermediate.dense.bias, %1024)\n",
      "  %1026 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1027 = Div(%1025, %1026)\n",
      "  %1028 = Erf(%1027)\n",
      "  %1029 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1030 = Add(%1028, %1029)\n",
      "  %1031 = Mul(%1025, %1030)\n",
      "  %1032 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1033 = Mul(%1031, %1032)\n",
      "  %1035 = MatMul(%1033, %2041)\n",
      "  %1036 = Add(%basemodel.bert.encoder.layer.5.output.dense.bias, %1035)\n",
      "  %1037 = Add(%1036, %1022)\n",
      "  %1038 = ReduceMean[axes = [-1]](%1037)\n",
      "  %1039 = Sub(%1037, %1038)\n",
      "  %1040 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1041 = Pow(%1039, %1040)\n",
      "  %1042 = ReduceMean[axes = [-1]](%1041)\n",
      "  %1043 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1044 = Add(%1042, %1043)\n",
      "  %1045 = Sqrt(%1044)\n",
      "  %1046 = Div(%1039, %1045)\n",
      "  %1047 = Mul(%1046, %basemodel.bert.encoder.layer.5.output.LayerNorm.weight)\n",
      "  %1048 = Add(%1047, %basemodel.bert.encoder.layer.5.output.LayerNorm.bias)\n",
      "  %1050 = MatMul(%1048, %2042)\n",
      "  %1051 = Add(%basemodel.bert.encoder.layer.6.attention.self.query.bias, %1050)\n",
      "  %1053 = MatMul(%1048, %2043)\n",
      "  %1054 = Add(%basemodel.bert.encoder.layer.6.attention.self.key.bias, %1053)\n",
      "  %1055 = Shape(%1054)\n",
      "  %1056 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1057 = Gather[axis = 0](%1055, %1056)\n",
      "  %1058 = Shape(%1054)\n",
      "  %1059 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1060 = Gather[axis = 0](%1058, %1059)\n",
      "  %1063 = Constant[value = <Tensor>]()\n",
      "  %1064 = Unsqueeze(%1057, %1063)\n",
      "  %1065 = Constant[value = <Tensor>]()\n",
      "  %1066 = Unsqueeze(%1060, %1065)\n",
      "  %1071 = Concat[axis = 0](%1064, %1066, %2044, %2045)\n",
      "  %1072 = Reshape[allowzero = 0](%1054, %1071)\n",
      "  %1074 = MatMul(%1048, %2046)\n",
      "  %1075 = Add(%basemodel.bert.encoder.layer.6.attention.self.value.bias, %1074)\n",
      "  %1076 = Shape(%1075)\n",
      "  %1077 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1078 = Gather[axis = 0](%1076, %1077)\n",
      "  %1079 = Shape(%1075)\n",
      "  %1080 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1081 = Gather[axis = 0](%1079, %1080)\n",
      "  %1084 = Constant[value = <Tensor>]()\n",
      "  %1085 = Unsqueeze(%1078, %1084)\n",
      "  %1086 = Constant[value = <Tensor>]()\n",
      "  %1087 = Unsqueeze(%1081, %1086)\n",
      "  %1092 = Concat[axis = 0](%1085, %1087, %2047, %2048)\n",
      "  %1093 = Reshape[allowzero = 0](%1075, %1092)\n",
      "  %1094 = Transpose[perm = [0, 2, 1, 3]](%1093)\n",
      "  %1095 = Shape(%1051)\n",
      "  %1096 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1097 = Gather[axis = 0](%1095, %1096)\n",
      "  %1098 = Shape(%1051)\n",
      "  %1099 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1100 = Gather[axis = 0](%1098, %1099)\n",
      "  %1103 = Constant[value = <Tensor>]()\n",
      "  %1104 = Unsqueeze(%1097, %1103)\n",
      "  %1105 = Constant[value = <Tensor>]()\n",
      "  %1106 = Unsqueeze(%1100, %1105)\n",
      "  %1111 = Concat[axis = 0](%1104, %1106, %2049, %2050)\n",
      "  %1112 = Reshape[allowzero = 0](%1051, %1111)\n",
      "  %1113 = Transpose[perm = [0, 2, 1, 3]](%1112)\n",
      "  %1114 = Transpose[perm = [0, 2, 3, 1]](%1072)\n",
      "  %1115 = MatMul(%1113, %1114)\n",
      "  %1116 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1117 = Div(%1115, %1116)\n",
      "  %1118 = Add(%1117, %246)\n",
      "  %1119 = Softmax[axis = -1](%1118)\n",
      "  %1120 = MatMul(%1119, %1094)\n",
      "  %1121 = Transpose[perm = [0, 2, 1, 3]](%1120)\n",
      "  %1122 = Shape(%1121)\n",
      "  %1123 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1124 = Gather[axis = 0](%1122, %1123)\n",
      "  %1125 = Shape(%1121)\n",
      "  %1126 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1127 = Gather[axis = 0](%1125, %1126)\n",
      "  %1129 = Constant[value = <Tensor>]()\n",
      "  %1130 = Unsqueeze(%1124, %1129)\n",
      "  %1131 = Constant[value = <Tensor>]()\n",
      "  %1132 = Unsqueeze(%1127, %1131)\n",
      "  %1135 = Concat[axis = 0](%1130, %1132, %2051)\n",
      "  %1136 = Reshape[allowzero = 0](%1121, %1135)\n",
      "  %1138 = MatMul(%1136, %2052)\n",
      "  %1139 = Add(%basemodel.bert.encoder.layer.6.attention.output.dense.bias, %1138)\n",
      "  %1140 = Add(%1139, %1048)\n",
      "  %1141 = ReduceMean[axes = [-1]](%1140)\n",
      "  %1142 = Sub(%1140, %1141)\n",
      "  %1143 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1144 = Pow(%1142, %1143)\n",
      "  %1145 = ReduceMean[axes = [-1]](%1144)\n",
      "  %1146 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1147 = Add(%1145, %1146)\n",
      "  %1148 = Sqrt(%1147)\n",
      "  %1149 = Div(%1142, %1148)\n",
      "  %1150 = Mul(%1149, %basemodel.bert.encoder.layer.6.attention.output.LayerNorm.weight)\n",
      "  %1151 = Add(%1150, %basemodel.bert.encoder.layer.6.attention.output.LayerNorm.bias)\n",
      "  %1153 = MatMul(%1151, %2053)\n",
      "  %1154 = Add(%basemodel.bert.encoder.layer.6.intermediate.dense.bias, %1153)\n",
      "  %1155 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1156 = Div(%1154, %1155)\n",
      "  %1157 = Erf(%1156)\n",
      "  %1158 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1159 = Add(%1157, %1158)\n",
      "  %1160 = Mul(%1154, %1159)\n",
      "  %1161 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1162 = Mul(%1160, %1161)\n",
      "  %1164 = MatMul(%1162, %2054)\n",
      "  %1165 = Add(%basemodel.bert.encoder.layer.6.output.dense.bias, %1164)\n",
      "  %1166 = Add(%1165, %1151)\n",
      "  %1167 = ReduceMean[axes = [-1]](%1166)\n",
      "  %1168 = Sub(%1166, %1167)\n",
      "  %1169 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1170 = Pow(%1168, %1169)\n",
      "  %1171 = ReduceMean[axes = [-1]](%1170)\n",
      "  %1172 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1173 = Add(%1171, %1172)\n",
      "  %1174 = Sqrt(%1173)\n",
      "  %1175 = Div(%1168, %1174)\n",
      "  %1176 = Mul(%1175, %basemodel.bert.encoder.layer.6.output.LayerNorm.weight)\n",
      "  %1177 = Add(%1176, %basemodel.bert.encoder.layer.6.output.LayerNorm.bias)\n",
      "  %1179 = MatMul(%1177, %2055)\n",
      "  %1180 = Add(%basemodel.bert.encoder.layer.7.attention.self.query.bias, %1179)\n",
      "  %1182 = MatMul(%1177, %2056)\n",
      "  %1183 = Add(%basemodel.bert.encoder.layer.7.attention.self.key.bias, %1182)\n",
      "  %1184 = Shape(%1183)\n",
      "  %1185 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1186 = Gather[axis = 0](%1184, %1185)\n",
      "  %1187 = Shape(%1183)\n",
      "  %1188 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1189 = Gather[axis = 0](%1187, %1188)\n",
      "  %1192 = Constant[value = <Tensor>]()\n",
      "  %1193 = Unsqueeze(%1186, %1192)\n",
      "  %1194 = Constant[value = <Tensor>]()\n",
      "  %1195 = Unsqueeze(%1189, %1194)\n",
      "  %1200 = Concat[axis = 0](%1193, %1195, %2057, %2058)\n",
      "  %1201 = Reshape[allowzero = 0](%1183, %1200)\n",
      "  %1203 = MatMul(%1177, %2059)\n",
      "  %1204 = Add(%basemodel.bert.encoder.layer.7.attention.self.value.bias, %1203)\n",
      "  %1205 = Shape(%1204)\n",
      "  %1206 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1207 = Gather[axis = 0](%1205, %1206)\n",
      "  %1208 = Shape(%1204)\n",
      "  %1209 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1210 = Gather[axis = 0](%1208, %1209)\n",
      "  %1213 = Constant[value = <Tensor>]()\n",
      "  %1214 = Unsqueeze(%1207, %1213)\n",
      "  %1215 = Constant[value = <Tensor>]()\n",
      "  %1216 = Unsqueeze(%1210, %1215)\n",
      "  %1221 = Concat[axis = 0](%1214, %1216, %2060, %2061)\n",
      "  %1222 = Reshape[allowzero = 0](%1204, %1221)\n",
      "  %1223 = Transpose[perm = [0, 2, 1, 3]](%1222)\n",
      "  %1224 = Shape(%1180)\n",
      "  %1225 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1226 = Gather[axis = 0](%1224, %1225)\n",
      "  %1227 = Shape(%1180)\n",
      "  %1228 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1229 = Gather[axis = 0](%1227, %1228)\n",
      "  %1232 = Constant[value = <Tensor>]()\n",
      "  %1233 = Unsqueeze(%1226, %1232)\n",
      "  %1234 = Constant[value = <Tensor>]()\n",
      "  %1235 = Unsqueeze(%1229, %1234)\n",
      "  %1240 = Concat[axis = 0](%1233, %1235, %2062, %2063)\n",
      "  %1241 = Reshape[allowzero = 0](%1180, %1240)\n",
      "  %1242 = Transpose[perm = [0, 2, 1, 3]](%1241)\n",
      "  %1243 = Transpose[perm = [0, 2, 3, 1]](%1201)\n",
      "  %1244 = MatMul(%1242, %1243)\n",
      "  %1245 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1246 = Div(%1244, %1245)\n",
      "  %1247 = Add(%1246, %246)\n",
      "  %1248 = Softmax[axis = -1](%1247)\n",
      "  %1249 = MatMul(%1248, %1223)\n",
      "  %1250 = Transpose[perm = [0, 2, 1, 3]](%1249)\n",
      "  %1251 = Shape(%1250)\n",
      "  %1252 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1253 = Gather[axis = 0](%1251, %1252)\n",
      "  %1254 = Shape(%1250)\n",
      "  %1255 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1256 = Gather[axis = 0](%1254, %1255)\n",
      "  %1258 = Constant[value = <Tensor>]()\n",
      "  %1259 = Unsqueeze(%1253, %1258)\n",
      "  %1260 = Constant[value = <Tensor>]()\n",
      "  %1261 = Unsqueeze(%1256, %1260)\n",
      "  %1264 = Concat[axis = 0](%1259, %1261, %2064)\n",
      "  %1265 = Reshape[allowzero = 0](%1250, %1264)\n",
      "  %1267 = MatMul(%1265, %2065)\n",
      "  %1268 = Add(%basemodel.bert.encoder.layer.7.attention.output.dense.bias, %1267)\n",
      "  %1269 = Add(%1268, %1177)\n",
      "  %1270 = ReduceMean[axes = [-1]](%1269)\n",
      "  %1271 = Sub(%1269, %1270)\n",
      "  %1272 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1273 = Pow(%1271, %1272)\n",
      "  %1274 = ReduceMean[axes = [-1]](%1273)\n",
      "  %1275 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1276 = Add(%1274, %1275)\n",
      "  %1277 = Sqrt(%1276)\n",
      "  %1278 = Div(%1271, %1277)\n",
      "  %1279 = Mul(%1278, %basemodel.bert.encoder.layer.7.attention.output.LayerNorm.weight)\n",
      "  %1280 = Add(%1279, %basemodel.bert.encoder.layer.7.attention.output.LayerNorm.bias)\n",
      "  %1282 = MatMul(%1280, %2066)\n",
      "  %1283 = Add(%basemodel.bert.encoder.layer.7.intermediate.dense.bias, %1282)\n",
      "  %1284 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1285 = Div(%1283, %1284)\n",
      "  %1286 = Erf(%1285)\n",
      "  %1287 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1288 = Add(%1286, %1287)\n",
      "  %1289 = Mul(%1283, %1288)\n",
      "  %1290 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1291 = Mul(%1289, %1290)\n",
      "  %1293 = MatMul(%1291, %2067)\n",
      "  %1294 = Add(%basemodel.bert.encoder.layer.7.output.dense.bias, %1293)\n",
      "  %1295 = Add(%1294, %1280)\n",
      "  %1296 = ReduceMean[axes = [-1]](%1295)\n",
      "  %1297 = Sub(%1295, %1296)\n",
      "  %1298 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1299 = Pow(%1297, %1298)\n",
      "  %1300 = ReduceMean[axes = [-1]](%1299)\n",
      "  %1301 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1302 = Add(%1300, %1301)\n",
      "  %1303 = Sqrt(%1302)\n",
      "  %1304 = Div(%1297, %1303)\n",
      "  %1305 = Mul(%1304, %basemodel.bert.encoder.layer.7.output.LayerNorm.weight)\n",
      "  %1306 = Add(%1305, %basemodel.bert.encoder.layer.7.output.LayerNorm.bias)\n",
      "  %1308 = MatMul(%1306, %2068)\n",
      "  %1309 = Add(%basemodel.bert.encoder.layer.8.attention.self.query.bias, %1308)\n",
      "  %1311 = MatMul(%1306, %2069)\n",
      "  %1312 = Add(%basemodel.bert.encoder.layer.8.attention.self.key.bias, %1311)\n",
      "  %1313 = Shape(%1312)\n",
      "  %1314 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1315 = Gather[axis = 0](%1313, %1314)\n",
      "  %1316 = Shape(%1312)\n",
      "  %1317 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1318 = Gather[axis = 0](%1316, %1317)\n",
      "  %1321 = Constant[value = <Tensor>]()\n",
      "  %1322 = Unsqueeze(%1315, %1321)\n",
      "  %1323 = Constant[value = <Tensor>]()\n",
      "  %1324 = Unsqueeze(%1318, %1323)\n",
      "  %1329 = Concat[axis = 0](%1322, %1324, %2070, %2071)\n",
      "  %1330 = Reshape[allowzero = 0](%1312, %1329)\n",
      "  %1332 = MatMul(%1306, %2072)\n",
      "  %1333 = Add(%basemodel.bert.encoder.layer.8.attention.self.value.bias, %1332)\n",
      "  %1334 = Shape(%1333)\n",
      "  %1335 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1336 = Gather[axis = 0](%1334, %1335)\n",
      "  %1337 = Shape(%1333)\n",
      "  %1338 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1339 = Gather[axis = 0](%1337, %1338)\n",
      "  %1342 = Constant[value = <Tensor>]()\n",
      "  %1343 = Unsqueeze(%1336, %1342)\n",
      "  %1344 = Constant[value = <Tensor>]()\n",
      "  %1345 = Unsqueeze(%1339, %1344)\n",
      "  %1350 = Concat[axis = 0](%1343, %1345, %2073, %2074)\n",
      "  %1351 = Reshape[allowzero = 0](%1333, %1350)\n",
      "  %1352 = Transpose[perm = [0, 2, 1, 3]](%1351)\n",
      "  %1353 = Shape(%1309)\n",
      "  %1354 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1355 = Gather[axis = 0](%1353, %1354)\n",
      "  %1356 = Shape(%1309)\n",
      "  %1357 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1358 = Gather[axis = 0](%1356, %1357)\n",
      "  %1361 = Constant[value = <Tensor>]()\n",
      "  %1362 = Unsqueeze(%1355, %1361)\n",
      "  %1363 = Constant[value = <Tensor>]()\n",
      "  %1364 = Unsqueeze(%1358, %1363)\n",
      "  %1369 = Concat[axis = 0](%1362, %1364, %2075, %2076)\n",
      "  %1370 = Reshape[allowzero = 0](%1309, %1369)\n",
      "  %1371 = Transpose[perm = [0, 2, 1, 3]](%1370)\n",
      "  %1372 = Transpose[perm = [0, 2, 3, 1]](%1330)\n",
      "  %1373 = MatMul(%1371, %1372)\n",
      "  %1374 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1375 = Div(%1373, %1374)\n",
      "  %1376 = Add(%1375, %246)\n",
      "  %1377 = Softmax[axis = -1](%1376)\n",
      "  %1378 = MatMul(%1377, %1352)\n",
      "  %1379 = Transpose[perm = [0, 2, 1, 3]](%1378)\n",
      "  %1380 = Shape(%1379)\n",
      "  %1381 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1382 = Gather[axis = 0](%1380, %1381)\n",
      "  %1383 = Shape(%1379)\n",
      "  %1384 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1385 = Gather[axis = 0](%1383, %1384)\n",
      "  %1387 = Constant[value = <Tensor>]()\n",
      "  %1388 = Unsqueeze(%1382, %1387)\n",
      "  %1389 = Constant[value = <Tensor>]()\n",
      "  %1390 = Unsqueeze(%1385, %1389)\n",
      "  %1393 = Concat[axis = 0](%1388, %1390, %2077)\n",
      "  %1394 = Reshape[allowzero = 0](%1379, %1393)\n",
      "  %1396 = MatMul(%1394, %2078)\n",
      "  %1397 = Add(%basemodel.bert.encoder.layer.8.attention.output.dense.bias, %1396)\n",
      "  %1398 = Add(%1397, %1306)\n",
      "  %1399 = ReduceMean[axes = [-1]](%1398)\n",
      "  %1400 = Sub(%1398, %1399)\n",
      "  %1401 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1402 = Pow(%1400, %1401)\n",
      "  %1403 = ReduceMean[axes = [-1]](%1402)\n",
      "  %1404 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1405 = Add(%1403, %1404)\n",
      "  %1406 = Sqrt(%1405)\n",
      "  %1407 = Div(%1400, %1406)\n",
      "  %1408 = Mul(%1407, %basemodel.bert.encoder.layer.8.attention.output.LayerNorm.weight)\n",
      "  %1409 = Add(%1408, %basemodel.bert.encoder.layer.8.attention.output.LayerNorm.bias)\n",
      "  %1411 = MatMul(%1409, %2079)\n",
      "  %1412 = Add(%basemodel.bert.encoder.layer.8.intermediate.dense.bias, %1411)\n",
      "  %1413 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1414 = Div(%1412, %1413)\n",
      "  %1415 = Erf(%1414)\n",
      "  %1416 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1417 = Add(%1415, %1416)\n",
      "  %1418 = Mul(%1412, %1417)\n",
      "  %1419 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1420 = Mul(%1418, %1419)\n",
      "  %1422 = MatMul(%1420, %2080)\n",
      "  %1423 = Add(%basemodel.bert.encoder.layer.8.output.dense.bias, %1422)\n",
      "  %1424 = Add(%1423, %1409)\n",
      "  %1425 = ReduceMean[axes = [-1]](%1424)\n",
      "  %1426 = Sub(%1424, %1425)\n",
      "  %1427 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1428 = Pow(%1426, %1427)\n",
      "  %1429 = ReduceMean[axes = [-1]](%1428)\n",
      "  %1430 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1431 = Add(%1429, %1430)\n",
      "  %1432 = Sqrt(%1431)\n",
      "  %1433 = Div(%1426, %1432)\n",
      "  %1434 = Mul(%1433, %basemodel.bert.encoder.layer.8.output.LayerNorm.weight)\n",
      "  %1435 = Add(%1434, %basemodel.bert.encoder.layer.8.output.LayerNorm.bias)\n",
      "  %1437 = MatMul(%1435, %2081)\n",
      "  %1438 = Add(%basemodel.bert.encoder.layer.9.attention.self.query.bias, %1437)\n",
      "  %1440 = MatMul(%1435, %2082)\n",
      "  %1441 = Add(%basemodel.bert.encoder.layer.9.attention.self.key.bias, %1440)\n",
      "  %1442 = Shape(%1441)\n",
      "  %1443 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1444 = Gather[axis = 0](%1442, %1443)\n",
      "  %1445 = Shape(%1441)\n",
      "  %1446 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1447 = Gather[axis = 0](%1445, %1446)\n",
      "  %1450 = Constant[value = <Tensor>]()\n",
      "  %1451 = Unsqueeze(%1444, %1450)\n",
      "  %1452 = Constant[value = <Tensor>]()\n",
      "  %1453 = Unsqueeze(%1447, %1452)\n",
      "  %1458 = Concat[axis = 0](%1451, %1453, %2083, %2084)\n",
      "  %1459 = Reshape[allowzero = 0](%1441, %1458)\n",
      "  %1461 = MatMul(%1435, %2085)\n",
      "  %1462 = Add(%basemodel.bert.encoder.layer.9.attention.self.value.bias, %1461)\n",
      "  %1463 = Shape(%1462)\n",
      "  %1464 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1465 = Gather[axis = 0](%1463, %1464)\n",
      "  %1466 = Shape(%1462)\n",
      "  %1467 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1468 = Gather[axis = 0](%1466, %1467)\n",
      "  %1471 = Constant[value = <Tensor>]()\n",
      "  %1472 = Unsqueeze(%1465, %1471)\n",
      "  %1473 = Constant[value = <Tensor>]()\n",
      "  %1474 = Unsqueeze(%1468, %1473)\n",
      "  %1479 = Concat[axis = 0](%1472, %1474, %2086, %2087)\n",
      "  %1480 = Reshape[allowzero = 0](%1462, %1479)\n",
      "  %1481 = Transpose[perm = [0, 2, 1, 3]](%1480)\n",
      "  %1482 = Shape(%1438)\n",
      "  %1483 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1484 = Gather[axis = 0](%1482, %1483)\n",
      "  %1485 = Shape(%1438)\n",
      "  %1486 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1487 = Gather[axis = 0](%1485, %1486)\n",
      "  %1490 = Constant[value = <Tensor>]()\n",
      "  %1491 = Unsqueeze(%1484, %1490)\n",
      "  %1492 = Constant[value = <Tensor>]()\n",
      "  %1493 = Unsqueeze(%1487, %1492)\n",
      "  %1498 = Concat[axis = 0](%1491, %1493, %2088, %2089)\n",
      "  %1499 = Reshape[allowzero = 0](%1438, %1498)\n",
      "  %1500 = Transpose[perm = [0, 2, 1, 3]](%1499)\n",
      "  %1501 = Transpose[perm = [0, 2, 3, 1]](%1459)\n",
      "  %1502 = MatMul(%1500, %1501)\n",
      "  %1503 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1504 = Div(%1502, %1503)\n",
      "  %1505 = Add(%1504, %246)\n",
      "  %1506 = Softmax[axis = -1](%1505)\n",
      "  %1507 = MatMul(%1506, %1481)\n",
      "  %1508 = Transpose[perm = [0, 2, 1, 3]](%1507)\n",
      "  %1509 = Shape(%1508)\n",
      "  %1510 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1511 = Gather[axis = 0](%1509, %1510)\n",
      "  %1512 = Shape(%1508)\n",
      "  %1513 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1514 = Gather[axis = 0](%1512, %1513)\n",
      "  %1516 = Constant[value = <Tensor>]()\n",
      "  %1517 = Unsqueeze(%1511, %1516)\n",
      "  %1518 = Constant[value = <Tensor>]()\n",
      "  %1519 = Unsqueeze(%1514, %1518)\n",
      "  %1522 = Concat[axis = 0](%1517, %1519, %2090)\n",
      "  %1523 = Reshape[allowzero = 0](%1508, %1522)\n",
      "  %1525 = MatMul(%1523, %2091)\n",
      "  %1526 = Add(%basemodel.bert.encoder.layer.9.attention.output.dense.bias, %1525)\n",
      "  %1527 = Add(%1526, %1435)\n",
      "  %1528 = ReduceMean[axes = [-1]](%1527)\n",
      "  %1529 = Sub(%1527, %1528)\n",
      "  %1530 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1531 = Pow(%1529, %1530)\n",
      "  %1532 = ReduceMean[axes = [-1]](%1531)\n",
      "  %1533 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1534 = Add(%1532, %1533)\n",
      "  %1535 = Sqrt(%1534)\n",
      "  %1536 = Div(%1529, %1535)\n",
      "  %1537 = Mul(%1536, %basemodel.bert.encoder.layer.9.attention.output.LayerNorm.weight)\n",
      "  %1538 = Add(%1537, %basemodel.bert.encoder.layer.9.attention.output.LayerNorm.bias)\n",
      "  %1540 = MatMul(%1538, %2092)\n",
      "  %1541 = Add(%basemodel.bert.encoder.layer.9.intermediate.dense.bias, %1540)\n",
      "  %1542 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1543 = Div(%1541, %1542)\n",
      "  %1544 = Erf(%1543)\n",
      "  %1545 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1546 = Add(%1544, %1545)\n",
      "  %1547 = Mul(%1541, %1546)\n",
      "  %1548 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1549 = Mul(%1547, %1548)\n",
      "  %1551 = MatMul(%1549, %2093)\n",
      "  %1552 = Add(%basemodel.bert.encoder.layer.9.output.dense.bias, %1551)\n",
      "  %1553 = Add(%1552, %1538)\n",
      "  %1554 = ReduceMean[axes = [-1]](%1553)\n",
      "  %1555 = Sub(%1553, %1554)\n",
      "  %1556 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1557 = Pow(%1555, %1556)\n",
      "  %1558 = ReduceMean[axes = [-1]](%1557)\n",
      "  %1559 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1560 = Add(%1558, %1559)\n",
      "  %1561 = Sqrt(%1560)\n",
      "  %1562 = Div(%1555, %1561)\n",
      "  %1563 = Mul(%1562, %basemodel.bert.encoder.layer.9.output.LayerNorm.weight)\n",
      "  %1564 = Add(%1563, %basemodel.bert.encoder.layer.9.output.LayerNorm.bias)\n",
      "  %1566 = MatMul(%1564, %2094)\n",
      "  %1567 = Add(%basemodel.bert.encoder.layer.10.attention.self.query.bias, %1566)\n",
      "  %1569 = MatMul(%1564, %2095)\n",
      "  %1570 = Add(%basemodel.bert.encoder.layer.10.attention.self.key.bias, %1569)\n",
      "  %1571 = Shape(%1570)\n",
      "  %1572 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1573 = Gather[axis = 0](%1571, %1572)\n",
      "  %1574 = Shape(%1570)\n",
      "  %1575 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1576 = Gather[axis = 0](%1574, %1575)\n",
      "  %1579 = Constant[value = <Tensor>]()\n",
      "  %1580 = Unsqueeze(%1573, %1579)\n",
      "  %1581 = Constant[value = <Tensor>]()\n",
      "  %1582 = Unsqueeze(%1576, %1581)\n",
      "  %1587 = Concat[axis = 0](%1580, %1582, %2096, %2097)\n",
      "  %1588 = Reshape[allowzero = 0](%1570, %1587)\n",
      "  %1590 = MatMul(%1564, %2098)\n",
      "  %1591 = Add(%basemodel.bert.encoder.layer.10.attention.self.value.bias, %1590)\n",
      "  %1592 = Shape(%1591)\n",
      "  %1593 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1594 = Gather[axis = 0](%1592, %1593)\n",
      "  %1595 = Shape(%1591)\n",
      "  %1596 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1597 = Gather[axis = 0](%1595, %1596)\n",
      "  %1600 = Constant[value = <Tensor>]()\n",
      "  %1601 = Unsqueeze(%1594, %1600)\n",
      "  %1602 = Constant[value = <Tensor>]()\n",
      "  %1603 = Unsqueeze(%1597, %1602)\n",
      "  %1608 = Concat[axis = 0](%1601, %1603, %2099, %2100)\n",
      "  %1609 = Reshape[allowzero = 0](%1591, %1608)\n",
      "  %1610 = Transpose[perm = [0, 2, 1, 3]](%1609)\n",
      "  %1611 = Shape(%1567)\n",
      "  %1612 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1613 = Gather[axis = 0](%1611, %1612)\n",
      "  %1614 = Shape(%1567)\n",
      "  %1615 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1616 = Gather[axis = 0](%1614, %1615)\n",
      "  %1619 = Constant[value = <Tensor>]()\n",
      "  %1620 = Unsqueeze(%1613, %1619)\n",
      "  %1621 = Constant[value = <Tensor>]()\n",
      "  %1622 = Unsqueeze(%1616, %1621)\n",
      "  %1627 = Concat[axis = 0](%1620, %1622, %2101, %2102)\n",
      "  %1628 = Reshape[allowzero = 0](%1567, %1627)\n",
      "  %1629 = Transpose[perm = [0, 2, 1, 3]](%1628)\n",
      "  %1630 = Transpose[perm = [0, 2, 3, 1]](%1588)\n",
      "  %1631 = MatMul(%1629, %1630)\n",
      "  %1632 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1633 = Div(%1631, %1632)\n",
      "  %1634 = Add(%1633, %246)\n",
      "  %1635 = Softmax[axis = -1](%1634)\n",
      "  %1636 = MatMul(%1635, %1610)\n",
      "  %1637 = Transpose[perm = [0, 2, 1, 3]](%1636)\n",
      "  %1638 = Shape(%1637)\n",
      "  %1639 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1640 = Gather[axis = 0](%1638, %1639)\n",
      "  %1641 = Shape(%1637)\n",
      "  %1642 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1643 = Gather[axis = 0](%1641, %1642)\n",
      "  %1645 = Constant[value = <Tensor>]()\n",
      "  %1646 = Unsqueeze(%1640, %1645)\n",
      "  %1647 = Constant[value = <Tensor>]()\n",
      "  %1648 = Unsqueeze(%1643, %1647)\n",
      "  %1651 = Concat[axis = 0](%1646, %1648, %2103)\n",
      "  %1652 = Reshape[allowzero = 0](%1637, %1651)\n",
      "  %1654 = MatMul(%1652, %2104)\n",
      "  %1655 = Add(%basemodel.bert.encoder.layer.10.attention.output.dense.bias, %1654)\n",
      "  %1656 = Add(%1655, %1564)\n",
      "  %1657 = ReduceMean[axes = [-1]](%1656)\n",
      "  %1658 = Sub(%1656, %1657)\n",
      "  %1659 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1660 = Pow(%1658, %1659)\n",
      "  %1661 = ReduceMean[axes = [-1]](%1660)\n",
      "  %1662 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1663 = Add(%1661, %1662)\n",
      "  %1664 = Sqrt(%1663)\n",
      "  %1665 = Div(%1658, %1664)\n",
      "  %1666 = Mul(%1665, %basemodel.bert.encoder.layer.10.attention.output.LayerNorm.weight)\n",
      "  %1667 = Add(%1666, %basemodel.bert.encoder.layer.10.attention.output.LayerNorm.bias)\n",
      "  %1669 = MatMul(%1667, %2105)\n",
      "  %1670 = Add(%basemodel.bert.encoder.layer.10.intermediate.dense.bias, %1669)\n",
      "  %1671 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1672 = Div(%1670, %1671)\n",
      "  %1673 = Erf(%1672)\n",
      "  %1674 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1675 = Add(%1673, %1674)\n",
      "  %1676 = Mul(%1670, %1675)\n",
      "  %1677 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1678 = Mul(%1676, %1677)\n",
      "  %1680 = MatMul(%1678, %2106)\n",
      "  %1681 = Add(%basemodel.bert.encoder.layer.10.output.dense.bias, %1680)\n",
      "  %1682 = Add(%1681, %1667)\n",
      "  %1683 = ReduceMean[axes = [-1]](%1682)\n",
      "  %1684 = Sub(%1682, %1683)\n",
      "  %1685 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1686 = Pow(%1684, %1685)\n",
      "  %1687 = ReduceMean[axes = [-1]](%1686)\n",
      "  %1688 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1689 = Add(%1687, %1688)\n",
      "  %1690 = Sqrt(%1689)\n",
      "  %1691 = Div(%1684, %1690)\n",
      "  %1692 = Mul(%1691, %basemodel.bert.encoder.layer.10.output.LayerNorm.weight)\n",
      "  %1693 = Add(%1692, %basemodel.bert.encoder.layer.10.output.LayerNorm.bias)\n",
      "  %1695 = MatMul(%1693, %2107)\n",
      "  %1696 = Add(%basemodel.bert.encoder.layer.11.attention.self.query.bias, %1695)\n",
      "  %1698 = MatMul(%1693, %2108)\n",
      "  %1699 = Add(%basemodel.bert.encoder.layer.11.attention.self.key.bias, %1698)\n",
      "  %1700 = Shape(%1699)\n",
      "  %1701 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1702 = Gather[axis = 0](%1700, %1701)\n",
      "  %1703 = Shape(%1699)\n",
      "  %1704 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1705 = Gather[axis = 0](%1703, %1704)\n",
      "  %1708 = Constant[value = <Tensor>]()\n",
      "  %1709 = Unsqueeze(%1702, %1708)\n",
      "  %1710 = Constant[value = <Tensor>]()\n",
      "  %1711 = Unsqueeze(%1705, %1710)\n",
      "  %1716 = Concat[axis = 0](%1709, %1711, %2109, %2110)\n",
      "  %1717 = Reshape[allowzero = 0](%1699, %1716)\n",
      "  %1719 = MatMul(%1693, %2111)\n",
      "  %1720 = Add(%basemodel.bert.encoder.layer.11.attention.self.value.bias, %1719)\n",
      "  %1721 = Shape(%1720)\n",
      "  %1722 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1723 = Gather[axis = 0](%1721, %1722)\n",
      "  %1724 = Shape(%1720)\n",
      "  %1725 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1726 = Gather[axis = 0](%1724, %1725)\n",
      "  %1729 = Constant[value = <Tensor>]()\n",
      "  %1730 = Unsqueeze(%1723, %1729)\n",
      "  %1731 = Constant[value = <Tensor>]()\n",
      "  %1732 = Unsqueeze(%1726, %1731)\n",
      "  %1737 = Concat[axis = 0](%1730, %1732, %2112, %2113)\n",
      "  %1738 = Reshape[allowzero = 0](%1720, %1737)\n",
      "  %1739 = Transpose[perm = [0, 2, 1, 3]](%1738)\n",
      "  %1740 = Shape(%1696)\n",
      "  %1741 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1742 = Gather[axis = 0](%1740, %1741)\n",
      "  %1743 = Shape(%1696)\n",
      "  %1744 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1745 = Gather[axis = 0](%1743, %1744)\n",
      "  %1748 = Constant[value = <Tensor>]()\n",
      "  %1749 = Unsqueeze(%1742, %1748)\n",
      "  %1750 = Constant[value = <Tensor>]()\n",
      "  %1751 = Unsqueeze(%1745, %1750)\n",
      "  %1756 = Concat[axis = 0](%1749, %1751, %2114, %2115)\n",
      "  %1757 = Reshape[allowzero = 0](%1696, %1756)\n",
      "  %1758 = Transpose[perm = [0, 2, 1, 3]](%1757)\n",
      "  %1759 = Transpose[perm = [0, 2, 3, 1]](%1717)\n",
      "  %1760 = MatMul(%1758, %1759)\n",
      "  %1761 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1762 = Div(%1760, %1761)\n",
      "  %1763 = Add(%1762, %246)\n",
      "  %1764 = Softmax[axis = -1](%1763)\n",
      "  %1765 = MatMul(%1764, %1739)\n",
      "  %1766 = Transpose[perm = [0, 2, 1, 3]](%1765)\n",
      "  %1767 = Shape(%1766)\n",
      "  %1768 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1769 = Gather[axis = 0](%1767, %1768)\n",
      "  %1770 = Shape(%1766)\n",
      "  %1771 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1772 = Gather[axis = 0](%1770, %1771)\n",
      "  %1774 = Constant[value = <Tensor>]()\n",
      "  %1775 = Unsqueeze(%1769, %1774)\n",
      "  %1776 = Constant[value = <Tensor>]()\n",
      "  %1777 = Unsqueeze(%1772, %1776)\n",
      "  %1780 = Concat[axis = 0](%1775, %1777, %2116)\n",
      "  %1781 = Reshape[allowzero = 0](%1766, %1780)\n",
      "  %1783 = MatMul(%1781, %2117)\n",
      "  %1784 = Add(%basemodel.bert.encoder.layer.11.attention.output.dense.bias, %1783)\n",
      "  %1785 = Add(%1784, %1693)\n",
      "  %1786 = ReduceMean[axes = [-1]](%1785)\n",
      "  %1787 = Sub(%1785, %1786)\n",
      "  %1788 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1789 = Pow(%1787, %1788)\n",
      "  %1790 = ReduceMean[axes = [-1]](%1789)\n",
      "  %1791 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1792 = Add(%1790, %1791)\n",
      "  %1793 = Sqrt(%1792)\n",
      "  %1794 = Div(%1787, %1793)\n",
      "  %1795 = Mul(%1794, %basemodel.bert.encoder.layer.11.attention.output.LayerNorm.weight)\n",
      "  %1796 = Add(%1795, %basemodel.bert.encoder.layer.11.attention.output.LayerNorm.bias)\n",
      "  %1798 = MatMul(%1796, %2118)\n",
      "  %1799 = Add(%basemodel.bert.encoder.layer.11.intermediate.dense.bias, %1798)\n",
      "  %1800 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1801 = Div(%1799, %1800)\n",
      "  %1802 = Erf(%1801)\n",
      "  %1803 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1804 = Add(%1802, %1803)\n",
      "  %1805 = Mul(%1799, %1804)\n",
      "  %1806 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1807 = Mul(%1805, %1806)\n",
      "  %1809 = MatMul(%1807, %2119)\n",
      "  %1810 = Add(%basemodel.bert.encoder.layer.11.output.dense.bias, %1809)\n",
      "  %1811 = Add(%1810, %1796)\n",
      "  %1812 = ReduceMean[axes = [-1]](%1811)\n",
      "  %1813 = Sub(%1811, %1812)\n",
      "  %1814 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1815 = Pow(%1813, %1814)\n",
      "  %1816 = ReduceMean[axes = [-1]](%1815)\n",
      "  %1817 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1818 = Add(%1816, %1817)\n",
      "  %1819 = Sqrt(%1818)\n",
      "  %1820 = Div(%1813, %1819)\n",
      "  %1821 = Mul(%1820, %basemodel.bert.encoder.layer.11.output.LayerNorm.weight)\n",
      "  %1822 = Add(%1821, %basemodel.bert.encoder.layer.11.output.LayerNorm.bias)\n",
      "  %1824 = MatMul(%1822, %2120)\n",
      "  %1825 = Add(%basemodel.start.bias, %1824)\n",
      "  %1827 = MatMul(%1822, %2121)\n",
      "  %1828 = Add(%basemodel.end.bias, %1827)\n",
      "  %1829 = Shape(%1825)\n",
      "  %1830 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1831 = Gather[axis = 0](%1829, %1830)\n",
      "  %1836 = Constant[value = <Tensor>]()\n",
      "  %1837 = Unsqueeze(%1831, %1836)\n",
      "  %1840 = Constant[value = <Tensor>]()\n",
      "  %1841 = Slice(%attention_mask, %2122, %1837, %2123, %1840)\n",
      "  %1842 = Constant[value = <Tensor>]()\n",
      "  %1843 = Unsqueeze(%1841, %1842)\n",
      "  %1848 = Constant[value = <Tensor>]()\n",
      "  %1849 = Unsqueeze(%1831, %1848)\n",
      "  %1852 = Concat[axis = 0](%2124, %1849, %2125)\n",
      "  %1853 = Constant[value = <Tensor>]()\n",
      "  %1854 = Reshape[allowzero = 0](%1852, %1853)\n",
      "  %1855 = Shape(%1854)\n",
      "  %1856 = ConstantOfShape[value = <Tensor>](%1855)\n",
      "  %1857 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1858 = Mul(%1856, %1857)\n",
      "  %1859 = Equal(%1854, %1858)\n",
      "  %1860 = Where(%1859, %1856, %1854)\n",
      "  %1861 = Expand(%1843, %1860)\n",
      "  %1862 = Constant[value = <Tensor>]()\n",
      "  %1863 = Unsqueeze(%1841, %1862)\n",
      "  %1870 = Constant[value = <Tensor>]()\n",
      "  %1871 = Unsqueeze(%1831, %1870)\n",
      "  %1872 = Concat[axis = 0](%2126, %2127, %1871)\n",
      "  %1873 = Constant[value = <Tensor>]()\n",
      "  %1874 = Reshape[allowzero = 0](%1872, %1873)\n",
      "  %1875 = Shape(%1874)\n",
      "  %1876 = ConstantOfShape[value = <Tensor>](%1875)\n",
      "  %1877 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1878 = Mul(%1876, %1877)\n",
      "  %1879 = Equal(%1874, %1878)\n",
      "  %1880 = Where(%1879, %1876, %1874)\n",
      "  %1881 = Expand(%1863, %1880)\n",
      "  %1882 = Mul(%1861, %1881)\n",
      "  %1883 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1884 = Trilu[upper = 1](%1882, %1883)\n",
      "  %1885 = Constant[value = <Tensor>]()\n",
      "  %1886 = Unsqueeze(%1884, %1885)\n",
      "  %1887 = Constant[value = <Tensor>]()\n",
      "  %1889 = ConstantOfShape[value = <Tensor>](%2128)\n",
      "  %1890 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1891 = Mul(%1889, %1890)\n",
      "  %1892 = Constant[value = <Tensor>]()\n",
      "  %1893 = Equal(%1892, %1891)\n",
      "  %1894 = Where(%1893, %1889, %1887)\n",
      "  %1895 = Expand(%1886, %1894)\n",
      "  %1896 = Shape(%1825)\n",
      "  %1897 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1898 = Gather[axis = 0](%1896, %1897)\n",
      "  %1899 = Shape(%1828)\n",
      "  %1900 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1901 = Gather[axis = 0](%1899, %1900)\n",
      "  %1902 = Shape(%1828)\n",
      "  %1903 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1904 = Gather[axis = 0](%1902, %1903)\n",
      "  %1905 = Shape(%1828)\n",
      "  %1906 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1907 = Gather[axis = 0](%1905, %1906)\n",
      "  %1909 = Constant[value = <Tensor>]()\n",
      "  %1910 = Unsqueeze(%1901, %1909)\n",
      "  %1911 = Constant[value = <Tensor>]()\n",
      "  %1912 = Unsqueeze(%1898, %1911)\n",
      "  %1915 = Concat[axis = 0](%1910, %1912, %2129)\n",
      "  %1916 = ConstantOfShape[value = <Tensor>](%1915)\n",
      "  %1917 = Cast[to = 1](%1916)\n",
      "  %1918 = Concat[axis = 2](%1825, %1917)\n",
      "  %1920 = Constant[value = <Tensor>]()\n",
      "  %1921 = Unsqueeze(%1901, %1920)\n",
      "  %1922 = Constant[value = <Tensor>]()\n",
      "  %1923 = Unsqueeze(%1904, %1922)\n",
      "  %1926 = Concat[axis = 0](%1921, %1923, %2130)\n",
      "  %1927 = ConstantOfShape[value = <Tensor>](%1926)\n",
      "  %1928 = Cast[to = 1](%1927)\n",
      "  %1929 = Concat[axis = 2](%1828, %1928)\n",
      "  %1930 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1931 = Add(%1907, %1930)\n",
      "  %1933 = MatMul(%1918, %2131)\n",
      "  %1934 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1935 = Mul(%1898, %1934)\n",
      "  %1936 = Constant[value = <Tensor>]()\n",
      "  %1937 = Unsqueeze(%1901, %1936)\n",
      "  %1938 = Constant[value = <Tensor>]()\n",
      "  %1939 = Unsqueeze(%1935, %1938)\n",
      "  %1940 = Constant[value = <Tensor>]()\n",
      "  %1941 = Unsqueeze(%1931, %1940)\n",
      "  %1942 = Concat[axis = 0](%1937, %1939, %1941)\n",
      "  %1943 = Reshape[allowzero = 0](%1933, %1942)\n",
      "  %1944 = Transpose[perm = [0, 2, 1]](%1929)\n",
      "  %1945 = MatMul(%1943, %1944)\n",
      "  %1946 = Transpose[perm = [0, 2, 1]](%1945)\n",
      "  %1948 = Constant[value = <Tensor>]()\n",
      "  %1949 = Unsqueeze(%1901, %1948)\n",
      "  %1950 = Constant[value = <Tensor>]()\n",
      "  %1951 = Unsqueeze(%1904, %1950)\n",
      "  %1952 = Constant[value = <Tensor>]()\n",
      "  %1953 = Unsqueeze(%1898, %1952)\n",
      "  %1956 = Concat[axis = 0](%1949, %1951, %1953, %2132)\n",
      "  %1957 = Reshape[allowzero = 0](%1946, %1956)\n",
      "  %1958 = Transpose[perm = [0, 2, 1, 3]](%1957)\n",
      "  %1959 = Cast[to = 1](%1895)\n",
      "  %1960 = Mul(%1958, %1959)\n",
      "  %output_0 = ArgMax[axis = 3, keepdims = 0, select_last_index = 0](%1960)\n",
      "  return %output_0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model2 = onnx.load(\"/root/autodl-nas/export_models/absa/gts-absa.onnx\")\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(model2)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model2.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb6cb0-7287-4f70-ad1f-e83633add418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
